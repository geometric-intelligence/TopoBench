_target_: topobench.model.TBModel

model_name: gin
model_domain: graph

feature_encoder:
  _target_: topobench.nn.encoders.${model.feature_encoder.encoder_name}
  encoder_name: AllCellFeatureEncoder
  in_channels: ${infer_in_channels:${dataset},${oc.select:transforms,null}} 
  out_channels: 32
  proj_dropout: 0.0

backbone:
  _target_: torch_geometric.nn.models.GIN
  in_channels: ${model.feature_encoder.out_channels}
  hidden_channels: ${model.feature_encoder.out_channels}
  num_layers: 1
  dropout: 0.0
  act: relu

backbone_wrapper:
  _target_: topobench.nn.wrappers.GNNWrapper
  _partial_: true
  wrapper_name: GNNWrapper
  out_channels: ${model.feature_encoder.out_channels}
  num_cell_dimensions: ${infer_num_cell_dimensions:${oc.select:model.feature_encoder.selected_dimensions,null},${model.feature_encoder.in_channels}}

readout:
  _target_: topobench.nn.readouts.${model.readout.readout_name}
  readout_name: MLPReadout 
  num_cell_dimensions: ${infer_num_cell_dimensions:${oc.select:model.feature_encoder.selected_dimensions,null},${model.feature_encoder.in_channels}} # The highest order of cell dimensions to consider
  in_channels: ${model.feature_encoder.out_channels}
  hidden_layers: []
  out_channels: ${dataset.parameters.num_classes}
  task_level: ${dataset.parameters.task_level}
  pooling_type: sum
  # Extra MLP params
  dropout: 0.0
  act: "relu"
  norm: null
  final_act: null

# compile model for faster training with pytorch 2.0
compile: false
