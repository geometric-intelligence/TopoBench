# Note that to avoid breaking of the pipeline we have to still precompute embeddings, the experiment/tabpfn_no_pse.yaml ensures that the embeddings are not used.
defaults:
  - liftings@_here_: graph2cell_default
  - data_manipulations@hopse_encoding: hopse_ps_information

hopse_encoding:
  neighborhoods:  
    - 'up_adjacency-0'
    #- 'up_incidence-0'
    # - 'up_adjacency-1'
    # - 'down_adjacency-1'
    # - 'down_adjacency-2'
    # - 'up_incidence-1'
    # - 'down_incidence-1'
    # - 'down_incidence-2'
  pe_types: 
    - 'RWSE' 
    #- 'ElstaticPE'
    #- 'HKdiagSE'
    #- 'LapPE'
   

  # Different PS have different sizes, need to unify them. 
  target_pe_dim: 20

  # LapPE config
  laplacian_norm_type: 'sym'
  posenc_LapPE_eigen_max_freqs: 18
  posenc_LapPE_eigen_eigvec_norm: 'L2'
  posenc_LapPE_eigen_skip_zero_freq: True
  posenc_LapPE_eigen_eigvec_abs: True

  # RWSE config
  kernel_param_RWSE: 
    - 2
    - 20

  # HKdiagSE config
  kernel_param_HKdiagSE: 
    - 1
    - 22


graph2cell_lifting: 
  neighborhoods: ${transforms.hopse_encoding.neighborhoods}
    