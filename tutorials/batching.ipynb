{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"./\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "import torch\n",
    "import torch_geometric\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from topobenchmarkx.data.preprocessor import PreProcessor\n",
    "from topobenchmarkx.dataloader.dataloader import TBXDataloader\n",
    "from topobenchmarkx.data.loaders import GraphLoader\n",
    "\n",
    "from topobenchmarkx.utils.config_resolvers import (\n",
    "    get_default_transform,\n",
    "    get_monitor_metric,\n",
    "    get_monitor_mode,\n",
    "    infer_in_channels,\n",
    ")\n",
    "\n",
    "\n",
    "initialize(config_path=\"../configs\", job_name=\"job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.patches import Polygon\n",
    "from itertools import combinations\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "def plot_graph(\n",
    "    data,\n",
    "    face_color_map: Optional[Dict[int, str]] = None,\n",
    "    node_size: int = 500,\n",
    "    font_size: int = 12,\n",
    "    seed: int = 5,\n",
    "    show: bool = True\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Visualize a simplicial complex from a PyTorch Geometric Data object.\n",
    "    \n",
    "    Args:\n",
    "        data: torch_geometric.data.Data object containing the simplicial complex\n",
    "        face_color_map: Dictionary mapping number of tetrahedrons to colors\n",
    "        node_size: Size of nodes in the visualization\n",
    "        font_size: Size of font for labels\n",
    "        seed: Random seed for layout\n",
    "        show: Whether to display the plot immediately\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The generated figure\n",
    "    \"\"\"\n",
    "    # Default color map if none provided\n",
    "    if face_color_map is None:\n",
    "        face_color_map = {\n",
    "            0: \"pink\",\n",
    "            1: \"gray\",\n",
    "            2: \"blue\",\n",
    "            3: \"blue\",\n",
    "            4: \"orange\",\n",
    "            5: \"purple\",\n",
    "            6: \"red\",\n",
    "            7: \"brown\",\n",
    "            8: \"black\",\n",
    "            9: \"gray\",\n",
    "        }\n",
    "    \n",
    "    # Extract vertices\n",
    "    num_vertices = data.num_nodes if hasattr(data, 'num_nodes') else data.x.shape[0]\n",
    "    vertices = list(range(num_vertices))\n",
    "    \n",
    "    # Extract edges from incidence matrix\n",
    "    edges = []\n",
    "    for edge in abs(data.incidence_1.to_dense().T):\n",
    "        edges.append(torch.where(edge == 1)[0].numpy())\n",
    "    edges = np.array(edges)\n",
    "    \n",
    "    # Extract tetrahedrons if available\n",
    "    tetrahedrons = []\n",
    "    if hasattr(data, 'tetrahedrons'):\n",
    "        tetrahedrons = data.tetrahedrons\n",
    "    elif hasattr(data, 'incidence_2'):\n",
    "        # Extract tetrahedrons from incidence_2 matrix if available\n",
    "        for tetra in abs(data.incidence_2.to_dense().T):\n",
    "            tetrahedrons.append(torch.where(tetra == 1)[0].tolist())\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(vertices)\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Find triangular cliques\n",
    "    cliques = list(nx.enumerate_all_cliques(G))\n",
    "    cliques = [triangle for triangle in cliques if len(triangle) == 3]\n",
    "    \n",
    "    # Create layout\n",
    "    pos = nx.spring_layout(G, seed=seed)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Draw nodes and labels\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        labels={i: f\"v_{i}\" for i in G.nodes()},\n",
    "        node_size=node_size,\n",
    "        node_color=\"skyblue\",\n",
    "        font_size=font_size,\n",
    "    )\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=\"g\", width=2, alpha=0.5)\n",
    "    \n",
    "    # Add edge labels\n",
    "    for i, (u, v) in enumerate(edges):\n",
    "        x = (pos[u][0] + pos[v][0]) / 2\n",
    "        y = (pos[u][1] + pos[v][1]) / 2\n",
    "        plt.text(x, y, f\"e_{i}\", fontsize=font_size - 2, color=\"r\")\n",
    "    \n",
    "    # Color the faces (cliques)\n",
    "    for clique in cliques:\n",
    "        # Count tetrahedrons containing this clique\n",
    "        counter = 0\n",
    "        for tetrahedron in tetrahedrons:\n",
    "            for comb in combinations(tetrahedron, 3):\n",
    "                if set(clique) == set(comb):\n",
    "                    counter += 1\n",
    "        \n",
    "        # Create and add polygon\n",
    "        polygon = [pos[v] for v in clique]\n",
    "        poly = Polygon(\n",
    "            polygon,\n",
    "            closed=True,\n",
    "            facecolor=face_color_map.get(counter, \"gray\"),  # Default to gray if counter not in map\n",
    "            edgecolor=\"pink\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        plt.gca().add_patch(poly)\n",
    "    \n",
    "    plt.title(f\"Graph with cliques colored ({num_vertices} vertices)\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "# replace adjacency keys with temp\n",
    "def workaround_adj(data):\n",
    "    n_incidences = len([key for key in data.keys() if \"incidence\" in key])\n",
    "    for i in range(n_incidences):\n",
    "        if f\"adjacency_{i}\" in data.keys():\n",
    "            data[f\"temp_{i}\"] = data[f\"adjacency_{i}\"]\n",
    "            del data[f\"adjacency_{i}\"]\n",
    "    return data\n",
    "\n",
    "def get_sampled_neighborhood(data, rank=0, is_hypergraph=False):\n",
    "    ''' This function updates the edge_index attribute of torch_geometric.data.Data. \n",
    "    \n",
    "    The function finds cells, of the specified rank K, that are either upper or lower neighbors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: torch_geometric.data.Data\n",
    "        The input data.\n",
    "    rank: int\n",
    "        The rank of the cells that you want to batch over.\n",
    "    is_hypergraph: bool\n",
    "        Whether the data represents an hypergraph.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch_geometric.data.Data\n",
    "        The output data with updated edge_index.\n",
    "        edge_index contains indices of connected cells of the specified rank K.  \n",
    "        Two cells of rank K are connected if they are either lower or upper neighbors. \n",
    "    '''\n",
    "    # TODO: add upper adj\n",
    "    if rank == 0:\n",
    "        return data\n",
    "    if is_hypergraph: #TODO: add rank=1 case\n",
    "        I = data.incidence_hyperedges\n",
    "        A = torch.sparse.mm(I,I.T) # lower adj matrix\n",
    "        edges = A.indices() \n",
    "    else:\n",
    "        # get number of incidences\n",
    "        max_rank = len([key for key in data.keys() if \"incidence\" in key])-1\n",
    "        if rank > max_rank:\n",
    "            raise ValueError(f\"Rank {rank} is greater than the maximum rank {max_rank} in the data.\")\n",
    "        if rank == max_rank:\n",
    "            edges = torch.empty((2, 0), dtype=torch.long)\n",
    "        else:\n",
    "            P = data[f\"incidence_{rank+1}\"]\n",
    "            Q = torch.sparse.mm(P,P.T)\n",
    "            edges = Q.indices()\n",
    "            \n",
    "        # This is for selecting the whole upper cells\n",
    "        # for i in range(rank+1, max_rank):\n",
    "        #     P = torch.sparse.mm(P, data[f\"incidence_{i+1}\"])\n",
    "        #     Q = torch.sparse.mm(P,P.T)\n",
    "        #     edges = torch.cat((edges, Q.indices()), dim=1)\n",
    "        \n",
    "        # This considers the lower adjacency \n",
    "        P = data[f\"incidence_{rank}\"]\n",
    "        Q = torch.sparse.mm(P.T,P)\n",
    "        edges = torch.cat((edges, Q.indices()), dim=1)\n",
    "        \n",
    "        # This is for selecting if the cells share any node\n",
    "        # for i in range(rank-1, 0, -1):\n",
    "        #     P = torch.sparse.mm(data[f\"incidence_{i}\"], P)\n",
    "        #     Q = torch.sparse.mm(P.T,P)\n",
    "        #     edges = torch.cat((edges, Q.indices()), dim=1)\n",
    "            \n",
    "    edges = torch.unique(edges, dim=1)\n",
    "    # Remove self edges\n",
    "    mask = edges[0, :] != edges[1, :]\n",
    "    edges = edges[:, mask]\n",
    "    \n",
    "    data.edge_index = edges\n",
    "    \n",
    "    # We need to set x to x_{rank} since NeighborLoader will take the number of nodes from the x attribute\n",
    "    # The correct x is given after the reduce_neighborhoods function\n",
    "    if is_hypergraph and rank == 1:\n",
    "        data.x = data.x_hyperedges\n",
    "    else:\n",
    "        data.x = data[f'x_{rank}']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def reduce_higher_ranks_incidences(batch, cells_ids, rank, max_rank, is_hypergraph=False):\n",
    "    \"\"\" Reduce the incidences with higher rank than the specified one.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torch_geometric.data.Data\n",
    "        The input data.\n",
    "    cells_ids: list[torch.Tensor]\n",
    "        List of tensors containing the ids of the cells. The length of the list should be equal to the maximum rank.\n",
    "    rank: int\n",
    "        The rank to select the higher order incidences.\n",
    "    max_rank: int\n",
    "        The maximum rank of the incidences.\n",
    "    is_hypergraph: bool\n",
    "        Whether the data represents an hypergraph.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch_geometric.data.Data\n",
    "        The output data with the reduced incidences.\n",
    "    \"\"\"\n",
    "    for i in range(1, max_rank+1):\n",
    "        if is_hypergraph:\n",
    "            incidence = batch.incidence_hyperedges\n",
    "        else:\n",
    "            incidence = batch[f\"incidence_{i}\"]\n",
    "            \n",
    "        if i != rank+1:\n",
    "            incidence = torch.index_select(incidence, 0, cells_ids[i-1])\n",
    "        cells_ids[i] = torch.where(torch.sum(incidence, dim=0).to_dense() > 1)[0]\n",
    "        incidence = torch.index_select(incidence, 1, cells_ids[i])\n",
    "        batch[f\"incidence_{i}\"] = incidence\n",
    "    if not is_hypergraph:\n",
    "        incidence = batch[f\"incidence_0\"]\n",
    "        incidence = torch.index_select(incidence, 1, cells_ids[0])\n",
    "        batch[f\"incidence_0\"] = incidence\n",
    "    \n",
    "    return batch, cells_ids\n",
    "\n",
    "def get_node_indices(batch, cells_ids, rank, is_hypergraph=False):\n",
    "    \"\"\" Get the indices of the nodes contained by the cells specified in cells_ids and rank.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torch_geometric.data.Data\n",
    "        The input data.\n",
    "    cells_ids: list[torch.Tensor]\n",
    "        List of tensors containing the ids of the cells. The length of the list should be equal to the maximum rank.\n",
    "    rank: int\n",
    "        The rank of the cells to consider.\n",
    "    is_hypergraph: bool\n",
    "        Whether the data represents an hypergraph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The indices of the nodes contained by the cells.\n",
    "    \"\"\"\n",
    "    cells_ids_new = [c_i for c_i in cells_ids]\n",
    "    for i in range(rank, 0, -1):\n",
    "        if is_hypergraph:\n",
    "            incidence = batch.incidence_hyperedges\n",
    "        else:\n",
    "            incidence = batch[f\"incidence_{i}\"]\n",
    "        incidence = torch.index_select(incidence, 1, cells_ids_new[i])\n",
    "        cells_ids_new[i-1] = torch.where(torch.sum(incidence, dim=1).to_dense() > 0)[0]\n",
    "    return cells_ids_new[0]\n",
    "\n",
    "def reduce_matrices(batch, cells_ids, names, rank, max_rank):\n",
    "    \"\"\" Reduce the matrices using the indices in cells_ids. \n",
    "    \n",
    "    The matrices are assumed to be in the batch with the names specified in the list names.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torch_geometric.data.Data\n",
    "        The input data.\n",
    "    cells_ids: list[torch.Tensor]\n",
    "        List of tensors containing the ids of the cells. The length of the list should be equal to the maximum rank.\n",
    "    names: list[str]\n",
    "        List of names of the matrices in the batch. They should appear in the format f\"{name}{i}\" where i is the rank of the matrix.\n",
    "    rank: int\n",
    "        The rank over which you are batching.\n",
    "    max_rank: int\n",
    "        The maximum rank of the matrices.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch_geometric.data.Data\n",
    "        The output data with the reduced matrices.\n",
    "    \"\"\"\n",
    "    for i in range(max_rank+1):\n",
    "        for name in names:\n",
    "            if f\"{name}{i}\" in batch.keys():\n",
    "                # matrix = change_sparse(batch[f\"{name}{i}\"])\n",
    "                matrix = batch[f\"{name}{i}\"]\n",
    "                if i==rank:\n",
    "                    matrix = torch.index_select(matrix, 1, cells_ids[i])\n",
    "                else:\n",
    "                    matrix = torch.index_select(matrix, 0, cells_ids[i])\n",
    "                    matrix = torch.index_select(matrix, 1, cells_ids[i])\n",
    "                batch[f\"{name}{i}\"] = matrix\n",
    "    return batch\n",
    "\n",
    "def reduce_neighborhoods(batch, rank=0, remove_self_loops=True):\n",
    "    \"\"\" Reduce the neighborhoods of the cells in the batch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: torch_geometric.data.Data\n",
    "        The input data.\n",
    "    rank: int\n",
    "        The rank of the cells to batch over.\n",
    "    remove_self_loops: bool\n",
    "        Whether to remove self loops from the edge_index.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch_geometric.data.Data\n",
    "        The output data with the reduced neighborhoods.\n",
    "    \"\"\"\n",
    "    is_hypergraph = False\n",
    "    if hasattr(batch, 'incidence_hyperedges'):\n",
    "        is_hypergraph = True\n",
    "        max_rank = 1\n",
    "    else:\n",
    "        max_rank = len([key for key in batch.keys() if \"incidence\" in key])-1\n",
    "    \n",
    "    if rank > max_rank:\n",
    "        raise ValueError(f\"Rank {rank} is greater than the maximum rank {max_rank} in the dataset.\")\n",
    "    \n",
    "    cells_ids = [None for _ in range(max_rank+1)]\n",
    "    \n",
    "    # the indices of the cells selected by the NeighborhoodLoader are saved in the batch in the attribute n_id\n",
    "    cells_ids[rank] = batch.n_id\n",
    "    \n",
    "    if rank == 0:\n",
    "        cells_ids[0] = batch.n_id\n",
    "    else:\n",
    "        cells_ids[0] = get_node_indices(batch, cells_ids, rank, is_hypergraph)\n",
    "        \n",
    "    batch, cells_ids = reduce_higher_ranks_incidences(batch, cells_ids, rank, max_rank, is_hypergraph)\n",
    "\n",
    "    batch = reduce_matrices(batch, \n",
    "                            cells_ids, \n",
    "                            names=['down_laplacian_', 'up_laplacian_', 'hodge_laplacian_', 'temp_'],\n",
    "                            rank=rank,\n",
    "                            max_rank=max_rank)\n",
    "                \n",
    "    # reduce the feature matrices\n",
    "    for i in range(max_rank+1):\n",
    "        if i != rank:\n",
    "            if f\"x_{i}\" in batch.keys():\n",
    "                batch[f\"x_{i}\"] = batch[f\"x_{i}\"][cells_ids[i]]\n",
    "            \n",
    "    # change the temp matrices back to adjacency\n",
    "    for i in range(max_rank+1):\n",
    "        if f\"temp_{i}\" in batch.keys():\n",
    "            batch[f\"adjacency_{i}\"] = batch[f\"temp_{i}\"]\n",
    "            del batch[f\"temp_{i}\"]\n",
    "            \n",
    "    # fix edge_index\n",
    "    if not is_hypergraph:\n",
    "        adjacency_0 = batch.adjacency_0.coalesce()\n",
    "        edge_index = adjacency_0.indices()\n",
    "        if remove_self_loops:\n",
    "            edge_index = torch_geometric.utils.remove_self_loops(edge_index)[0]\n",
    "        batch.edge_index = edge_index\n",
    "    \n",
    "    # fix x\n",
    "    batch.x = batch[f\"x_0\"]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "class ReduceNeighborhoods():\n",
    "    \"\"\" Reduce the neighborhoods of the cells in the batch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rank: int\n",
    "        The rank of the cells to batch over.\n",
    "    remove_self_loops: bool\n",
    "        Whether to remove self loops from the edge_index.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rank=0, remove_self_loops=True):\n",
    "        self.rank = rank\n",
    "        self.remove_self_loops = remove_self_loops\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        \"\"\" Call reduce_neighborhoods.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch: torch_geometric.data.Data\n",
    "            The input data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch_geometric.data.Data\n",
    "            The output data with the reduced neighborhoods.\n",
    "        \"\"\"\n",
    "        return reduce_neighborhoods(batch, self.rank, self.remove_self_loops)\n",
    "\n",
    "class NeighborLoaderWrapper(NeighborLoader):\n",
    "    \"\"\" NeighborLoader with get_sampled_neighborhood.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: torch_geometric.data.Dataset\n",
    "        The input dataset.\n",
    "    rank: int\n",
    "        The rank of the cells to batch over.\n",
    "    **kwargs: dict\n",
    "        Additional arguments for the NeighborLoader.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, rank=0, **kwargs):\n",
    "        is_hypergraph = hasattr(data, 'incidence_hyperedges')\n",
    "        data = get_sampled_neighborhood(data, rank, is_hypergraph)\n",
    "        # This workaround is needed because torch_geometric treats any attribute of data with adj in the name differently and it raises errors.\n",
    "        data = workaround_adj(data)\n",
    "        if 'num_neighbors' in kwargs.keys():\n",
    "            if len(kwargs['num_neighbors']) > 1:\n",
    "                raise NotImplementedError(\"NeighborLoaderWrapper only supports one-hop neighborhood selection.\")\n",
    "        super(NeighborLoaderWrapper, self).__init__(data, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topobenchmarkx.data.utils.utils import load_manual_graph\n",
    "\n",
    "cfg = compose(config_name=\"run.yaml\", \n",
    "              overrides=[\"dataset=graph/manual_dataset\", \"model=simplicial/san\"], \n",
    "              return_hydra_config=True)\n",
    "data = load_manual_graph()\n",
    "preprocessed_dataset = PreProcessor(data, './', cfg['transforms'])\n",
    "data = preprocessed_dataset[0]\n",
    "print(data)\n",
    "plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shape is a list, it breaks everything if we keep it\n",
    "# TODO: add somehow to workaround\n",
    "if hasattr(data, \"shape\"):\n",
    "    del data[\"shape\"]\n",
    "    \n",
    "\n",
    "# Training, validation and split idxs should be defined somewhere, here we use a toy example\n",
    "rank = 1\n",
    "if hasattr(data, \"x_hyperedges\") and rank==1:\n",
    "    n_cells = data.x_hyperedges.shape[0]\n",
    "else:\n",
    "    n_cells = data[f'x_{rank}'].shape[0]\n",
    "\n",
    "train_prop = 0.5\n",
    "n_train = int(train_prop * n_cells)\n",
    "train_mask = torch.zeros(n_cells, dtype=torch.bool)\n",
    "train_mask[:n_train] = 1\n",
    "\n",
    "if rank != 0:\n",
    "    y = torch.zeros(n_cells, dtype=torch.long)\n",
    "    data.y = y\n",
    "batch_size = 2\n",
    "\n",
    "# num_neighbors controls also the number of hops (for 2 hops do num_neighbors=[-1, -1])\n",
    "reduce = ReduceNeighborhoods(rank=rank, remove_self_loops=True)\n",
    "\n",
    "loader = NeighborLoaderWrapper(data,\n",
    "                               rank=rank,\n",
    "                               num_neighbors=[-1],\n",
    "                               input_nodes=train_mask,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               transform=reduce)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.n_id)\n",
    "    print(batch.edge_index)\n",
    "    if hasattr(batch, 'incidence_hyperedges'):\n",
    "        print(batch.incidence_hyperedges.to_dense())\n",
    "    else:\n",
    "        print(batch.incidence_3.to_dense())\n",
    "        print(batch.incidence_2.to_dense())\n",
    "        print(batch.incidence_1.to_dense())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# num_neighbors controls also the number of hops (for 2 hops do num_neighbors=[-1, -1])\n",
    "reduce = ReduceNeighborhoods(rank=rank, remove_self_loops=True)\n",
    "\n",
    "loader = NeighborLoaderWrapper(data,\n",
    "                               rank=rank,\n",
    "                               num_neighbors=[-1],\n",
    "                               input_nodes=train_mask,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               transform=reduce)\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.n_id)\n",
    "    print(batch.edge_index)\n",
    "    if hasattr(batch, 'incidence_hyperedges'):\n",
    "        print(batch.incidence_hyperedges.to_dense())\n",
    "    else:\n",
    "        print(batch.incidence_3.to_dense())\n",
    "        print(batch.incidence_2.to_dense())\n",
    "        print(batch.incidence_1.to_dense())\n",
    "    break\n",
    "\n",
    "plot_graph(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_simplicial_complex(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"run.yaml\", \n",
    "              overrides=[\"dataset=graph/cocitation_cora\", \"model=hypergraph/allsettransformer\"], \n",
    "              return_hydra_config=True)\n",
    "graph_loader = GraphLoader(cfg.dataset.loader.parameters)\n",
    "dataset, dataset_dir = graph_loader.load()\n",
    "preprocessed_dataset = PreProcessor(dataset, './', cfg['transforms'])\n",
    "data = preprocessed_dataset[0]\n",
    "# shape is a list, it breaks everything if we keep it\n",
    "# TODO: add somehow to workaround\n",
    "if hasattr(data, \"shape\"):\n",
    "    del data[\"shape\"]\n",
    "    \n",
    "\n",
    "# Training, validation and split idxs should be defined somewhere, here we use a toy example\n",
    "rank = 1\n",
    "if hasattr(data, \"x_hyperedges\") and rank==1:\n",
    "    n_cells = data.x_hyperedges.shape[0]\n",
    "else:\n",
    "    n_cells = data[f'x_{rank}'].shape[0]\n",
    "\n",
    "train_prop = 0.5\n",
    "n_train = int(train_prop * n_cells)\n",
    "train_mask = torch.zeros(n_cells, dtype=torch.bool)\n",
    "train_mask[:n_train] = 1\n",
    "\n",
    "if rank != 0:\n",
    "    y = torch.zeros(n_cells, dtype=torch.long)\n",
    "    data.y = y\n",
    "batch_size = 1\n",
    "\n",
    "# num_neighbors controls also the number of hops (for 2 hops do num_neighbors=[-1, -1])\n",
    "reduce = ReduceNeighborhoods(rank=rank, remove_self_loops=True)\n",
    "\n",
    "loader = NeighborLoaderWrapper(data,\n",
    "                               rank=rank,\n",
    "                               num_neighbors=[-1],\n",
    "                               input_nodes=train_mask,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               transform=reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(batch.n_id)\n",
    "    print(batch.edge_index)\n",
    "    if hasattr(batch, 'incidence_hyperedges'):\n",
    "        print(batch.incidence_hyperedges.to_dense())\n",
    "    else:\n",
    "        print(batch.incidence_3.to_dense())\n",
    "        print(batch.incidence_2.to_dense())\n",
    "        print(batch.incidence_1.to_dense())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in loader:\n",
    "#     plot_graph(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(data, 'incidence_3'):\n",
    "    del data['incidence_3']\n",
    "if hasattr(data, 'x_3'):\n",
    "    del data['x_3']\n",
    "for key in list(data.keys()):\n",
    "    if 'laplacian' in key or 'temp' in key or 'mask' in key or 'hyperedges' in key:\n",
    "        del data[key]\n",
    "\n",
    "incidence_3 = torch.tensor([[],[]]).to_sparse()\n",
    "incidence_2 = torch.tensor([[1,0],[1,0],[1,0],[0,0],[0,1],[0,1],[0,1]]).float().to_sparse()\n",
    "incidence_1 = torch.tensor([[1,0,1,0,0,0,0],[1,1,0,0,0,0,0],[0,1,1,1,0,0,0],[0,0,0,1,1,0,1],[0,0,0,0,1,1,0],[0,0,0,0,0,1,1]]).float().to_sparse()\n",
    "incidence_0 = torch.tensor([[1,1,1,1,1,1]]).float().to_sparse()\n",
    "data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0\n",
    "\n",
    "data['incidence_3'] = incidence_3\n",
    "data['incidence_2'] = incidence_2\n",
    "data['incidence_1'] = incidence_1\n",
    "data['incidence_0'] = incidence_0\n",
    "\n",
    "data['x_3'] = torch.tensor([]).float()\n",
    "data['x_2'] = torch.tensor([[1,0],[0,1]]).float()\n",
    "data['x_1'] = torch.tensor([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1],[1,0,0]]).float()\n",
    "data['x_0'] = torch.tensor([[1,0,0,0,0,0],[0,1,0,0,0,0],[0,0,1,0,0,0],[0,0,0,1,0,0],[0,0,0,0,1,0],[0,0,0,0,0,1]]).float()\n",
    "data['x'] = data[f'x_{rank}']\n",
    "data['y'] = torch.zeros(data[f'x_{rank}'].shape[0], dtype=torch.long)\n",
    "\n",
    "data['edge_index'] = torch.tensor([[0,0,1,1,2,2,2,3,3,3,4,4,5,5],[1,2,0,2,0,1,3,2,4,5,3,5,3,4]])\n",
    "data['temp_0'] = torch.sparse_coo_tensor(data['edge_index'], torch.ones(data['edge_index'].shape[1]), data['x_0'].shape)\n",
    "print(data)\n",
    "plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_neighbors controls also the number of hops (for 2 hops do num_neighbors=[-1, -1])\n",
    "reduce = ReduceNeighborhoods(rank=rank, remove_self_loops=True)\n",
    "batch_size = 1\n",
    "loader = NeighborLoaderWrapper(data,\n",
    "                               rank=rank,\n",
    "                               num_neighbors=[-1],\n",
    "                               input_nodes=train_mask,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               transform=reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(loader):\n",
    "    if i==2:\n",
    "        print(batch.adjacency_0.to_dense())\n",
    "        plot_graph(batch)\n",
    "        print(batch)\n",
    "        print(batch.n_id)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_3 = torch.tensor([[1],[1],[1],[1]]).float().to_sparse()\n",
    "incidence_2 = torch.tensor([[1,0,1,0],[1,1,0,0],[0,1,1,0],[0,0,1,1],[1,0,0,1],[0,1,0,1]]).float().to_sparse()\n",
    "incidence_1 = torch.tensor([[1,1,1,0,0,0],[1,0,0,1,1,0],[0,1,0,0,1,1],[0,0,1,1,0,1]]).float().to_sparse()\n",
    "incidence_0 = torch.tensor([[1,1,1,1]]).float().to_sparse()\n",
    "\n",
    "x_3 = torch.tensor([[1,0]]).float()\n",
    "x_2 = torch.tensor([[1,0],[0,1],[1,1],[0,0]]).float()\n",
    "x_1 = torch.tensor([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]]).float()\n",
    "x_0 = torch.tensor([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]).float()\n",
    "\n",
    "rank = 2\n",
    "\n",
    "data['incidence_3'] = incidence_3\n",
    "data['incidence_2'] = incidence_2\n",
    "data['incidence_1'] = incidence_1\n",
    "data['incidence_0'] = incidence_0\n",
    "\n",
    "data['x_3'] = x_3\n",
    "data['x_2'] = x_2\n",
    "data['x_1'] = x_1\n",
    "data['x_0'] = x_0\n",
    "data['x'] = data[f'x_{rank}']\n",
    "data['y'] = torch.zeros(data[f'x_{rank}'].shape[0], dtype=torch.long)\n",
    "\n",
    "data['edge_index'] = torch.tensor([[0,0,0,1,1,1,2,2,2,3,3,3],[1,2,3,0,2,3,0,1,3,0,1,2]])\n",
    "data['temp_0'] = torch.sparse_coo_tensor(data['edge_index'], torch.ones(data['edge_index'].shape[1]), data['x_0'].shape)\n",
    "print(data)\n",
    "plot_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_neighbors controls also the number of hops (for 2 hops do num_neighbors=[-1, -1])\n",
    "reduce = ReduceNeighborhoods(rank=rank, remove_self_loops=True)\n",
    "batch_size = 1\n",
    "loader = NeighborLoaderWrapper(data,\n",
    "                               rank=rank,\n",
    "                               num_neighbors=[-1],\n",
    "                               input_nodes=train_mask,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               transform=reduce)\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    if i==0:\n",
    "        plot_graph(batch)\n",
    "        print(batch)\n",
    "        print(batch.n_id)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
