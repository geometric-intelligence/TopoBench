{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On-Disk Learning Part 2: Advanced Techniques\n",
    "\n",
    "**Optimize your research workflow with intelligent caching and storage options**\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- ‚úÖ DAG-based incremental caching (2-3√ó faster iteration)\n",
    "- ‚úÖ Storage backend options (files vs mmap)\n",
    "- ‚úÖ Parallel processing (3-4√ó speedup)\n",
    "- ‚úÖ Best practices for iterative experimentation\n",
    "\n",
    "**Time:** 20-25 minutes  \n",
    "**Prerequisites:** Complete Part 1 first\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Iteration Problem\n",
    "\n",
    "Research involves testing multiple transform combinations:\n",
    "\n",
    "### Without Caching\n",
    "```python\n",
    "# Baseline\n",
    "config1 = {\"clique_lifting\": {...}}  # 40 minutes\n",
    "\n",
    "# Add feature A  \n",
    "config2 = {\"clique_lifting\": {...}, \"feature_A\": {...}}  # 54 minutes (reprocesses clique!)\n",
    "\n",
    "# Try feature B\n",
    "config3 = {\"clique_lifting\": {...}, \"feature_B\": {...}}  # 54 minutes (reprocesses clique!)\n",
    "\n",
    "# Total: 148 minutes, wasted 108 minutes reprocessing!\n",
    "```\n",
    "\n",
    "### With DAG Caching\n",
    "```python\n",
    "# Baseline\n",
    "config1 = {\"clique_lifting\": {...}}  # 40 minutes (cached!)\n",
    "\n",
    "# Add feature A\n",
    "config2 = {\"clique_lifting\": {...}, \"feature_A\": {...}}  # 14 minutes (reuses clique!)\n",
    "\n",
    "# Try feature B  \n",
    "config3 = {\"clique_lifting\": {...}, \"feature_B\": {...}}  # 14 minutes (reuses clique!)\n",
    "\n",
    "# Total: 68 minutes - saved 80 minutes (2.2√ó faster!)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from topobench.data.datasets import SyntheticGraphDataset\n",
    "from topobench.data.preprocessor import OnDiskInductivePreprocessor\n",
    "import time\n",
    "\n",
    "# Create dataset\n",
    "dataset = SyntheticGraphDataset(num_samples=2000, num_nodes=20, num_features=16, seed=42)\n",
    "print(f\"Dataset ready: {len(dataset)} graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DAG Caching in Action\n",
    "\n",
    "### Experiment 1: Baseline Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: SimplicialCliqueLifting (expensive transform)\n",
    "config1 = OmegaConf.create({\n",
    "    \"clique_lifting\": {\n",
    "        \"transform_type\": \"lifting\",\n",
    "        \"transform_name\": \"SimplicialCliqueLifting\",\n",
    "        \"complex_dim\": 2\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"[Experiment 1] Baseline transform\")\n",
    "start = time.time()\n",
    "\n",
    "preprocessor1 = OnDiskInductivePreprocessor(\n",
    "    dataset=dataset,\n",
    "    data_dir=\"./data/dag_demo\",\n",
    "    transforms_config=config1,\n",
    "    storage_backend=\"files\",  # Fast for development\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "time1 = time.time() - start\n",
    "print(f\"Time: {time1:.1f}s\")\n",
    "print(\"Transform cached at: ./data/dag_demo/transform_chain/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Add Feature Transform (Reuses Clique!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ProjectionSum (clique_lifting will be reused!)\n",
    "config2 = OmegaConf.create({\n",
    "    \"clique_lifting\": {  # Same config = cached!\n",
    "        \"transform_type\": \"lifting\",\n",
    "        \"transform_name\": \"SimplicialCliqueLifting\",\n",
    "        \"complex_dim\": 2\n",
    "    },\n",
    "    \"projection\": {  # NEW transform\n",
    "        \"transform_type\": \"feature\",\n",
    "        \"transform_name\": \"ProjectionSum\"\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"\\n[Experiment 2] Add ProjectionSum\")\n",
    "start = time.time()\n",
    "\n",
    "preprocessor2 = OnDiskInductivePreprocessor(\n",
    "    dataset=dataset,\n",
    "    data_dir=\"./data/dag_demo\",  # Same directory!\n",
    "    transforms_config=config2,\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "time2 = time.time() - start\n",
    "speedup = time1 / time2 if time2 > 0 else 0\n",
    "\n",
    "print(f\"Time: {time2:.1f}s\")\n",
    "print(f\"Speedup: {speedup:.1f}√ó (reused clique_lifting!)\")\n",
    "print(f\"Look for message: 'Reusing 1 cached transform(s)!' above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How It Works\n",
    "\n",
    "TopoBench creates unique cache directories:\n",
    "\n",
    "```\n",
    "data_dir/transform_chain/\n",
    "  DataTransform_0_abc123/  ‚Üê SimplicialCliqueLifting  \n",
    "  DataTransform_1_def456/  ‚Üê ProjectionSum\n",
    "```\n",
    "\n",
    "Cache key = **transform_id** (position) + **hash** (parameters)\n",
    "\n",
    "- Same config ‚Üí reuse cache ‚úÖ\n",
    "- Changed params ‚Üí new cache ‚úÖ  \n",
    "- Different position ‚Üí new cache ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Storage Backends: Files vs Mmap\n",
    "\n",
    "TopoBench offers two storage backends:\n",
    "\n",
    "### Files Backend (Development)\n",
    "- ‚ö° **Fast iteration** (3-4√ó with parallel)\n",
    "- üìä **Clear DAG benefits** visible\n",
    "- üíæ **Larger disk** usage (~4-5√ó more)\n",
    "- üéØ **Use when:** Experimenting, iterating\n",
    "\n",
    "### Mmap Backend (Production)  \n",
    "- üíæ **Compressed** (4-5√ó smaller)\n",
    "- üöÄ **Fast I/O** during training\n",
    "- ‚ö†Ô∏è **Slower preprocessing** (compression overhead)\n",
    "- üéØ **Use when:** Final deployment, limited disk\n",
    "\n",
    "### Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small dataset for comparison\n",
    "small_dataset = SyntheticGraphDataset(num_samples=500, num_nodes=20)\n",
    "config = OmegaConf.create({\"clique\": {\"transform_type\": \"lifting\", \"transform_name\": \"SimplicialCliqueLifting\", \"complex_dim\": 2}})\n",
    "\n",
    "# Files backend\n",
    "print(\"Files backend (development):\")\n",
    "start = time.time()\n",
    "preprocessor_files = OnDiskInductivePreprocessor(\n",
    "    dataset=small_dataset,\n",
    "    data_dir=\"./data/compare_files\",\n",
    "    transforms_config=config,\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=4\n",
    ")\n",
    "time_files = time.time() - start\n",
    "print(f\"  Time: {time_files:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mmap backend  \n",
    "print(\"\\nMmap backend (production):\")\n",
    "start = time.time()\n",
    "preprocessor_mmap = OnDiskInductivePreprocessor(\n",
    "    dataset=small_dataset,\n",
    "    data_dir=\"./data/compare_mmap\",\n",
    "    transforms_config=config,\n",
    "    storage_backend=\"mmap\",\n",
    "    compression=\"lz4\",\n",
    "    num_workers=1  # Use 1 worker with mmap\n",
    ")\n",
    "time_mmap = time.time() - start\n",
    "print(f\"  Time: {time_mmap:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check disk usage\n",
    "import subprocess\n",
    "try:\n",
    "    files_size = subprocess.check_output(['du', '-sh', './data/compare_files']).decode().split()[0]\n",
    "    mmap_size = subprocess.check_output(['du', '-sh', './data/compare_mmap']).decode().split()[0]\n",
    "    print(f\"\\nDisk usage:\")\n",
    "    print(f\"  Files: {files_size}\")\n",
    "    print(f\"  Mmap:  {mmap_size} (compressed)\")\n",
    "except:\n",
    "    print(\"\\n(Disk usage check requires Unix du command)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Guide\n",
    "\n",
    "**Choose FILES when:**\n",
    "- ‚úÖ Iterating on transform combinations\n",
    "- ‚úÖ Prototyping pipelines\n",
    "- ‚úÖ Disk space is abundant\n",
    "- ‚úÖ Want fastest development cycle\n",
    "\n",
    "**Choose MMAP when:**\n",
    "- ‚úÖ Finalizing pipeline for production\n",
    "- ‚úÖ Disk space is limited  \n",
    "- ‚úÖ Training repeatedly on same data\n",
    "- ‚úÖ Want optimal storage + I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Parallel Processing\n",
    "\n",
    "Enable multi-core processing for faster preprocessing:\n",
    "\n",
    "### Performance with Different Worker Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different worker counts\n",
    "test_dataset = SyntheticGraphDataset(num_samples=1000, num_nodes=20)\n",
    "config = OmegaConf.create({\"clique\": {\"transform_type\": \"lifting\", \"transform_name\": \"SimplicialCliqueLifting\", \"complex_dim\": 2}})\n",
    "\n",
    "for workers in [1, 2, 4]:\n",
    "    print(f\"\\nTesting {workers} worker(s):\")\n",
    "    start = time.time()\n",
    "    \n",
    "    preprocessor = OnDiskInductivePreprocessor(\n",
    "        dataset=test_dataset,\n",
    "        data_dir=f\"./data/parallel_{workers}\",\n",
    "        transforms_config=config,\n",
    "        storage_backend=\"files\",\n",
    "        num_workers=workers,\n",
    "        force_reload=True  # Reprocess to measure time\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"  Time: {elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "\n",
    "```python\n",
    "# Development: Use parallel processing with files\n",
    "OnDiskInductivePreprocessor(\n",
    "    ...,\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=7  # Use N-1 cores\n",
    ")\n",
    "\n",
    "# Production: Use mmap with 1 worker\n",
    "OnDiskInductivePreprocessor(\n",
    "    ...,\n",
    "    storage_backend=\"mmap\",\n",
    "    compression=\"lz4\",\n",
    "    num_workers=1  # Compression is sequential\n",
    ")\n",
    "```\n",
    "\n",
    "**Why 1 worker with mmap?** Compression creates a bottleneck that limits parallel speedup to ~2√ó instead of 3-4√ó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Complete Workflow Example\n",
    "\n",
    "### Realistic Research Scenario\n",
    "\n",
    "Goal: Find best transform combination for your task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Development (files backend + parallel)\n",
    "dataset = SyntheticGraphDataset(num_samples=1000, num_nodes=30)\n",
    "\n",
    "# Baseline\n",
    "config_baseline = OmegaConf.create({\n",
    "    \"lifting\": {\"transform_type\": \"lifting\", \"transform_name\": \"SimplicialCliqueLifting\", \"complex_dim\": 2}\n",
    "})\n",
    "\n",
    "preprocessor_baseline = OnDiskInductivePreprocessor(\n",
    "    dataset=dataset,\n",
    "    data_dir=\"./data/workflow\",\n",
    "    transforms_config=config_baseline,\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=4\n",
    ")\n",
    "print(\"Baseline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try variant A (reuses lifting!)\n",
    "config_A = OmegaConf.create({\n",
    "    \"lifting\": {\"transform_type\": \"lifting\", \"transform_name\": \"SimplicialCliqueLifting\", \"complex_dim\": 2},\n",
    "    \"features\": {\"transform_type\": \"feature\", \"transform_name\": \"ProjectionSum\"}\n",
    "})\n",
    "\n",
    "preprocessor_A = OnDiskInductivePreprocessor(\n",
    "    dataset=dataset,\n",
    "    data_dir=\"./data/workflow\",  # Reuse cache!\n",
    "    transforms_config=config_A,\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=4\n",
    ")\n",
    "print(\"Variant A created (reused lifting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Production (convert best to mmap)\n",
    "# Assuming variant A won, convert to compressed format\n",
    "preprocessor_production = OnDiskInductivePreprocessor(\n",
    "    dataset=dataset,\n",
    "    data_dir=\"./data/production\",\n",
    "    transforms_config=config_A,  # Best config\n",
    "    storage_backend=\"mmap\",\n",
    "    compression=\"lz4\",\n",
    "    num_workers=1\n",
    ")\n",
    "print(\"Production version created (compressed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Summary\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. ‚úÖ **DAG caching:** Automatically reuses transforms (2-3√ó faster iteration)\n",
    "2. ‚úÖ **Storage backends:** Files (fast dev) vs Mmap (small storage)\n",
    "3. ‚úÖ **Parallel processing:** 3-4√ó speedup with multiple workers\n",
    "4. ‚úÖ **Workflows:** Development ‚Üí experimentation ‚Üí production\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Feature | Benefit | When to Use |\n",
    "|---------|---------|-------------|\n",
    "| **DAG Caching** | 2-3√ó faster | Always (automatic) |\n",
    "| **Files Backend** | Fast iteration | Development |\n",
    "| **Mmap Backend** | 4-5√ó smaller | Production |\n",
    "| **Parallel (files)** | 3-4√ó speedup | Large datasets |\n",
    "\n",
    "### Recommended Workflow\n",
    "\n",
    "```python\n",
    "# 1. Development: Fast iteration\n",
    "dev = OnDiskInductivePreprocessor(\n",
    "    storage_backend=\"files\",\n",
    "    num_workers=7\n",
    ")\n",
    "\n",
    "# 2. Experiment: Try variations (DAG cache speeds this up!)\n",
    "# ... iterate on transforms ...\n",
    "\n",
    "# 3. Production: Convert final pipeline\n",
    "prod = OnDiskInductivePreprocessor(\n",
    "    storage_backend=\"mmap\",\n",
    "    compression=\"lz4\",\n",
    "    num_workers=1\n",
    ")\n",
    "```\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **`README_DAG_CACHING.md`**: Complete technical reference\n",
    "- **`SPEED_VS_COMPRESSION_TRADEOFF.md`**: Detailed backend comparison\n",
    "- **GitHub Issues**: Ask questions and report issues\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've mastered TopoBench's on-disk preprocessing.\n",
    "\n",
    "You can now:\n",
    "- Train on datasets beyond RAM ‚úÖ\n",
    "- Iterate rapidly with DAG caching ‚úÖ  \n",
    "- Choose the right backend for each phase ‚úÖ\n",
    "- Optimize preprocessing with parallel workers ‚úÖ\n",
    "\n",
    "**Happy researching!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
