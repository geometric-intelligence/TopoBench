#!/usr/bin/env bash

# Define log files
LOG_FILE="scripts/script_output.log"
ERROR_LOG_FILE="scripts/script_error.log"
FAILED_LOG_FILE="scripts/failed_runs.log"

# Clear previous log files
> "$LOG_FILE"
> "$ERROR_LOG_FILE"
> "$FAILED_LOG_FILE"

# GPU configuration
NUM_GPUS=4
GPU_DEVICES=(0 1 2 3)

# Data seeds to distribute across GPUs
# GPU 0: seed 0 (separate job)
# GPU 0: seed 3 (separate job)
# GPU 1: seed 5
# GPU 2: seed 7
# GPU 3: seed 9
SEEDS_GPU_0_JOB1="0"
SEEDS_GPU_0_JOB2="3"
SEEDS_GPU_1="5"
SEEDS_GPU_2="7"
SEEDS_GPU_3="9"

# Function to run a command and check for failure
run_command() {
	local cmd="$1"
	local gpu_id="$2"
	local seeds="$3"
	local log_file="scripts/script_output_gpu${gpu_id}_seeds${seeds}.log"
	local err_file="scripts/script_error_gpu${gpu_id}_seeds${seeds}.log"
	
	# Run the command and capture the output and error
	{ eval "$cmd" 2>&1 | tee -a "$log_file"; } 2>> "$err_file"
	local exit_code=${PIPESTATUS[0]}
	
	# Append to main logs
	cat "$log_file" >> "$LOG_FILE"
	cat "$err_file" >> "$ERROR_LOG_FILE"
	
	# Check if the command failed
	if [ $exit_code -ne 0 ]; then
		echo "Command failed on GPU $gpu_id (seeds $seeds): $cmd" >> "$FAILED_LOG_FILE"
		echo "Check $err_file for details." >> "$FAILED_LOG_FILE"
	fi
	
	return $exit_code
}

commands=(
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
# 'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
# 'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
)

# Iterate over the commands and run them in parallel across GPUs with different seeds
for cmd in "${commands[@]}"; do
	echo "========================================"
	echo "Processing command: ${cmd:0:100}..."
	
	# Launch jobs on GPUs in parallel with different seed splits
	# GPU 0: seed 0 (first job)
	if [ -n "$SEEDS_GPU_0_JOB1" ]; then
		modified_cmd="${cmd//dataset.split_params.data_seed=0,3,5,7,9/dataset.split_params.data_seed=$SEEDS_GPU_0_JOB1}"
		modified_cmd="${modified_cmd//trainer.devices=\\\[6\\\]/trainer.devices=\\\[${GPU_DEVICES[0]}\\\]}"
		echo "  -> GPU ${GPU_DEVICES[0]} with seed $SEEDS_GPU_0_JOB1"
		run_command "$modified_cmd" "${GPU_DEVICES[0]}" "$SEEDS_GPU_0_JOB1" &
	fi
	
	# GPU 0: seed 3 (second job, runs simultaneously on same GPU)
	if [ -n "$SEEDS_GPU_0_JOB2" ]; then
		modified_cmd="${cmd//dataset.split_params.data_seed=0,3,5,7,9/dataset.split_params.data_seed=$SEEDS_GPU_0_JOB2}"
		modified_cmd="${modified_cmd//trainer.devices=\\\[6\\\]/trainer.devices=\\\[${GPU_DEVICES[0]}\\\]}"
		echo "  -> GPU ${GPU_DEVICES[0]} with seed $SEEDS_GPU_0_JOB2"
		run_command "$modified_cmd" "${GPU_DEVICES[0]}" "$SEEDS_GPU_0_JOB2" &
	fi
	
	# GPU 1: seed 5
	if [ -n "$SEEDS_GPU_1" ]; then
		modified_cmd="${cmd//dataset.split_params.data_seed=0,3,5,7,9/dataset.split_params.data_seed=$SEEDS_GPU_1}"
		modified_cmd="${modified_cmd//trainer.devices=\\\[6\\\]/trainer.devices=\\\[${GPU_DEVICES[1]}\\\]}"
		echo "  -> GPU ${GPU_DEVICES[1]} with seeds $SEEDS_GPU_1"
		run_command "$modified_cmd" "${GPU_DEVICES[1]}" "$SEEDS_GPU_1" &
	fi
	
	# GPU 2: seed 7
	if [ -n "$SEEDS_GPU_2" ]; then
		modified_cmd="${cmd//dataset.split_params.data_seed=0,3,5,7,9/dataset.split_params.data_seed=$SEEDS_GPU_2}"
		modified_cmd="${modified_cmd//trainer.devices=\\\[6\\\]/trainer.devices=\\\[${GPU_DEVICES[2]}\\\]}"
		echo "  -> GPU ${GPU_DEVICES[2]} with seeds $SEEDS_GPU_2"
		run_command "$modified_cmd" "${GPU_DEVICES[2]}" "$SEEDS_GPU_2" &
	fi
	
	# GPU 3: seed 9
	if [ -n "$SEEDS_GPU_3" ]; then
		modified_cmd="${cmd//dataset.split_params.data_seed=0,3,5,7,9/dataset.split_params.data_seed=$SEEDS_GPU_3}"
		modified_cmd="${modified_cmd//trainer.devices=\\\[6\\\]/trainer.devices=\\\[${GPU_DEVICES[3]}\\\]}"
		echo "  -> GPU ${GPU_DEVICES[3]} with seeds $SEEDS_GPU_3"
		run_command "$modified_cmd" "${GPU_DEVICES[3]}" "$SEEDS_GPU_3" &
	fi
	
	# Wait for all parallel jobs for this command to complete
	echo "  Waiting for all GPUs to complete this command..."
	wait
	echo "  Command completed!"
done

echo "========================================"
echo "All commands completed!"
