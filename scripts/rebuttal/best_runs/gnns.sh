#!/usr/bin/env bash

# Define log files
LOG_FILE="scripts/script_output.log"
ERROR_LOG_FILE="scripts/script_error.log"
FAILED_LOG_FILE="scripts/failed_runs.log"

# Clear previous log files
> "$LOG_FILE"
> "$ERROR_LOG_FILE"
> "$FAILED_LOG_FILE"

# Function to run a command and check for failure
run_command() {
	local cmd="$1"
	# Run the command and capture the output and error
	{ eval "$cmd" 2>&1 | tee -a "$LOG_FILE"; } 2>> "$ERROR_LOG_FILE"
	# Check if the command failed
	if [ ${PIPESTATUS[0]} -ne 0 ]; then
		echo "Command failed: $cmd" >> "$FAILED_LOG_FILE"
		echo "Check $ERROR_LOG_FILE for details." >> "$FAILED_LOG_FILE"
	fi
}

commands=(
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=graph/MUTAG model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,MUTAG,graph
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_orientation,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0'] evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_betti_numbers,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] dataset.loader.parameters.slice=False experiment=hopse_m_gnn_mantra transforms.redefine_simplicial_neighborhoods.neighborhoods=['up_adjacency-0']  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,MANTRA_name,simplicial
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=256 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/ZINC model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE] transforms.one_hot_node_degree_features.degrees_field=x transforms.one_hot_node_degree_features.features_field=x experiment=hopse_m_gnn_cell_zinc  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,ZINC,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI109 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI109,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/NCI1 model=graph/hopse_gat model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,NCI1,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gin model.backbone.num_layers=4 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GIN","graph"] logger.wandb.project=GNNs_times --multirun' # GIN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=4 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gcn model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GCN","graph"] logger.wandb.project=GNNs_times --multirun' # GCN,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE,LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE,ElstaticPE,HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=128 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[RWSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[ElstaticPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=2 model.feature_encoder.out_channels=32 model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 transforms.sann_encoding.neighborhoods=['up_adjacency-0'] transforms.sann_encoding.pe_types=[HKdiagSE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
'python -m topobench dataset=graph/PROTEINS model=graph/hopse_gat model.backbone.num_layers=1 model.feature_encoder.out_channels=64 model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 transforms.sann_encoding.neighborhoods=['up_adjacency-0','down_incidence-1'] transforms.sann_encoding.pe_types=[LapPE]  experiment=hopse_m_gnn_cell dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=\[6\] callbacks.early_stopping.patience=10 logger.wandb.tags=["GAT","graph"] logger.wandb.project=GNNs_times --multirun' # GAT,PROTEINS,graph
)

# Iterate over the commands and run them
for cmd in "${commands[@]}"; do
	echo "Running: $cmd"
	run_command "$cmd"
done
