# betti_numbers
python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gin experiment=hopse_m_gnn_mantra transforms.sann_encoding.pe_types=['RWSE','ElstaticPE','HKdiagSE','LapPE'] model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=64 model.readout.hidden_dim=64 model.feature_encoder.out_channels=64 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=256 dataset.loader.parameters.manifold_dim=2 evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gin","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gin,MANTRA_betti_numbers,simplicial
python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gat experiment=hopse_m_gnn_mantra transforms.sann_encoding.pe_types=['RWSE','ElstaticPE','HKdiagSE','LapPE'] model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=128 model.readout.hidden_dim=128 model.feature_encoder.out_channels=128 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=256 dataset.loader.parameters.manifold_dim=2 evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gat","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gat,MANTRA_betti_numbers,simplicial
python -m topobench dataset=simplicial/mantra_betti_numbers model=graph/hopse_gcn experiment=hopse_m_gnn_mantra transforms.sann_encoding.pe_types=['RWSE','ElstaticPE','HKdiagSE','LapPE'] model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 dataset.dataloader_params.batch_size=128 dataset.loader.parameters.manifold_dim=2 evaluator=betti_numbers  dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[7\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gcn","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gcn,MANTRA_betti_numbers,simplicial

# # mantra_name
# python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gat model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=256 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gat","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gat,MANTRA_name,simplicial
# python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gin model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=256 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gin","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gin,MANTRA_name,simplicial
# python -m topobench dataset=simplicial/mantra_name model=graph/hopse_gcn model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=128 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gcn","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gcn,MANTRA_name,simplicial

# # mantra_orientation
# python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gat model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=128 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gat","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gat,MANTRA_orientation,simplicial
# python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gin model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=64 model.readout.hidden_dim=64 model.feature_encoder.out_channels=64 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.001 dataset.dataloader_params.batch_size=128 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gin","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gin,MANTRA_orientation,simplicial
# python -m topobench dataset=simplicial/mantra_orientation model=graph/hopse_gcn model.feature_encoder.proj_dropout=0.25 model.backbone.hidden_channels=32 model.readout.hidden_dim=32 model.feature_encoder.out_channels=32 model.readout.readout_name=NoReadOut optimizer.parameters.weight_decay=0.0001 optimizer.parameters.lr=0.01 dataset.dataloader_params.batch_size=128 dataset.loader.parameters.manifold_dim=2   dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=250 trainer.check_val_every_n_epoch=5 trainer.devices=\[1\] callbacks.early_stopping.patience=10 logger.wandb.tags=["gcn","graph"] logger.wandb.project=HOPSE_rebuttal_mantra --multirun # gcn,MANTRA_orientation,simplicial


