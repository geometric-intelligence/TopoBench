#!/bin/bash

# Define log files
LOG_FILE="scripts/script_output.log"
ERROR_LOG_FILE="scripts/script_error.log"
FAILED_LOG_FILE="scripts/failed_runs.log"

# Clear previous log files
> $LOG_FILE
> $ERROR_LOG_FILE
> $FAILED_LOG_FILE

# Function to run a command and check for failure
run_command() {
    local cmd="$1"
    
    # Run the command and capture the output and error
    { eval "$cmd" 2>&1 | tee -a "$LOG_FILE"; } 2>> "$ERROR_LOG_FILE"
    
    # Check if the command failed
    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        echo "Command failed: $cmd" >> "$FAILED_LOG_FILE"
        echo "Check $ERROR_LOG_FILE for details." >> "$FAILED_LOG_FILE"
    fi
}

# List of commands to execute
commands=(

'python -m topobench model=cell/cccn dataset=graph/MUTAG optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=32 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cccn dataset=graph/NCI1 optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.backbone.n_layers=4 model.readout.readout_name=NoReadOut model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cccn dataset=graph/NCI109 optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=4 model.readout.readout_name=NoReadOut model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cccn dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.backbone.n_layers=1 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=256 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cccn dataset=graph/ZINC optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x seed=42,3,5,23,150 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'

'python -m topobench model=cell/cwn dataset=graph/MUTAG optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.n_layers=2 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=32 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cwn dataset=graph/NCI1 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cwn dataset=graph/NCI109 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.n_layers=3 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cwn dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.backbone.n_layers=3 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=cell/cwn dataset=graph/ZINC optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.n_layers=2 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x seed=42,3,5,23,150 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'

'python -m topobench model=simplicial/sccnn_custom dataset=graph/MUTAG optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=1 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=32 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/sccnn_custom dataset=graph/NCI1 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.n_layers=2 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/sccnn_custom dataset=graph/NCI109 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.backbone.n_layers=2 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/sccnn_custom dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=1 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/sccnn_custom dataset=graph/ZINC optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x seed=42,3,5,23,150 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'

'python -m topobench model=simplicial/scn dataset=graph/MUTAG optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=3 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=64 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/scn dataset=graph/NCI1 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/scn dataset=graph/NCI109 optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/scn dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=2 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'
'python -m topobench model=simplicial/scn dataset=graph/ZINC optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.backbone.n_layers=4 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x seed=42,3,5,23,150 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing --multirun'


"python -m topobench model=cell/topotune model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=\[1-up_incidence-0,1-up_adjacency-1,1-down_incidence-2\] logger.wandb.project=TopoBench_preprocessing dataset=graph/MUTAG optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.layers=2 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=32 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 trainer.devices=\[1\] --multirun"
"python -m topobench model=cell/topotune model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=\[1-up_incidence-0,1-up_adjacency-1,1-down_incidence-2\] logger.wandb.project=TopoBench_preprocessing dataset=graph/NCI1 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.layers=4 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.devices=\[1\] --multirun"
"python -m topobench model=cell/topotune model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=\[1-up_incidence-0,1-up_adjacency-1,1-down_incidence-2\] logger.wandb.project=TopoBench_preprocessing dataset=graph/NCI109 optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.layers=3 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.devices=\[2\] --multirun"
"python -m topobench model=cell/topotune model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=\[1-up_incidence-0,1-up_adjacency-1,1-down_incidence-2\] logger.wandb.project=TopoBench_preprocessing dataset=graph/ZINC optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.backbone.layers=2 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 transforms.graph2cell_lifting.max_cell_length=10 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 trainer.devices=\[2\] --multirun"
"python -m topobench model=cell/topotune model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=\[1-up_incidence-0,1-up_adjacency-1,1-down_incidence-2\] logger.wandb.project=TopoBench_preprocessing dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.layers=4 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=1 trainer.max_epochs=500 dataset.split_params.data_seed=0,3,5,7,9 trainer.min_epochs=50 trainer.check_val_every_n_epoch=1 callbacks.early_stopping.patience=50 trainer.devices=\[4\] --multirun"

"python -m topobench dataset=graph/MUTAG model=simplicial/topotune model.feature_encoder.out_channels=128 model.tune_gnn=GIN model.backbone.GNN.num_layers=1 model.backbone.neighborhoods=[1-up_laplacian-0,1-up_incidence-0,1-down_incidence-1,1-down_laplacian-1,1-up_laplacian-1,1-up_incidence-1,1-down_incidence-2,1-down_laplacian-2] model.backbone.layers=3 dataset.split_params.data_seed=1,3,5,7,9 model.readout.readout_name=NoReadOut logger.wandb.project=TopoBench_preprocessing trainer.max_epochs=500 trainer.min_epochs=50 trainer.devices=[0] transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=64 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 optimizer.parameters.lr=0.001 --multirun"
"python -m topobench dataset=graph/NCI1 model=simplicial/topotune model.feature_encoder.out_channels=64 model.backbone.GNN.num_layers=1 model.tune_gnn=GIN model.backbone.neighborhoods=[1-up_laplacian-0,1-up_incidence-0,1-down_incidence-1,1-down_laplacian-1,1-up_laplacian-1,1-up_incidence-1,1-down_incidence-2,1-down_laplacian-2] model.backbone.layers=3 model.feature_encoder.proj_dropout=0.5 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 trainer.devices=[0] logger.wandb.project=TopoBench_preprocessing optimizer.parameters.lr=0.001 --multirun"
"python -m topobench model=simplicial/topotune dataset=graph/ZINC model.tune_gnn=GIN model.backbone.neighborhoods=[1-up_laplacian-0,1-up_incidence-0,1-down_incidence-1,1-down_laplacian-1,1-up_laplacian-1,1-up_incidence-1,1-down_incidence-2,1-down_laplacian-2] optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.backbone.layers=4 model.readout.readout_name=PropagateSignalDown transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=128 callbacks.early_stopping.min_delta=0.005 transforms.one_hot_node_degree_features.degrees_fields=x seed=42,3,5,23,150 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 logger.wandb.project=TopoBench_preprocessing trainer.devices=[0] --multirun"
"python -m topobench dataset=graph/NCI109 model=simplicial/topotune model.feature_encoder.out_channels=64 model.backbone.GNN.num_layers=1 model.tune_gnn=GIN model.backbone.neighborhoods=[1-up_laplacian-0,1-up_incidence-0,1-down_incidence-1,1-down_laplacian-1,1-up_laplacian-1,1-up_incidence-1,1-down_incidence-2,1-down_laplacian-2] model.backbone.layers=4 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 trainer.devices=[1] logger.wandb.project=TopoBench_preprocessing optimizer.parameters.lr=0.001 --multirun"
"python -m topobench dataset=graph/NCI109 model=simplicial/topotune model.feature_encoder.out_channels=64 model.backbone.GNN.num_layers=1 model.tune_gnn=GIN model.backbone.neighborhoods=[1-up_laplacian-0,1-up_incidence-0,1-down_incidence-1,1-down_laplacian-1,1-up_laplacian-1,1-up_incidence-1,1-down_incidence-2,1-down_laplacian-2] model.backbone.layers=4 model.readout.readout_name=NoReadOut transforms.graph2simplicial_lifting.signed=True model.feature_encoder.proj_dropout=0.25 dataset.dataloader_params.batch_size=128 dataset.split_params.data_seed=0,3,5,7,9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 callbacks.early_stopping.patience=10 trainer.devices=[1] logger.wandb.project=TopoBench_preprocessing optimizer.parameters.lr=0.001 --multirun"

)

# Iterate over the commands and run them
for cmd in "${commands[@]}"; do
    echo "Running: $cmd"
    run_command "$cmd"
done

