echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=1 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/khop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[7] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/cocitation_pubmed optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/amazon_ratings optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/roman_empire optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=1 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.001 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.01 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=32 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=64 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=2 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=3 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=5 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=0 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=3 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=5 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=7 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''
echo '================================='
echo 'Rerunning: python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun'
echo '---------------------------------'
python -m topobench model=hypergraph/unignn2 dataset=graph/PROTEINS optimizer.parameters.lr=0.1 model.feature_encoder.out_channels=128 model.readout.readout_name=PropagateSignalDown model.feature_encoder.proj_dropout=0.5 dataset.dataloader_params.batch_size=256 transforms=[liftings/graph2hypergraph/exclusive_hop] transforms.liftings.graph2hypergraph.k_value=10 dataset.split_params.data_seed=9 trainer.max_epochs=500 trainer.min_epochs=50 trainer.check_val_every_n_epoch=5 trainer.devices=[6] callbacks.early_stopping.patience=10 logger.wandb.project=hypergraph_liftings_main2 model.backbone.n_layers=2 --multirun
echo 'SUCCESS - Command finished.'
echo ''