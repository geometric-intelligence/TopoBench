{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJ_PREFIX = \"main_exp\"\n",
    "PROJ_TYPES = [\"SANN\", \"GPSE\"]\n",
    "PROJ_DS = [\n",
    "    \"NCI1\",\n",
    "    \"NCI109\",\n",
    "    \"MUTAG\",\n",
    "    \"PROTEINS\",\n",
    "    \"ZINC\",\n",
    "    \"IMDB-BINARY\",\n",
    "    \"IMDB-MULTI\",\n",
    "]\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api(overrides={\"base_url\": \"https://api.wandb.ai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "for project_dataset in PROJ_DS:\n",
    "    for project_type in PROJ_TYPES:\n",
    "        project_name = f\"{PROJ_PREFIX}_{project_type}_{project_dataset}\"\n",
    "        if project_name not in csv_names:\n",
    "            runs = api.runs(f\"{user}/{project_name}\")\n",
    "            try:\n",
    "                list(runs)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            summary_list, config_list, name_list = [], [], []\n",
    "            for run in runs:\n",
    "                # .summary contains the output keys/values for metrics like accuracy.\n",
    "                #  We call ._json_dict to omit large files\n",
    "                summary_list.append(run.summary._json_dict)\n",
    "\n",
    "                # .config contains the hyperparameters.\n",
    "                #  We remove special values that start with _.\n",
    "                config_list.append(\n",
    "                    {\n",
    "                        k: v\n",
    "                        for k, v in run.config.items()\n",
    "                        if not k.startswith(\"_\")\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # .name is the human-readable name of the run.\n",
    "                name_list.append(run.name)\n",
    "\n",
    "            runs_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"summary\": summary_list,\n",
    "                    \"config\": config_list,\n",
    "                    \"name\": name_list,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            runs_df.to_csv(f\"csv/{user}_{project_name}.csv\")\n",
    "        else:\n",
    "            runs_df = pd.read_csv(\n",
    "                f\"csv/{user}_{project_name}.csv\", index_col=0\n",
    "            )\n",
    "\n",
    "            for row in runs_df.iloc:\n",
    "                row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "                row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "    lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "    df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "    df_init = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"csv/*.csv\")\n",
    "df_list = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, index_col=0)\n",
    "    for row in df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "        row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "    lst = [i[\"summary\"] for i in df.iloc]\n",
    "    df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "    df_init = df.copy()\n",
    "\n",
    "    df_list.append(df_init)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\n",
    "    \"model\",\n",
    "    \"dataset\",\n",
    "    \"callbacks\",\n",
    "    \"paths\",\n",
    "    \"transforms\",\n",
    "    \"optimizer\",\n",
    "]\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/0rz4lf5s51bfpr4hwz5hx0kh0000gn/T/ipykernel_5972/1307283954.py:1: DtypeWarning: Columns (35,37,92,113,123,132,134,135,136,148,157,159,160,162,163,164,166,168,169,170,173,174,175,181,182,183,188,190,191,192,193,195,196,197,199,200,201,203,204,206,207,208,209,210,212,213,214,216,217,218,219,221,222,223,224,225,226,227,228,230,231,232,233,234,235,236,248,250,254,261,264,267,270) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('merged_csv/merged_normalized.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged_csv/merged_normalized.csv\")\n",
    "columns_to_eval = [\"transforms.sann_encoding.pe_types\"]\n",
    "for col in columns_to_eval:\n",
    "    df[col] = df[col].apply(lambda x: str(x).replace(\"nan\", \"None\"))\n",
    "    df[col] = df[col].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct model name based on each pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_name(row):\n",
    "    if isinstance(row[\"transforms.sann_encoding.pe_types\"], list):\n",
    "        return \"HOPSE_MANUAL_PE\"\n",
    "    elif row[\"model.model_name\"] == \"sann\":\n",
    "        if type(\n",
    "            row[\"transforms.sann_encoding.pretrain_model\"]\n",
    "        ) == float and pd.isna(row[\"transforms.sann_encoding.pretrain_model\"]):\n",
    "            return \"SANN\"\n",
    "        else:\n",
    "            return \"HOPSE_GPSE\"\n",
    "    else:\n",
    "        return row[\"model.model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"model.model_name\"] = df.apply(map_name, axis=1)\n",
    "df[\"transforms.sann_encoding.neighborhoods\"] = df[\n",
    "    \"transforms.sann_encoding.neighborhoods\"\n",
    "].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HOPSE_GPSE', 'scn', 'sccnn', nan, 'SANN', 'HOPSE_MANUAL_PE',\n",
       "       'gin', 'gcn'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"model.model_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NCI109', 'MANTRA_betti_numbers', 'NCI1', 'MUTAG', 'MANTRA_name',\n",
       "       'MANTRA_orientation', nan, 'PROTEINS', 'IMDB-BINARY', 'ZINC',\n",
       "       'IMDB-MULTI'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dataset.loader.parameters.data_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AvgTime/train_batch_mean</th>\n",
       "      <th>AvgTime/train_batch_std</th>\n",
       "      <th>AvgTime/train_epoch_mean</th>\n",
       "      <th>AvgTime/train_epoch_std</th>\n",
       "      <th>AvgTime/val_batch_mean</th>\n",
       "      <th>AvgTime/val_batch_std</th>\n",
       "      <th>AvgTime/val_epoch_mean</th>\n",
       "      <th>AvgTime/val_epoch_std</th>\n",
       "      <th>...</th>\n",
       "      <th>callbacks.model_checkpoint.save_last</th>\n",
       "      <th>callbacks.model_checkpoint.save_top_k</th>\n",
       "      <th>callbacks.model_checkpoint.every_n_epochs</th>\n",
       "      <th>callbacks.model_checkpoint.save_weights_only</th>\n",
       "      <th>callbacks.model_checkpoint.every_n_train_steps</th>\n",
       "      <th>callbacks.model_checkpoint.train_time_interval</th>\n",
       "      <th>callbacks.model_checkpoint.auto_insert_metric_name</th>\n",
       "      <th>callbacks.model_checkpoint.save_on_train_epoch_end</th>\n",
       "      <th>callbacks.learning_rate_monitor._target_</th>\n",
       "      <th>callbacks.learning_rate_monitor.logging_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15348</th>\n",
       "      <td>15348</td>\n",
       "      <td>15348</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>18.782126</td>\n",
       "      <td>3.057649</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>7.468087</td>\n",
       "      <td>0.636926</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15349</th>\n",
       "      <td>15349</td>\n",
       "      <td>15349</td>\n",
       "      <td>0.028702</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>19.219027</td>\n",
       "      <td>3.050732</td>\n",
       "      <td>0.013355</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>7.539920</td>\n",
       "      <td>0.113171</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15350</th>\n",
       "      <td>15350</td>\n",
       "      <td>15350</td>\n",
       "      <td>0.027799</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>18.830744</td>\n",
       "      <td>3.077185</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>7.427293</td>\n",
       "      <td>0.152190</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>15351</td>\n",
       "      <td>15351</td>\n",
       "      <td>0.028366</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>19.200341</td>\n",
       "      <td>3.248864</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>7.667151</td>\n",
       "      <td>0.691265</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15352</th>\n",
       "      <td>15352</td>\n",
       "      <td>15352</td>\n",
       "      <td>0.045146</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>18.786867</td>\n",
       "      <td>3.569898</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>7.799555</td>\n",
       "      <td>1.317402</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194266</th>\n",
       "      <td>194266</td>\n",
       "      <td>194266</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>10.728102</td>\n",
       "      <td>2.240022</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>5.672234</td>\n",
       "      <td>1.296537</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194267</th>\n",
       "      <td>194267</td>\n",
       "      <td>194267</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>10.429274</td>\n",
       "      <td>2.151637</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>4.808242</td>\n",
       "      <td>1.162993</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194268</th>\n",
       "      <td>194268</td>\n",
       "      <td>194268</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>11.165850</td>\n",
       "      <td>2.520713</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>5.874798</td>\n",
       "      <td>1.805193</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194269</th>\n",
       "      <td>194269</td>\n",
       "      <td>194269</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>9.412992</td>\n",
       "      <td>1.910430</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>4.128219</td>\n",
       "      <td>0.884713</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194270</th>\n",
       "      <td>194270</td>\n",
       "      <td>194270</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>9.495475</td>\n",
       "      <td>1.917523</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>4.239056</td>\n",
       "      <td>0.804171</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lightning.pytorch.callbacks.LearningRateMonitor</td>\n",
       "      <td>epoch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7252 rows × 274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  AvgTime/train_batch_mean  \\\n",
       "15348          15348       15348                  0.028011   \n",
       "15349          15349       15349                  0.028702   \n",
       "15350          15350       15350                  0.027799   \n",
       "15351          15351       15351                  0.028366   \n",
       "15352          15352       15352                  0.045146   \n",
       "...              ...         ...                       ...   \n",
       "194266        194266      194266                  0.016987   \n",
       "194267        194267      194267                  0.016992   \n",
       "194268        194268      194268                  0.017494   \n",
       "194269        194269      194269                  0.016411   \n",
       "194270        194270      194270                  0.016632   \n",
       "\n",
       "        AvgTime/train_batch_std  AvgTime/train_epoch_mean  \\\n",
       "15348                  0.001779                 18.782126   \n",
       "15349                  0.001932                 19.219027   \n",
       "15350                  0.001745                 18.830744   \n",
       "15351                  0.001876                 19.200341   \n",
       "15352                  0.016090                 18.786867   \n",
       "...                         ...                       ...   \n",
       "194266                 0.001852                 10.728102   \n",
       "194267                 0.001949                 10.429274   \n",
       "194268                 0.002339                 11.165850   \n",
       "194269                 0.001949                  9.412992   \n",
       "194270                 0.001887                  9.495475   \n",
       "\n",
       "        AvgTime/train_epoch_std  AvgTime/val_batch_mean  \\\n",
       "15348                  3.057649                0.013052   \n",
       "15349                  3.050732                0.013355   \n",
       "15350                  3.077185                0.013167   \n",
       "15351                  3.248864                0.013314   \n",
       "15352                  3.569898                0.024431   \n",
       "...                         ...                     ...   \n",
       "194266                 2.240022                0.009448   \n",
       "194267                 2.151637                0.009495   \n",
       "194268                 2.520713                0.009686   \n",
       "194269                 1.910430                0.009065   \n",
       "194270                 1.917523                0.009218   \n",
       "\n",
       "        AvgTime/val_batch_std  AvgTime/val_epoch_mean  AvgTime/val_epoch_std  \\\n",
       "15348                0.000510                7.468087               0.636926   \n",
       "15349                0.000435                7.539920               0.113171   \n",
       "15350                0.000516                7.427293               0.152190   \n",
       "15351                0.000443                7.667151               0.691265   \n",
       "15352                0.011655                7.799555               1.317402   \n",
       "...                       ...                     ...                    ...   \n",
       "194266               0.001915                5.672234               1.296537   \n",
       "194267               0.002006                4.808242               1.162993   \n",
       "194268               0.002220                5.874798               1.805193   \n",
       "194269               0.001948                4.128219               0.884713   \n",
       "194270               0.002144                4.239056               0.804171   \n",
       "\n",
       "        ...  callbacks.model_checkpoint.save_last  \\\n",
       "15348   ...                                 False   \n",
       "15349   ...                                 False   \n",
       "15350   ...                                 False   \n",
       "15351   ...                                 False   \n",
       "15352   ...                                 False   \n",
       "...     ...                                   ...   \n",
       "194266  ...                                 False   \n",
       "194267  ...                                 False   \n",
       "194268  ...                                 False   \n",
       "194269  ...                                 False   \n",
       "194270  ...                                 False   \n",
       "\n",
       "        callbacks.model_checkpoint.save_top_k  \\\n",
       "15348                                     1.0   \n",
       "15349                                     1.0   \n",
       "15350                                     1.0   \n",
       "15351                                     1.0   \n",
       "15352                                     1.0   \n",
       "...                                       ...   \n",
       "194266                                    1.0   \n",
       "194267                                    1.0   \n",
       "194268                                    1.0   \n",
       "194269                                    1.0   \n",
       "194270                                    1.0   \n",
       "\n",
       "        callbacks.model_checkpoint.every_n_epochs  \\\n",
       "15348                                         NaN   \n",
       "15349                                         NaN   \n",
       "15350                                         NaN   \n",
       "15351                                         NaN   \n",
       "15352                                         NaN   \n",
       "...                                           ...   \n",
       "194266                                        NaN   \n",
       "194267                                        NaN   \n",
       "194268                                        NaN   \n",
       "194269                                        NaN   \n",
       "194270                                        NaN   \n",
       "\n",
       "       callbacks.model_checkpoint.save_weights_only  \\\n",
       "15348                                         False   \n",
       "15349                                         False   \n",
       "15350                                         False   \n",
       "15351                                         False   \n",
       "15352                                         False   \n",
       "...                                             ...   \n",
       "194266                                        False   \n",
       "194267                                        False   \n",
       "194268                                        False   \n",
       "194269                                        False   \n",
       "194270                                        False   \n",
       "\n",
       "        callbacks.model_checkpoint.every_n_train_steps  \\\n",
       "15348                                              NaN   \n",
       "15349                                              NaN   \n",
       "15350                                              NaN   \n",
       "15351                                              NaN   \n",
       "15352                                              NaN   \n",
       "...                                                ...   \n",
       "194266                                             NaN   \n",
       "194267                                             NaN   \n",
       "194268                                             NaN   \n",
       "194269                                             NaN   \n",
       "194270                                             NaN   \n",
       "\n",
       "        callbacks.model_checkpoint.train_time_interval  \\\n",
       "15348                                              NaN   \n",
       "15349                                              NaN   \n",
       "15350                                              NaN   \n",
       "15351                                              NaN   \n",
       "15352                                              NaN   \n",
       "...                                                ...   \n",
       "194266                                             NaN   \n",
       "194267                                             NaN   \n",
       "194268                                             NaN   \n",
       "194269                                             NaN   \n",
       "194270                                             NaN   \n",
       "\n",
       "        callbacks.model_checkpoint.auto_insert_metric_name  \\\n",
       "15348                                               False    \n",
       "15349                                               False    \n",
       "15350                                               False    \n",
       "15351                                               False    \n",
       "15352                                               False    \n",
       "...                                                   ...    \n",
       "194266                                              False    \n",
       "194267                                              False    \n",
       "194268                                              False    \n",
       "194269                                              False    \n",
       "194270                                              False    \n",
       "\n",
       "        callbacks.model_checkpoint.save_on_train_epoch_end  \\\n",
       "15348                                                 NaN    \n",
       "15349                                                 NaN    \n",
       "15350                                                 NaN    \n",
       "15351                                                 NaN    \n",
       "15352                                                 NaN    \n",
       "...                                                   ...    \n",
       "194266                                                NaN    \n",
       "194267                                                NaN    \n",
       "194268                                                NaN    \n",
       "194269                                                NaN    \n",
       "194270                                                NaN    \n",
       "\n",
       "               callbacks.learning_rate_monitor._target_  \\\n",
       "15348   lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "15349   lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "15350   lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "15351   lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "15352   lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "...                                                 ...   \n",
       "194266  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "194267  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "194268  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "194269  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "194270  lightning.pytorch.callbacks.LearningRateMonitor   \n",
       "\n",
       "        callbacks.learning_rate_monitor.logging_interval  \n",
       "15348                                              epoch  \n",
       "15349                                              epoch  \n",
       "15350                                              epoch  \n",
       "15351                                              epoch  \n",
       "15352                                              epoch  \n",
       "...                                                  ...  \n",
       "194266                                             epoch  \n",
       "194267                                             epoch  \n",
       "194268                                             epoch  \n",
       "194269                                             epoch  \n",
       "194270                                             epoch  \n",
       "\n",
       "[7252 rows x 274 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"dataset.loader.parameters.data_name\"] == \"MANTRA_betti_numbers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0.1',\n",
       " 'Unnamed: 0',\n",
       " 'AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " '_wandb',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'loss',\n",
       " 'seed',\n",
       " 'tags',\n",
       " 'test',\n",
       " 'paths',\n",
       " 'train',\n",
       " 'extras',\n",
       " 'logger',\n",
       " 'trainer',\n",
       " 'ckpt_path',\n",
       " 'evaluator',\n",
       " 'task_name',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'model/params/non_trainable',\n",
       " 'test/accuracy_0',\n",
       " 'test/accuracy_1',\n",
       " 'test/accuracy_2',\n",
       " 'test/f1_0',\n",
       " 'test/f1_1',\n",
       " 'test/f1_2',\n",
       " 'test/precision_0',\n",
       " 'test/precision_1',\n",
       " 'test/precision_2',\n",
       " 'test/recall_0',\n",
       " 'test/recall_1',\n",
       " 'test/recall_2',\n",
       " 'train/accuracy_0',\n",
       " 'train/accuracy_1',\n",
       " 'train/accuracy_2',\n",
       " 'train/f1_0',\n",
       " 'train/f1_1',\n",
       " 'train/f1_2',\n",
       " 'train/precision_0',\n",
       " 'train/precision_1',\n",
       " 'train/precision_2',\n",
       " 'train/recall_0',\n",
       " 'train/recall_1',\n",
       " 'train/recall_2',\n",
       " 'val/accuracy_0',\n",
       " 'val/accuracy_1',\n",
       " 'val/accuracy_2',\n",
       " 'val/f1_0',\n",
       " 'val/f1_1',\n",
       " 'val/f1_2',\n",
       " 'val/precision_0',\n",
       " 'val/precision_1',\n",
       " 'val/precision_2',\n",
       " 'val/recall_0',\n",
       " 'val/recall_1',\n",
       " 'val/recall_2',\n",
       " 'test/f1',\n",
       " 'train/f1',\n",
       " 'val/f1',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.compile',\n",
       " 'model._target_',\n",
       " 'model.model_name',\n",
       " 'model.model_domain',\n",
       " 'model.readout.max_hop',\n",
       " 'model.readout._target_',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.task_level',\n",
       " 'model.readout.complex_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.readout.pooling_type',\n",
       " 'model.readout.readout_name',\n",
       " 'model.readout.num_cell_dimensions',\n",
       " 'model.backbone.max_hop',\n",
       " 'model.backbone._target_',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.update_func',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.max_hop',\n",
       " 'model.feature_encoder._target_',\n",
       " 'model.feature_encoder.all_ones',\n",
       " 'model.feature_encoder.in_channels',\n",
       " 'model.feature_encoder.encoder_name',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.feature_encoder.feature_lifting',\n",
       " 'model.feature_encoder.dataset_in_channels',\n",
       " 'model.feature_encoder.selected_dimensions',\n",
       " 'model.backbone_wrapper.max_hop',\n",
       " 'model.backbone_wrapper._target_',\n",
       " 'model.backbone_wrapper._partial_',\n",
       " 'model.backbone_wrapper.complex_dim',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'model.backbone_wrapper.wrapper_name',\n",
       " 'model.backbone_wrapper.num_cell_dimensions',\n",
       " 'model.backbone.in_channels_0',\n",
       " 'model.backbone.in_channels_1',\n",
       " 'model.backbone.in_channels_2',\n",
       " 'model.backbone.sc_order',\n",
       " 'model.backbone.aggr_norm',\n",
       " 'model.backbone.conv_order',\n",
       " 'model.backbone.in_channels_all',\n",
       " 'model.backbone.hidden_channels_all',\n",
       " 'model.backbone.act',\n",
       " 'model.backbone.dropout',\n",
       " 'model.backbone.num_layers',\n",
       " 'dataset.loader._target_',\n",
       " 'dataset.loader.parameters.data_dir',\n",
       " 'dataset.loader.parameters.data_name',\n",
       " 'dataset.loader.parameters.data_type',\n",
       " 'dataset.loader.parameters.data_domain',\n",
       " 'dataset.parameters.task',\n",
       " 'dataset.parameters.loss_type',\n",
       " 'dataset.parameters.task_level',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.parameters.num_features',\n",
       " 'dataset.parameters.monitor_metric',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.split_type',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.split_params.data_split_dir',\n",
       " 'dataset.split_params.learning_setting',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.dataloader_params.pin_memory',\n",
       " 'dataset.dataloader_params.num_workers',\n",
       " 'dataset.loader.parameters.slice',\n",
       " 'dataset.loader.parameters.version',\n",
       " 'dataset.loader.parameters.manifold_dim',\n",
       " 'dataset.loader.parameters.model_domain',\n",
       " 'dataset.loader.parameters.load_as_graph',\n",
       " 'dataset.loader.parameters.task_variable',\n",
       " 'dataset.parameters.data_seed',\n",
       " 'dataset.parameters.num_betti_numbers',\n",
       " 'dataset.parameters.max_dim_if_lifted',\n",
       " 'dataset.parameters.preserve_edge_attr_if_lifted',\n",
       " 'dataset.parameters.metrics',\n",
       " 'dataset.dataloader_params.persistent_workers',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'dataset.parameters.degrees_fields',\n",
       " 'transforms.sann_encoding.cuda',\n",
       " 'transforms.sann_encoding.device',\n",
       " 'transforms.sann_encoding.dim_out',\n",
       " 'transforms.sann_encoding.max_hop',\n",
       " 'transforms.sann_encoding._target_',\n",
       " 'transforms.sann_encoding.max_rank',\n",
       " 'transforms.sann_encoding.in_channels',\n",
       " 'transforms.sann_encoding.copy_initial',\n",
       " 'transforms.sann_encoding.neighborhoods',\n",
       " 'transforms.sann_encoding.pretrain_model',\n",
       " 'transforms.sann_encoding.transform_name',\n",
       " 'transforms.sann_encoding.transform_type',\n",
       " 'transforms.sann_encoding.dim_target_node',\n",
       " 'transforms.sann_encoding.dim_target_graph',\n",
       " 'transforms.graph2cell_lifting._target_',\n",
       " 'transforms.graph2cell_lifting.complex_dim',\n",
       " 'transforms.graph2cell_lifting.neighborhoods',\n",
       " 'transforms.graph2cell_lifting.transform_name',\n",
       " 'transforms.graph2cell_lifting.transform_type',\n",
       " 'transforms.graph2cell_lifting.feature_lifting',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.graph2cell_lifting.preserve_edge_attr',\n",
       " 'transforms.redefine_simplicial_neighborhoods.signed',\n",
       " 'transforms.redefine_simplicial_neighborhoods._target_',\n",
       " 'transforms.redefine_simplicial_neighborhoods.complex_dim',\n",
       " 'transforms.redefine_simplicial_neighborhoods.keys_to_keep',\n",
       " 'transforms.redefine_simplicial_neighborhoods.neighborhoods',\n",
       " 'transforms.redefine_simplicial_neighborhoods.transform_name',\n",
       " 'transforms.redefine_simplicial_neighborhoods.transform_type',\n",
       " 'transforms.graph2simplicial_lifting.signed',\n",
       " 'transforms.graph2simplicial_lifting._target_',\n",
       " 'transforms.graph2simplicial_lifting.complex_dim',\n",
       " 'transforms.graph2simplicial_lifting.neighborhoods',\n",
       " 'transforms.graph2simplicial_lifting.transform_name',\n",
       " 'transforms.graph2simplicial_lifting.transform_type',\n",
       " 'transforms.graph2simplicial_lifting.feature_lifting',\n",
       " 'transforms.graph2simplicial_lifting.preserve_edge_attr',\n",
       " 'transforms.sann_encoding.complex_dim',\n",
       " 'transforms.sann_encoding.use_initial_features',\n",
       " 'transforms.sann_encoding.pe_types',\n",
       " 'transforms.sann_encoding.is_undirected',\n",
       " 'transforms.sann_encoding.target_pe_dim',\n",
       " 'transforms.sann_encoding.kernel_param_RWSE',\n",
       " 'transforms.sann_encoding.laplacian_norm_type',\n",
       " 'transforms.sann_encoding.kernel_param_CycleGE',\n",
       " 'transforms.sann_encoding.kernel_param_HKdiagSE',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_max_freqs',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_eigvec_abs',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_eigvec_norm',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_skip_zero_freq',\n",
       " 'transforms.data_manipulations._target_',\n",
       " 'transforms.data_manipulations.transform_name',\n",
       " 'transforms.data_manipulations.transform_type',\n",
       " 'transforms.data_manipulations.selected_fields',\n",
       " 'transforms.one_hot_node_degree_features._target_',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'transforms.one_hot_node_degree_features.degrees_fields',\n",
       " 'transforms.one_hot_node_degree_features.transform_name',\n",
       " 'transforms.one_hot_node_degree_features.transform_type',\n",
       " 'transforms.one_hot_node_degree_features.features_fields',\n",
       " 'transforms.one_hot_node_degree_features.degrees_field',\n",
       " 'transforms.one_hot_node_degree_features.features_field',\n",
       " 'transforms.one_hot_node_degree_features.keep_degree_field',\n",
       " 'optimizer._target_',\n",
       " 'optimizer.optimizer_id',\n",
       " 'optimizer.scheduler.scheduler_id',\n",
       " 'optimizer.scheduler.scheduler_params.gamma',\n",
       " 'optimizer.scheduler.scheduler_params.step_size',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay',\n",
       " 'callbacks.model_timer._target_',\n",
       " 'callbacks.model_summary._target_',\n",
       " 'callbacks.model_summary.max_depth',\n",
       " 'callbacks.early_stopping.mode',\n",
       " 'callbacks.early_stopping.strict',\n",
       " 'callbacks.early_stopping.monitor',\n",
       " 'callbacks.early_stopping.verbose',\n",
       " 'callbacks.early_stopping._target_',\n",
       " 'callbacks.early_stopping.patience',\n",
       " 'callbacks.early_stopping.min_delta',\n",
       " 'callbacks.early_stopping.check_finite',\n",
       " 'callbacks.early_stopping.stopping_threshold',\n",
       " 'callbacks.early_stopping.divergence_threshold',\n",
       " 'callbacks.early_stopping.check_on_train_epoch_end',\n",
       " 'callbacks.model_checkpoint.mode',\n",
       " 'callbacks.model_checkpoint.dirpath',\n",
       " 'callbacks.model_checkpoint.monitor',\n",
       " 'callbacks.model_checkpoint.verbose',\n",
       " 'callbacks.model_checkpoint._target_',\n",
       " 'callbacks.model_checkpoint.filename',\n",
       " 'callbacks.model_checkpoint.save_last',\n",
       " 'callbacks.model_checkpoint.save_top_k',\n",
       " 'callbacks.model_checkpoint.every_n_epochs',\n",
       " 'callbacks.model_checkpoint.save_weights_only',\n",
       " 'callbacks.model_checkpoint.every_n_train_steps',\n",
       " 'callbacks.model_checkpoint.train_time_interval',\n",
       " 'callbacks.model_checkpoint.auto_insert_metric_name',\n",
       " 'callbacks.model_checkpoint.save_on_train_epoch_end',\n",
       " 'callbacks.learning_rate_monitor._target_',\n",
       " 'callbacks.learning_rate_monitor.logging_interval']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get grouped df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[\"dataset.split_params.data_seed\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30996    0.829787\n",
       "30997    0.914894\n",
       "30998    0.851064\n",
       "30999    0.872340\n",
       "31000    0.893617\n",
       "           ...   \n",
       "46351    0.851064\n",
       "46352    0.957447\n",
       "46353    0.638298\n",
       "46354    0.638298\n",
       "46355    0.744681\n",
       "Name: test/accuracy, Length: 15360, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cell', 'simplicial', 'graph'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"model.model_domain\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0.1',\n",
       " 'Unnamed: 0',\n",
       " 'AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " '_wandb',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'loss',\n",
       " 'seed',\n",
       " 'tags',\n",
       " 'test',\n",
       " 'paths',\n",
       " 'train',\n",
       " 'extras',\n",
       " 'logger',\n",
       " 'trainer',\n",
       " 'ckpt_path',\n",
       " 'evaluator',\n",
       " 'task_name',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'model/params/non_trainable',\n",
       " 'test/accuracy_0',\n",
       " 'test/accuracy_1',\n",
       " 'test/accuracy_2',\n",
       " 'test/f1_0',\n",
       " 'test/f1_1',\n",
       " 'test/f1_2',\n",
       " 'test/precision_0',\n",
       " 'test/precision_1',\n",
       " 'test/precision_2',\n",
       " 'test/recall_0',\n",
       " 'test/recall_1',\n",
       " 'test/recall_2',\n",
       " 'train/accuracy_0',\n",
       " 'train/accuracy_1',\n",
       " 'train/accuracy_2',\n",
       " 'train/f1_0',\n",
       " 'train/f1_1',\n",
       " 'train/f1_2',\n",
       " 'train/precision_0',\n",
       " 'train/precision_1',\n",
       " 'train/precision_2',\n",
       " 'train/recall_0',\n",
       " 'train/recall_1',\n",
       " 'train/recall_2',\n",
       " 'val/accuracy_0',\n",
       " 'val/accuracy_1',\n",
       " 'val/accuracy_2',\n",
       " 'val/f1_0',\n",
       " 'val/f1_1',\n",
       " 'val/f1_2',\n",
       " 'val/precision_0',\n",
       " 'val/precision_1',\n",
       " 'val/precision_2',\n",
       " 'val/recall_0',\n",
       " 'val/recall_1',\n",
       " 'val/recall_2',\n",
       " 'test/f1',\n",
       " 'train/f1',\n",
       " 'val/f1',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.compile',\n",
       " 'model._target_',\n",
       " 'model.model_name',\n",
       " 'model.model_domain',\n",
       " 'model.readout.max_hop',\n",
       " 'model.readout._target_',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.task_level',\n",
       " 'model.readout.complex_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.readout.pooling_type',\n",
       " 'model.readout.readout_name',\n",
       " 'model.readout.num_cell_dimensions',\n",
       " 'model.backbone.max_hop',\n",
       " 'model.backbone._target_',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.update_func',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.max_hop',\n",
       " 'model.feature_encoder._target_',\n",
       " 'model.feature_encoder.all_ones',\n",
       " 'model.feature_encoder.in_channels',\n",
       " 'model.feature_encoder.encoder_name',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.feature_encoder.feature_lifting',\n",
       " 'model.feature_encoder.dataset_in_channels',\n",
       " 'model.feature_encoder.selected_dimensions',\n",
       " 'model.backbone_wrapper.max_hop',\n",
       " 'model.backbone_wrapper._target_',\n",
       " 'model.backbone_wrapper._partial_',\n",
       " 'model.backbone_wrapper.complex_dim',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'model.backbone_wrapper.wrapper_name',\n",
       " 'model.backbone_wrapper.num_cell_dimensions',\n",
       " 'model.backbone.in_channels_0',\n",
       " 'model.backbone.in_channels_1',\n",
       " 'model.backbone.in_channels_2',\n",
       " 'model.backbone.sc_order',\n",
       " 'model.backbone.aggr_norm',\n",
       " 'model.backbone.conv_order',\n",
       " 'model.backbone.in_channels_all',\n",
       " 'model.backbone.hidden_channels_all',\n",
       " 'model.backbone.act',\n",
       " 'model.backbone.dropout',\n",
       " 'model.backbone.num_layers',\n",
       " 'dataset.loader._target_',\n",
       " 'dataset.loader.parameters.data_dir',\n",
       " 'dataset.loader.parameters.data_name',\n",
       " 'dataset.loader.parameters.data_type',\n",
       " 'dataset.loader.parameters.data_domain',\n",
       " 'dataset.parameters.task',\n",
       " 'dataset.parameters.loss_type',\n",
       " 'dataset.parameters.task_level',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.parameters.num_features',\n",
       " 'dataset.parameters.monitor_metric',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.split_type',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.split_params.data_split_dir',\n",
       " 'dataset.split_params.learning_setting',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.dataloader_params.pin_memory',\n",
       " 'dataset.dataloader_params.num_workers',\n",
       " 'dataset.loader.parameters.slice',\n",
       " 'dataset.loader.parameters.version',\n",
       " 'dataset.loader.parameters.manifold_dim',\n",
       " 'dataset.loader.parameters.model_domain',\n",
       " 'dataset.loader.parameters.load_as_graph',\n",
       " 'dataset.loader.parameters.task_variable',\n",
       " 'dataset.parameters.data_seed',\n",
       " 'dataset.parameters.num_betti_numbers',\n",
       " 'dataset.parameters.max_dim_if_lifted',\n",
       " 'dataset.parameters.preserve_edge_attr_if_lifted',\n",
       " 'dataset.parameters.metrics',\n",
       " 'dataset.dataloader_params.persistent_workers',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'dataset.parameters.degrees_fields',\n",
       " 'transforms.sann_encoding.cuda',\n",
       " 'transforms.sann_encoding.device',\n",
       " 'transforms.sann_encoding.dim_out',\n",
       " 'transforms.sann_encoding.max_hop',\n",
       " 'transforms.sann_encoding._target_',\n",
       " 'transforms.sann_encoding.max_rank',\n",
       " 'transforms.sann_encoding.in_channels',\n",
       " 'transforms.sann_encoding.copy_initial',\n",
       " 'transforms.sann_encoding.neighborhoods',\n",
       " 'transforms.sann_encoding.pretrain_model',\n",
       " 'transforms.sann_encoding.transform_name',\n",
       " 'transforms.sann_encoding.transform_type',\n",
       " 'transforms.sann_encoding.dim_target_node',\n",
       " 'transforms.sann_encoding.dim_target_graph',\n",
       " 'transforms.graph2cell_lifting._target_',\n",
       " 'transforms.graph2cell_lifting.complex_dim',\n",
       " 'transforms.graph2cell_lifting.neighborhoods',\n",
       " 'transforms.graph2cell_lifting.transform_name',\n",
       " 'transforms.graph2cell_lifting.transform_type',\n",
       " 'transforms.graph2cell_lifting.feature_lifting',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.graph2cell_lifting.preserve_edge_attr',\n",
       " 'transforms.redefine_simplicial_neighborhoods.signed',\n",
       " 'transforms.redefine_simplicial_neighborhoods._target_',\n",
       " 'transforms.redefine_simplicial_neighborhoods.complex_dim',\n",
       " 'transforms.redefine_simplicial_neighborhoods.keys_to_keep',\n",
       " 'transforms.redefine_simplicial_neighborhoods.neighborhoods',\n",
       " 'transforms.redefine_simplicial_neighborhoods.transform_name',\n",
       " 'transforms.redefine_simplicial_neighborhoods.transform_type',\n",
       " 'transforms.graph2simplicial_lifting.signed',\n",
       " 'transforms.graph2simplicial_lifting._target_',\n",
       " 'transforms.graph2simplicial_lifting.complex_dim',\n",
       " 'transforms.graph2simplicial_lifting.neighborhoods',\n",
       " 'transforms.graph2simplicial_lifting.transform_name',\n",
       " 'transforms.graph2simplicial_lifting.transform_type',\n",
       " 'transforms.graph2simplicial_lifting.feature_lifting',\n",
       " 'transforms.graph2simplicial_lifting.preserve_edge_attr',\n",
       " 'transforms.sann_encoding.complex_dim',\n",
       " 'transforms.sann_encoding.use_initial_features',\n",
       " 'transforms.sann_encoding.pe_types',\n",
       " 'transforms.sann_encoding.is_undirected',\n",
       " 'transforms.sann_encoding.target_pe_dim',\n",
       " 'transforms.sann_encoding.kernel_param_RWSE',\n",
       " 'transforms.sann_encoding.laplacian_norm_type',\n",
       " 'transforms.sann_encoding.kernel_param_CycleGE',\n",
       " 'transforms.sann_encoding.kernel_param_HKdiagSE',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_max_freqs',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_eigvec_abs',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_eigvec_norm',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_skip_zero_freq',\n",
       " 'transforms.data_manipulations._target_',\n",
       " 'transforms.data_manipulations.transform_name',\n",
       " 'transforms.data_manipulations.transform_type',\n",
       " 'transforms.data_manipulations.selected_fields',\n",
       " 'transforms.one_hot_node_degree_features._target_',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'transforms.one_hot_node_degree_features.degrees_fields',\n",
       " 'transforms.one_hot_node_degree_features.transform_name',\n",
       " 'transforms.one_hot_node_degree_features.transform_type',\n",
       " 'transforms.one_hot_node_degree_features.features_fields',\n",
       " 'transforms.one_hot_node_degree_features.degrees_field',\n",
       " 'transforms.one_hot_node_degree_features.features_field',\n",
       " 'transforms.one_hot_node_degree_features.keep_degree_field',\n",
       " 'optimizer._target_',\n",
       " 'optimizer.optimizer_id',\n",
       " 'optimizer.scheduler.scheduler_id',\n",
       " 'optimizer.scheduler.scheduler_params.gamma',\n",
       " 'optimizer.scheduler.scheduler_params.step_size',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay',\n",
       " 'callbacks.model_timer._target_',\n",
       " 'callbacks.model_summary._target_',\n",
       " 'callbacks.model_summary.max_depth',\n",
       " 'callbacks.early_stopping.mode',\n",
       " 'callbacks.early_stopping.strict',\n",
       " 'callbacks.early_stopping.monitor',\n",
       " 'callbacks.early_stopping.verbose',\n",
       " 'callbacks.early_stopping._target_',\n",
       " 'callbacks.early_stopping.patience',\n",
       " 'callbacks.early_stopping.min_delta',\n",
       " 'callbacks.early_stopping.check_finite',\n",
       " 'callbacks.early_stopping.stopping_threshold',\n",
       " 'callbacks.early_stopping.divergence_threshold',\n",
       " 'callbacks.early_stopping.check_on_train_epoch_end',\n",
       " 'callbacks.model_checkpoint.mode',\n",
       " 'callbacks.model_checkpoint.dirpath',\n",
       " 'callbacks.model_checkpoint.monitor',\n",
       " 'callbacks.model_checkpoint.verbose',\n",
       " 'callbacks.model_checkpoint._target_',\n",
       " 'callbacks.model_checkpoint.filename',\n",
       " 'callbacks.model_checkpoint.save_last',\n",
       " 'callbacks.model_checkpoint.save_top_k',\n",
       " 'callbacks.model_checkpoint.every_n_epochs',\n",
       " 'callbacks.model_checkpoint.save_weights_only',\n",
       " 'callbacks.model_checkpoint.every_n_train_steps',\n",
       " 'callbacks.model_checkpoint.train_time_interval',\n",
       " 'callbacks.model_checkpoint.auto_insert_metric_name',\n",
       " 'callbacks.model_checkpoint.save_on_train_epoch_end',\n",
       " 'callbacks.learning_rate_monitor._target_',\n",
       " 'callbacks.learning_rate_monitor.logging_interval']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_params = []\n",
    "for param in list(df.columns):\n",
    "    if df[param].dtype == pd.CategoricalDtype:\n",
    "        continue\n",
    "    if len(df[param].unique()) > 1:\n",
    "        changed_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0.1',\n",
       " 'Unnamed: 0',\n",
       " 'AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'seed',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'model/params/non_trainable',\n",
       " 'test/accuracy_0',\n",
       " 'test/accuracy_1',\n",
       " 'test/accuracy_2',\n",
       " 'test/f1_0',\n",
       " 'test/f1_1',\n",
       " 'test/f1_2',\n",
       " 'test/precision_0',\n",
       " 'test/precision_1',\n",
       " 'test/precision_2',\n",
       " 'test/recall_0',\n",
       " 'test/recall_1',\n",
       " 'test/recall_2',\n",
       " 'train/accuracy_0',\n",
       " 'train/accuracy_1',\n",
       " 'train/accuracy_2',\n",
       " 'train/f1_0',\n",
       " 'train/f1_1',\n",
       " 'train/f1_2',\n",
       " 'train/precision_0',\n",
       " 'train/precision_1',\n",
       " 'train/precision_2',\n",
       " 'train/recall_0',\n",
       " 'train/recall_1',\n",
       " 'train/recall_2',\n",
       " 'val/accuracy_0',\n",
       " 'val/accuracy_1',\n",
       " 'val/accuracy_2',\n",
       " 'val/f1_0',\n",
       " 'val/f1_1',\n",
       " 'val/f1_2',\n",
       " 'val/precision_0',\n",
       " 'val/precision_1',\n",
       " 'val/precision_2',\n",
       " 'val/recall_0',\n",
       " 'val/recall_1',\n",
       " 'val/recall_2',\n",
       " 'test/f1',\n",
       " 'train/f1',\n",
       " 'val/f1',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.readout.max_hop',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.complex_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.readout.num_cell_dimensions',\n",
       " 'model.backbone.max_hop',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.max_hop',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.backbone_wrapper.max_hop',\n",
       " 'model.backbone_wrapper.complex_dim',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'model.backbone_wrapper.num_cell_dimensions',\n",
       " 'model.backbone.in_channels_0',\n",
       " 'model.backbone.in_channels_1',\n",
       " 'model.backbone.in_channels_2',\n",
       " 'model.backbone.sc_order',\n",
       " 'model.backbone.conv_order',\n",
       " 'model.backbone.dropout',\n",
       " 'model.backbone.num_layers',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.dataloader_params.num_workers',\n",
       " 'dataset.loader.parameters.manifold_dim',\n",
       " 'dataset.parameters.data_seed',\n",
       " 'dataset.parameters.max_dim_if_lifted',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'transforms.sann_encoding.dim_out',\n",
       " 'transforms.sann_encoding.max_hop',\n",
       " 'transforms.sann_encoding.max_rank',\n",
       " 'transforms.sann_encoding.dim_target_node',\n",
       " 'transforms.sann_encoding.dim_target_graph',\n",
       " 'transforms.graph2cell_lifting.complex_dim',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.redefine_simplicial_neighborhoods.complex_dim',\n",
       " 'transforms.graph2simplicial_lifting.complex_dim',\n",
       " 'transforms.sann_encoding.complex_dim',\n",
       " 'transforms.sann_encoding.target_pe_dim',\n",
       " 'transforms.sann_encoding.posenc_LapPE_eigen_max_freqs',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'optimizer.scheduler.scheduler_params.gamma',\n",
       " 'optimizer.scheduler.scheduler_params.step_size',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay',\n",
       " 'callbacks.model_summary.max_depth',\n",
       " 'callbacks.early_stopping.patience',\n",
       " 'callbacks.early_stopping.min_delta',\n",
       " 'callbacks.model_checkpoint.save_top_k']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HOPSE_GPSE', 'scn', 'sccnn', 'SANN', 'gin', 'gcn'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"model.model_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "\n",
    "sweeped_columns = [\n",
    "    \"transforms.sann_encoding.max_hop\",\n",
    "    \"transforms.sann_encoding.max_rank\",\n",
    "    \"transforms.sann_encoding.neighborhoods\",\n",
    "    \"transforms.sann_encoding.pretrain_model\",\n",
    "    \"transforms.sann_encoding.complex_dim\",\n",
    "    \"model.feature_encoder.proj_dropout\",\n",
    "    \"model.backbone.n_layers\",\n",
    "    \"model.backbone.hidden_channels\",\n",
    "    \"model.readout.hidden_dim\",\n",
    "    \"model.feature_encoder.out_channels\",\n",
    "    # SCCNN\n",
    "    \"model.backbone.sc_order\",\n",
    "    \"model.backbone.conv_order\",\n",
    "    \"model.readout.readout_name\",\n",
    "    # Others\n",
    "    \"optimizer.parameters.weight_decay\",\n",
    "    \"optimizer.parameters.lr\",\n",
    "    \"dataset.dataloader_params.batch_size\",\n",
    "    \"dataset.loader.parameters.manifold_dim\",\n",
    "    # Additional\n",
    "    \"transforms.sann_encoding.copy_initial\",\n",
    "    \"transforms.graph2cell_lifting.max_cell_length\",\n",
    "    \"transforms.sann_encoding.use_initial_features\",\n",
    "    \"transforms.sann_encoding.is_undirected\",\n",
    "    \"transforms.sann_encoding.target_pe_dim\",\n",
    "    \"transforms.sann_encoding.laplacian_norm_type\",\n",
    "    \"transforms.sann_encoding.posenc_LapPE_eigen_max_freqs\",\n",
    "    \"transforms.sann_encoding.posenc_LapPE_eigen_eigvec_abs\",\n",
    "    \"transforms.sann_encoding.posenc_LapPE_eigen_eigvec_norm\",\n",
    "    \"transforms.sann_encoding.posenc_LapPE_eigen_skip_zero_freq\",\n",
    "    \"transforms.redefine_simplicial_neighborhoods.signed\",\n",
    "    \"transforms.redefine_simplicial_neighborhoods.complex_dim\",\n",
    "]\n",
    "run_columns = [\n",
    "    \"dataset.split_params.data_seed\",\n",
    "    \"seed\",\n",
    "]\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = [\n",
    "    \"model.model_name\",\n",
    "    \"model.model_domain\",\n",
    "    \"dataset.loader.parameters.data_name\",\n",
    "]\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    \"val/loss\",\n",
    "    \"test/loss\",\n",
    "    \"val/mae\",\n",
    "    \"test/mae\",\n",
    "    \"val/mse\",\n",
    "    \"test/mse\",\n",
    "    \"val/accuracy\",\n",
    "    \"test/accuracy\",\n",
    "    \"val/auroc\",\n",
    "    \"test/auroc\",\n",
    "    \"val/recall\",\n",
    "    \"test/recall\",\n",
    "    \"val/precision\",\n",
    "    \"test/precision\",\n",
    "    \"val/f1\",\n",
    "    \"test/f1\",\n",
    "]\n",
    "keep_columns = (\n",
    "    dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    ")\n",
    "df_keep = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: test/accuracy, dtype: float64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keep[\n",
    "    (df_keep[\"model.model_name\"] == \"HOPSE_GPSE\")\n",
    "    & (df[\"dataset.loader.parameters.data_name\"] == \"MUTAG\")\n",
    "    & (df[\"model.model_domain\"] == \"simplicial\")\n",
    "][\"test/accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_correct_dataname(row):\n",
    "    if row[\"dataset.loader.parameters.data_name\"] == \"MANTRA_betti_numbers\":\n",
    "        rows = []\n",
    "        for i in range(3):\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict[\"dataset.loader.parameters.data_name\"] = (\n",
    "                row_dict[\"dataset.loader.parameters.data_name\"] + f\"_{i}\"\n",
    "            )\n",
    "            row_dict[\"val/f1\"] = row_dict[f\"val/f1_{i}\"]\n",
    "            row_dict[\"test/f1\"] = row_dict[f\"test/f1_{i}\"]\n",
    "            rows.append(pd.DataFrame.from_records([row_dict]))\n",
    "        return pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dfs = []\n",
    "for i, row in df.iterrows():\n",
    "    if row[\"dataset.loader.parameters.data_name\"] == \"MANTRA_betti_numbers\":\n",
    "        rows = []\n",
    "        for i in range(3):\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict[\"dataset.loader.parameters.data_name\"] = (\n",
    "                row_dict[\"dataset.loader.parameters.data_name\"] + f\"_{i}\"\n",
    "            )\n",
    "            row_dict[\"val/f1\"] = row_dict[f\"val/f1_{i}\"]\n",
    "            row_dict[\"test/f1\"] = row_dict[f\"test/f1_{i}\"]\n",
    "            rows.append(pd.DataFrame.from_records([row_dict]))\n",
    "        scores_dfs.append(pd.concat(rows))\n",
    "scores_df = pd.concat(scores_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/0rz4lf5s51bfpr4hwz5hx0kh0000gn/T/ipykernel_20668/2233766090.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  explode_df[~df['val/f1_0'].isna()][['val/f1', 'val/f1_0']]\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m explode_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/f1\u001b[39m\u001b[38;5;124m'\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mexplode_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval/f1_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/f1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/f1_0\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/sann_311/lib/python3.11/site-packages/pandas/core/frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/sann_311/lib/python3.11/site-packages/pandas/core/frame.py:4149\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4145\u001b[0m     )\n\u001b[1;32m   4147\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[1;32m   4148\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m-> 4149\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sann_311/lib/python3.11/site-packages/pandas/core/indexing.py:2662\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2660\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[0;32m-> 2662\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2663\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2665\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2666\u001b[0m     )\n\u001b[1;32m   2668\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   2670\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "explode_df = df.explode(\"val/f1\")\n",
    "explode_df[~df[\"val/f1_0\"].isna()][[\"val/f1\", \"val/f1_0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\n",
    "    [\"model.model_name\", \"dataset.loader.parameters.data_name\", \"val/f1\"]\n",
    "]\n",
    "df = df[df[\"dataset.loader.parameters.data_name\"] != \"MANTRA_betti_numbers\"]\n",
    "df = pd.concat([df, scores_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    \"val/accuracy\",\n",
    "    \"test/accuracy\",\n",
    "    \"val/auroc\",\n",
    "    \"test/auroc\",\n",
    "    \"val/loss\",\n",
    "    \"val/recall\",\n",
    "    \"test/recall\",\n",
    "    \"val/precision\",\n",
    "    \"test/precision\",\n",
    "    \"val/f1\",\n",
    "    \"test/f1\",\n",
    "]\n",
    "performance_split = [\n",
    "    \"val/loss\",\n",
    "    \"test/loss\",\n",
    "]\n",
    "performance_regression = [\n",
    "    \"val/mae\",\n",
    "    \"test/mae\",\n",
    "    \"val/mse\",\n",
    "    \"test/mse\",\n",
    "]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    \"NCI109\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"NCI1\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"PROTEINS\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MUTAG\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"ZINC\": {\n",
    "        \"optim_metric\": \"val/mae\",\n",
    "        \"eval_metric\": \"test/mae\",\n",
    "        \"direction\": \"min\",\n",
    "        \"performance_columns\": performance_regression,\n",
    "    },\n",
    "    \"IMDB-BINARY\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"IMDB-MULTI\": {\n",
    "        \"optim_metric\": \"val/accuracy\",\n",
    "        \"eval_metric\": \"test/accuracy\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"Cora\": {\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"Citeseer\": {\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"PubMed\": {\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_name\": {\n",
    "        \"optim_metric\": \"val/f1\",\n",
    "        \"eval_metric\": \"test/f1\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_orientation\": {\n",
    "        \"optim_metric\": \"val/f1\",\n",
    "        \"eval_metric\": \"test/f1\",\n",
    "        \"direction\": \"max\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_betti_numbers\": {\n",
    "        \"optim_metric\": \"val/loss\",\n",
    "        \"eval_metric\": \"val/loss\",\n",
    "        \"direction\": \"min\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_betti_numbers_0\": {\n",
    "        \"optim_metric\": \"val/loss\",\n",
    "        \"eval_metric\": \"test/f1\",\n",
    "        \"direction\": \"min\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_betti_numbers_1\": {\n",
    "        \"optim_metric\": \"val/loss\",\n",
    "        \"eval_metric\": \"test/f1\",\n",
    "        \"direction\": \"min\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "    \"MANTRA_betti_numbers_2\": {\n",
    "        \"optim_metric\": \"val/loss\",\n",
    "        \"eval_metric\": \"test/f1\",\n",
    "        \"direction\": \"min\",\n",
    "        \"performance_columns\": performance_classification,\n",
    "    },\n",
    "}\n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>val/loss</th>\n",
       "      <th>test/f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.036363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.039794</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.052050</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.044742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOPSE_GPSE</td>\n",
       "      <td>0.354617</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model.model_name  val/loss  test/f1\n",
       "0        HOPSE_GPSE  0.036120      1.0\n",
       "0        HOPSE_GPSE  0.036363      1.0\n",
       "0        HOPSE_GPSE  0.036407      1.0\n",
       "0        HOPSE_GPSE  0.036260      1.0\n",
       "0        HOPSE_GPSE  0.034499      1.0\n",
       "..              ...       ...      ...\n",
       "0        HOPSE_GPSE  0.039794      1.0\n",
       "0        HOPSE_GPSE  0.052050      1.0\n",
       "0        HOPSE_GPSE  0.044742      1.0\n",
       "0        HOPSE_GPSE  0.059122      1.0\n",
       "0        HOPSE_GPSE  0.354617      1.0\n",
       "\n",
       "[3840 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (\n",
    "    df_keep[\"dataset.loader.parameters.data_name\"] == \"MANTRA_betti_numbers_0\"\n",
    ")\n",
    "mask = (mask) & (df_keep[\"model.model_name\"] == \"HOPSE_GPSE\")\n",
    "df_keep[mask][[\"model.model_name\", \"val/loss\", \"test/f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_subsets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NCI109, Model: HOPSE_GPSE\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: scn\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: sccnn\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: SANN\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: HOPSE_MANUAL_PE\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: gin\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: NCI109, Model: gcn\n",
      "[5 4 3]\n",
      "99.79163772746215\n",
      "Dataset: MANTRA_betti_numbers, Model: HOPSE_GPSE\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: scn\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: sccnn\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: SANN\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: HOPSE_MANUAL_PE\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: gin\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: MANTRA_betti_numbers, Model: gcn\n",
      "[ 5  4  3 12  8  7  6]\n",
      "99.93055555555556\n",
      "Dataset: NCI1, Model: HOPSE_GPSE\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: scn\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: sccnn\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: SANN\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: HOPSE_MANUAL_PE\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: gin\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: NCI1, Model: gcn\n",
      "[5 4]\n",
      "99.98611111111111\n",
      "Dataset: MUTAG, Model: HOPSE_GPSE\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: scn\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: sccnn\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: SANN\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: HOPSE_MANUAL_PE\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: gin\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MUTAG, Model: gcn\n",
      "[5 4]\n",
      "99.97577519379846\n",
      "Dataset: MANTRA_name, Model: HOPSE_GPSE\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: scn\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: sccnn\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: SANN\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: HOPSE_MANUAL_PE\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: gin\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_name, Model: gcn\n",
      "[ 5  4  0  2  1  3 15 14]\n",
      "98.59022556390977\n",
      "Dataset: MANTRA_orientation, Model: HOPSE_GPSE\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: scn\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: sccnn\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: SANN\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: HOPSE_MANUAL_PE\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: gin\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: MANTRA_orientation, Model: gcn\n",
      "[ 5  4  3  2 10 15 11]\n",
      "93.66319444444444\n",
      "Dataset: PROTEINS, Model: HOPSE_GPSE\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: scn\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: sccnn\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: SANN\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: HOPSE_MANUAL_PE\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: gin\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: PROTEINS, Model: gcn\n",
      "[5 4]\n",
      "99.92088607594937\n",
      "Dataset: IMDB-BINARY, Model: HOPSE_GPSE\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: scn\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: sccnn\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: SANN\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: HOPSE_MANUAL_PE\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: gin\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: gcn\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: ZINC, Model: HOPSE_GPSE\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: scn\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: sccnn\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: SANN\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: HOPSE_MANUAL_PE\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: gin\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: ZINC, Model: gcn\n",
      "[5 4 2 0 3 1]\n",
      "97.91666666666666\n",
      "Dataset: IMDB-MULTI, Model: HOPSE_GPSE\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: scn\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: sccnn\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: SANN\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: HOPSE_MANUAL_PE\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: gin\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: gcn\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n"
     ]
    }
   ],
   "source": [
    "search_metric_types = [\n",
    "    \"accuracy\",\n",
    "]  #'auroc', 'recall', 'precision']\n",
    "\n",
    "\n",
    "# Get unique datasets\n",
    "datasets = list(df[\"dataset.loader.parameters.data_name\"].unique())\n",
    "# Get unique models\n",
    "models = list(df[\"model.model_name\"].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "best_results_all_metrics = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "collect_subsets = defaultdict(dict)\n",
    "collect_bast_parameters = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df_keep[\n",
    "            (df_keep[\"dataset.loader.parameters.data_name\"] == dataset)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset][\"optim_metric\"]\n",
    "        eval_metric = optimization_metrics[dataset][\"eval_metric\"]\n",
    "        direction = optimization_metrics[dataset][\"direction\"]\n",
    "\n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset][\n",
    "            \"performance_columns\"\n",
    "        ]\n",
    "        subset = subset[\n",
    "            dataset_model_columns\n",
    "            + sweeped_columns\n",
    "            + performance_columns\n",
    "            + run_columns\n",
    "        ]\n",
    "\n",
    "        aggregated = subset.groupby(\n",
    "            sweeped_columns + [\"model.model_name\", \"model.model_domain\"],\n",
    "            dropna=False,\n",
    "        ).agg(\n",
    "            {col: [\"mean\", \"std\", \"count\"] for col in performance_columns},\n",
    "        )\n",
    "\n",
    "        # aggregated = subset.groupby(sweeped_columns, dropna=False).count()\n",
    "        n_count = 5 if \"MANTRA\" not in dataset else 4\n",
    "        # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        print(aggregated[(eval_metric, \"count\")].unique())\n",
    "        # print(aggregated['dataset.split_params.data_seed'].unique())\n",
    "        print(\n",
    "            (aggregated[(eval_metric, \"count\")] >= n_count).sum()\n",
    "            / len(aggregated)\n",
    "            * 100\n",
    "        )\n",
    "        aggregated = aggregated[aggregated[(eval_metric, \"count\")] >= n_count]\n",
    "        # print(len(aggregated[aggregated['seed'] > 4]))\n",
    "        # aggregated = aggregated.sort_values(\n",
    "        #         by=(eval_metric, \"mean\"), ascending=(direction == 'min')\n",
    "        #     )\n",
    "\n",
    "        # Git percent in case of classification\n",
    "        if \"test/accuracy\" in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "\n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "\n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "\n",
    "        collect_subsets[dataset] = aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m protein_subset \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_subsets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPROTEINS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest/accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval/accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.model_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.model_domain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransforms.sann_encoding.neighborhoods\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.backbone.n_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m protein_subset\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverfit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m protein_subset[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m-\u001b[39m protein_subset[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      3\u001b[0m protein_subset\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverfit\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "protein_subset = collect_subsets[\"PROTEINS\"][\n",
    "    [\n",
    "        \"test/accuracy\",\n",
    "        \"val/accuracy\",\n",
    "        \"model.model_name\",\n",
    "        \"model.model_domain\",\n",
    "        \"transforms.sann_encoding.neighborhoods\",\n",
    "        \"model.backbone.n_layers\",\n",
    "    ]\n",
    "]\n",
    "protein_subset.loc[:, \"overfit\"] = (\n",
    "    protein_subset[(\"val/accuracy\", \"mean\")]\n",
    "    - protein_subset[(\"test/accuracy\", \"mean\")]\n",
    ")\n",
    "protein_subset.sort_values(by=\"overfit\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HOPSE_MANUAL_PE', 'HOPSE_GPSE', 'SANN'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mantra_name = collect_subsets[\"ZINC\"][\n",
    "    [\n",
    "        \"val/mse\",\n",
    "        \"model.model_name\",\n",
    "        \"model.model_domain\",\n",
    "        \"transforms.sann_encoding.neighborhoods\",\n",
    "        \"model.backbone.n_layers\",\n",
    "    ]\n",
    "].sort_values(by=(\"val/mse\", \"mean\"), ascending=True)\n",
    "df_mantra_name[\"model.model_name\"].unique()\n",
    "# df_mantra_name[df_mantra_name['model.model_name']=='HOPSE_GPSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test/accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val/accuracy</th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>transforms.sann_encoding.max_rank</th>\n",
       "      <th>model.model_domain</th>\n",
       "      <th>transforms.sann_encoding.neighborhoods</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "      <th>optimizer.parameters.weight_decay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>97.0051</td>\n",
       "      <td>1.2179</td>\n",
       "      <td>5</td>\n",
       "      <td>96.9087</td>\n",
       "      <td>1.1758</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>96.7659</td>\n",
       "      <td>1.0780</td>\n",
       "      <td>5</td>\n",
       "      <td>96.5100</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>96.4951</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>5</td>\n",
       "      <td>96.3635</td>\n",
       "      <td>1.4067</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>95.8832</td>\n",
       "      <td>1.4888</td>\n",
       "      <td>5</td>\n",
       "      <td>95.8201</td>\n",
       "      <td>1.3570</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>95.6124</td>\n",
       "      <td>1.6675</td>\n",
       "      <td>5</td>\n",
       "      <td>95.7126</td>\n",
       "      <td>1.3051</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>88.6064</td>\n",
       "      <td>13.9130</td>\n",
       "      <td>5</td>\n",
       "      <td>74.1103</td>\n",
       "      <td>35.8536</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>94.8299</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>5</td>\n",
       "      <td>74.0121</td>\n",
       "      <td>38.5558</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'down_incidence-1', 'down_i...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>94.3978</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>5</td>\n",
       "      <td>73.9713</td>\n",
       "      <td>35.8221</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>81.4984</td>\n",
       "      <td>29.3627</td>\n",
       "      <td>5</td>\n",
       "      <td>72.3041</td>\n",
       "      <td>35.1230</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>94.2142</td>\n",
       "      <td>1.0297</td>\n",
       "      <td>5</td>\n",
       "      <td>69.4613</td>\n",
       "      <td>35.0128</td>\n",
       "      <td>5</td>\n",
       "      <td>HOPSE_MANUAL_PE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>simplicial</td>\n",
       "      <td>['up_adjacency-0', 'up_incidence-0', 'up_incid...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    test/accuracy                val/accuracy                model.model_name  \\\n",
       "             mean      std count         mean      std count                    \n",
       "504       97.0051   1.2179     5      96.9087   1.1758     5  HOPSE_MANUAL_PE   \n",
       "506       96.7659   1.0780     5      96.5100   0.9742     5  HOPSE_MANUAL_PE   \n",
       "516       96.4951   1.5603     5      96.3635   1.4067     5  HOPSE_MANUAL_PE   \n",
       "508       95.8832   1.4888     5      95.8201   1.3570     5  HOPSE_MANUAL_PE   \n",
       "512       95.6124   1.6675     5      95.7126   1.3051     5  HOPSE_MANUAL_PE   \n",
       "..            ...      ...   ...          ...      ...   ...              ...   \n",
       "511       88.6064  13.9130     5      74.1103  35.8536     5  HOPSE_MANUAL_PE   \n",
       "493       94.8299   0.0124     5      74.0121  38.5558     5  HOPSE_MANUAL_PE   \n",
       "531       94.3978   0.9127     5      73.9713  35.8221     5  HOPSE_MANUAL_PE   \n",
       "635       81.4984  29.3627     5      72.3041  35.1230     5  HOPSE_MANUAL_PE   \n",
       "585       94.2142   1.0297     5      69.4613  35.0128     5  HOPSE_MANUAL_PE   \n",
       "\n",
       "    transforms.sann_encoding.max_rank model.model_domain  \\\n",
       "                                                           \n",
       "504                               2.0         simplicial   \n",
       "506                               2.0         simplicial   \n",
       "516                               2.0         simplicial   \n",
       "508                               2.0         simplicial   \n",
       "512                               2.0         simplicial   \n",
       "..                                ...                ...   \n",
       "511                               2.0         simplicial   \n",
       "493                               2.0         simplicial   \n",
       "531                               2.0         simplicial   \n",
       "635                               2.0         simplicial   \n",
       "585                               2.0         simplicial   \n",
       "\n",
       "                transforms.sann_encoding.neighborhoods  \\\n",
       "                                                         \n",
       "504  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "506  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "516  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "508  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "512  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "..                                                 ...   \n",
       "511  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "493  ['up_adjacency-0', 'down_incidence-1', 'down_i...   \n",
       "531  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "635                                 ['up_adjacency-0']   \n",
       "585  ['up_adjacency-0', 'up_incidence-0', 'up_incid...   \n",
       "\n",
       "    model.backbone.n_layers optimizer.parameters.weight_decay  \n",
       "                                                               \n",
       "504                     1.0                            0.0000  \n",
       "506                     1.0                            0.0001  \n",
       "516                     2.0                            0.0000  \n",
       "508                     1.0                            0.0000  \n",
       "512                     2.0                            0.0000  \n",
       "..                      ...                               ...  \n",
       "511                     1.0                            0.0001  \n",
       "493                     2.0                            0.0000  \n",
       "531                     1.0                            0.0001  \n",
       "635                     2.0                            0.0001  \n",
       "585                     2.0                            0.0000  \n",
       "\n",
       "[168 rows x 12 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = collect_subsets[\"MANTRA_name\"][\n",
    "    collect_subsets[\"MANTRA_name\"][\"model.model_name\"] == \"HOPSE_MANUAL_PE\"\n",
    "][\n",
    "    [\n",
    "        \"test/accuracy\",\n",
    "        \"val/accuracy\",\n",
    "        \"model.model_name\",\n",
    "        \"transforms.sann_encoding.max_rank\",\n",
    "        \"model.model_domain\",\n",
    "        \"transforms.sann_encoding.neighborhoods\",\n",
    "        \"model.backbone.n_layers\",\n",
    "        \"optimizer.parameters.weight_decay\",\n",
    "    ]\n",
    "].sort_values(by=(\"val/accuracy\", \"mean\"), ascending=False)\n",
    "# df_test = collect_subsets['PROTEINS'][[ 'test/accuracy', 'val/accuracy', 'model.model_name', 'model.model_domain', 'transforms.sann_encoding.neighborhoods', 'model.backbone.n_layers']].sort_values(by=('test/accuracy', 'mean'), ascending=False)\n",
    "# df_test[df_test['model.model_name']=='HOPSE_GPSE']['model.model_domain'].unique()\n",
    "# df_test.iloc[0]['transforms.sann_encoding.neighborhoods'].item()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_list_to_name(inc_list):\n",
    "    inc_list = eval(inc_list)\n",
    "    inc_name = \"\"\n",
    "    for inc in inc_list:\n",
    "        inc_num = inc.split(\"-\")\n",
    "        inc_val = int(inc_num[0]) if len(inc_num) == 3 else 1\n",
    "        dim = int(inc_num[-1])\n",
    "\n",
    "        key = \"\"\n",
    "        if \"incidence\" in inc:\n",
    "            if \"up\" in inc:\n",
    "                key = f\"U_{dim}_{dim + inc_val}\"\n",
    "            elif \"down\" in inc:\n",
    "                key = f\"L_{dim - inc_val}_{dim}\"\n",
    "            else:\n",
    "                raise Exception(\"Unknown NHBD\")\n",
    "        elif \"adjacency\" in inc:\n",
    "            key = \"A_\"\n",
    "            if \"up\" in inc:\n",
    "                key = f\"A_{dim}\"\n",
    "            elif \"down\" in inc:\n",
    "                key = f\"A_{dim}\"\n",
    "            else:\n",
    "                raise Exception(\"Unknown NHBD\")\n",
    "        inc_name += key + \",\"\n",
    "    return inc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROTEINS max\n",
      "NCI109 max\n",
      "NCI1 max\n",
      "IMDB-BINARY max\n",
      "ZINC min\n",
      "IMDB-MULTI max\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    agg_sub = collect_subsets[dataset].copy()\n",
    "    eval_metric = optimization_metrics[dataset][\"eval_metric\"]\n",
    "    optim_dir = optimization_metrics[dataset][\"direction\"]\n",
    "    print(dataset, optim_dir)\n",
    "    agg_sub.sort_values(\n",
    "        by=(eval_metric, \"mean\"), ascending=(optim_dir == \"min\"), inplace=True\n",
    "    )\n",
    "    agg_subset = agg_sub[:10].copy()\n",
    "\n",
    "    cols = [\n",
    "        \"transforms.sann_encoding.neighborhoods\",\n",
    "        \"transforms.sann_encoding.pretrain_model\",\n",
    "        \"model.backbone.n_layers\",\n",
    "        \"model.model_domain\",\n",
    "        \"model.feature_encoder.proj_dropout\",\n",
    "        \"model.feature_encoder.out_channels\",\n",
    "        \"optimizer.parameters.weight_decay\",\n",
    "        \"optimizer.parameters.lr\",\n",
    "        \"dataset.dataloader_params.batch_size\",\n",
    "    ]\n",
    "\n",
    "    # iterate over rows\n",
    "    model_names = []\n",
    "    for index, row in agg_subset.iterrows():\n",
    "        m_name = row[\"model.model_name\"].item()\n",
    "        # Get values of the row\n",
    "        values = [row[col].item() for col in cols]\n",
    "        is_sann = \"SANN\" in m_name\n",
    "\n",
    "        model_name = f\"{m_name}|\"\n",
    "        for col, value in zip(cols, values):\n",
    "            if col == \"transforms.sann_encoding.max_hop\" and is_sann:\n",
    "                model_name += f\"Hop={value}|\"\n",
    "            elif col == \"model.backbone.n_layers\":\n",
    "                model_name += f\"L={value}|\"\n",
    "            elif (\n",
    "                col == \"transforms.sann_encoding.neighborhoods\" and not is_sann\n",
    "            ):\n",
    "                model_name += f\"NH={inc_list_to_name(value)}|\"\n",
    "            elif col == \"model.feature_encoder.out_channels\":\n",
    "                model_name += f\"OCs={value}|\"\n",
    "            elif col == \"optimizer.parameters.lr\":\n",
    "                model_name += f\"LR={value}|\"\n",
    "            elif col == \"optimizer.parameters.weight_decay\":\n",
    "                model_name += f\"WD={value}|\"\n",
    "            elif col == \"dataset.dataloader_params.batch_size\":\n",
    "                model_name += f\"BS={value}|\"\n",
    "        model_names.append(model_name)\n",
    "    agg_subset[\"Model_name\"] = model_names\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    model_names = agg_subset[\"Model_name\"]\n",
    "\n",
    "    accuracy_means = np.array(agg_subset[(eval_metric, \"mean\")])\n",
    "    accuracy_stds = np.array(agg_subset[(eval_metric, \"std\")])\n",
    "    bars = plt.bar(\n",
    "        model_names,\n",
    "        accuracy_means,\n",
    "        yerr=accuracy_stds,\n",
    "        capsize=5,\n",
    "        color=\"skyblue\",\n",
    "    )\n",
    "\n",
    "    accuracy_means = np.array(agg_subset[(eval_metric, \"mean\")])\n",
    "    # Adding data labels on top of bars\n",
    "    for bar, mean in zip(bars, accuracy_means):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 0.2,\n",
    "            f\"{mean:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    # plt.xticks(rotation=45)\n",
    "    plt.title(f\"Model performance for {dataset} dataset\")\n",
    "    plt.ylabel(f\"Test {eval_metric}\")\n",
    "    plt.tight_layout()\n",
    "    delta = agg_subset[(eval_metric, \"std\")].max() + 1\n",
    "    plt.ylim(\n",
    "        (agg_subset[(eval_metric, \"mean\")].min() - delta).round(),\n",
    "        (agg_subset[(eval_metric, \"mean\")].max() + delta).round(),\n",
    "    )\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"figures/{dataset}_performance.png\", dpi=300, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    aggregated = collect_subsets[dataset]\n",
    "    for m_name in aggregated[\"model.model_name\"].unique():\n",
    "        agg_sub = aggregated[aggregated[\"model.model_name\"] == m_name].copy()\n",
    "        optim_metric = optimization_metrics[dataset][\"eval_metric\"]\n",
    "        optim_dir = optimization_metrics[dataset][\"direction\"]\n",
    "        agg_sub.sort_values(\n",
    "            by=(optim_metric, \"mean\"),\n",
    "            ascending=(optim_dir == \"min\"),\n",
    "            inplace=True,\n",
    "        )\n",
    "        agg_subset = agg_sub[:10].copy()\n",
    "\n",
    "        cols = [\n",
    "            \"transforms.sann_encoding.neighborhoods\",\n",
    "            \"transforms.sann_encoding.pretrain_model\",\n",
    "            \"model.backbone.n_layers\",\n",
    "            \"model.model_domain\",\n",
    "            \"model.feature_encoder.out_channels\",\n",
    "            \"optimizer.parameters.weight_decay\",\n",
    "            \"optimizer.parameters.lr\",\n",
    "            \"model.feature_encoder.proj_dropout\",\n",
    "            \"dataset.dataloader_params.batch_size\",\n",
    "        ]\n",
    "\n",
    "        # iterate over rows\n",
    "        model_names = []\n",
    "        for index, row in agg_subset.iterrows():\n",
    "            # Get values of the row\n",
    "            values = [row[col].item() for col in cols]\n",
    "            is_sann = \"SANN\" in m_name\n",
    "\n",
    "            model_name = f\"{m_name}|\"\n",
    "            for col, value in zip(cols, values):\n",
    "                if col == \"transforms.sann_encoding.max_hop\" and is_sann:\n",
    "                    model_name += f\"Hop={value}|\"\n",
    "                elif col == \"model.backbone.n_layers\":\n",
    "                    model_name += f\"L={value}|\"\n",
    "                elif (\n",
    "                    col == \"transforms.sann_encoding.neighborhoods\"\n",
    "                    and not is_sann\n",
    "                ):\n",
    "                    model_name += f\"NH={inc_list_to_name(value)}|\"\n",
    "                elif col == \"model.feature_encoder.out_channels\":\n",
    "                    model_name += f\"OCs={value}|\"\n",
    "                elif col == \"optimizer.parameters.lr\":\n",
    "                    model_name += f\"LR={value}|\"\n",
    "                elif col == \"optimizer.parameters.weight_decay\":\n",
    "                    model_name += f\"WD={value}|\"\n",
    "                elif col == \"dataset.dataloader_params.batch_size\":\n",
    "                    model_name += f\"BS={value}|\"\n",
    "            model_names.append(model_name)\n",
    "        agg_subset[\"Model_name\"] = model_names\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        model_names = agg_subset[\"Model_name\"]\n",
    "\n",
    "        accuracy_means = np.array(agg_subset[(optim_metric, \"mean\")])\n",
    "        accuracy_stds = np.array(agg_subset[(optim_metric, \"std\")])\n",
    "        bars = plt.bar(\n",
    "            model_names,\n",
    "            accuracy_means,\n",
    "            yerr=accuracy_stds,\n",
    "            capsize=5,\n",
    "            color=\"skyblue\",\n",
    "        )\n",
    "\n",
    "        accuracy_means = np.array(agg_subset[(optim_metric, \"mean\")])\n",
    "        # Adding data labels on top of bars\n",
    "        for bar, mean in zip(bars, accuracy_means):\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height() + 0.2,\n",
    "                f\"{mean:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "        # plt.xticks(rotation=45)\n",
    "        plt.title(f\"Model performance for {dataset} dataset\")\n",
    "        plt.ylabel(\"Test accuracy\")\n",
    "        plt.tight_layout()\n",
    "        delta = agg_subset[(optim_metric, \"std\")].max() + 1\n",
    "        plt.ylim(\n",
    "            (agg_subset[(optim_metric, \"mean\")].min() - delta).round(),\n",
    "            (agg_subset[(optim_metric, \"mean\")].max() + delta).round(),\n",
    "        )\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        # Rotate x-axis labels\n",
    "        plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "\n",
    "        plt.savefig(\n",
    "            f\"figures/{m_name}_performance_{dataset}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\"model\": [], \"dataset\": [], \"mean\": [], \"std\": [], \"domain\": []}\n",
    "\n",
    "for dataset in datasets:\n",
    "    aggregated = collect_subsets[dataset]\n",
    "    for m_name in aggregated[\"model.model_name\"].unique():\n",
    "        for domain in aggregated[\"model.model_domain\"].unique():\n",
    "            agg_sub = aggregated[\n",
    "                (aggregated[\"model.model_name\"] == m_name)\n",
    "                & (aggregated[\"model.model_domain\"] == domain)\n",
    "            ].copy()\n",
    "            optim_metric = optimization_metrics[dataset][\"optim_metric\"]\n",
    "            eval_metric = optimization_metrics[dataset][\"eval_metric\"]\n",
    "            optim_dir = optimization_metrics[dataset][\"direction\"]\n",
    "            agg_sub.sort_values(\n",
    "                by=(optim_metric, \"mean\"),\n",
    "                ascending=(optim_dir == \"min\"),\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "            df_dict[\"domain\"].append(\n",
    "                agg_sub.iloc[0][\"model.model_domain\"].item()\n",
    "            )\n",
    "            df_dict[\"model\"].append(m_name)\n",
    "            df_dict[\"dataset\"].append(dataset)\n",
    "            df_dict[\"mean\"].append(agg_sub.iloc[0][(eval_metric, \"mean\")])\n",
    "            df_dict[\"std\"].append(agg_sub.iloc[0][(eval_metric, \"std\")])\n",
    "df_res = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.extend(\n",
    "    [\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 83.40,\n",
    "            \"std\": 4.85,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.05,\n",
    "            \"std\": 2.16,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 76.11,\n",
    "            \"std\": 1.69,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 75.62,\n",
    "            \"std\": 0.76,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.38,\n",
    "            \"std\": 0.03,\n",
    "        },\n",
    "        # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.39, 'std': 0.65},\n",
    "        # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 74.62, 'std': 1.95},\n",
    "        # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 87.68, 'std': 0.33},\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 85.11,\n",
    "            \"std\": 6.73,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.41,\n",
    "            \"std\": 1.77,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 76.42,\n",
    "            \"std\": 1.67,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 75.62,\n",
    "            \"std\": 0.94,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.36,\n",
    "            \"std\": 0.01,\n",
    "        },\n",
    "        # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.51, 'std': 0.70},\n",
    "        # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.41, 'std': 2.00},\n",
    "        # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.18, 'std': 0.26},\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 86.38,\n",
    "            \"std\": 6.49,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 72.54,\n",
    "            \"std\": 3.07,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 77.65,\n",
    "            \"std\": 1.11,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 77.19,\n",
    "            \"std\": 0.21,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.19,\n",
    "            \"std\": 0.00,\n",
    "        },\n",
    "        # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'Cora', 'mean': 87.42, 'std': 1.85},\n",
    "        # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.13, 'std': 1.17},\n",
    "        # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.47, 'std': 0.27},\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 85.53,\n",
    "            \"std\": 6.80,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 73.62,\n",
    "            \"std\": 2.72,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 78.23,\n",
    "            \"std\": 1.47,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 77.10,\n",
    "            \"std\": 0.83,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.24,\n",
    "            \"std\": 0.00,\n",
    "        },\n",
    "        # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.57, 'std': 0.58},\n",
    "        # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.89, 'std': 1.84},\n",
    "        # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 89.40, 'std': 0.57},\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 83.83,\n",
    "            \"std\": 6.49,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 70.97,\n",
    "            \"std\": 4.06,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 73.00,\n",
    "            \"std\": 1.37,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 73.20,\n",
    "            \"std\": 1.05,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.45,\n",
    "            \"std\": 0.02,\n",
    "        },\n",
    "        # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'Cora', 'mean': 84.61, 'std': 1.32},\n",
    "        # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.05, 'std': 1.67},\n",
    "        # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.37, 'std': 0.22},\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 85.96,\n",
    "            \"std\": 7.15,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 73.73,\n",
    "            \"std\": 2.95,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 76.75,\n",
    "            \"std\": 1.63,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 76.94,\n",
    "            \"std\": 0.82,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"cell\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.31,\n",
    "            \"std\": 0.01,\n",
    "        },\n",
    "        # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'Cora', 'mean': 87.24, 'std': 0.58},\n",
    "        # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 74.26, 'std': 1.47},\n",
    "        # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.65, 'std': 0.55},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Simplicial models\n",
    "data.extend(\n",
    "    [\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 79.15,\n",
    "            \"std\": 4.09,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.62,\n",
    "            \"std\": 1.95,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 74.86,\n",
    "            \"std\": 1.42,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 74.81,\n",
    "            \"std\": 1.14,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GAT\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.57,\n",
    "            \"std\": 0.03,\n",
    "        },\n",
    "        # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.33, 'std': 0.67},\n",
    "        # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.65, 'std': 1.93},\n",
    "        # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 87.72, 'std': 0.36},\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 74.04,\n",
    "            \"std\": 8.30,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.91,\n",
    "            \"std\": 2.51,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 74.20,\n",
    "            \"std\": 2.17,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 74.13,\n",
    "            \"std\": 0.53,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GCN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.53,\n",
    "            \"std\": 0.05,\n",
    "        },\n",
    "        # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.51, 'std': 0.70},\n",
    "        # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.41, 'std': 2.00},\n",
    "        # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.19, 'std': 0.24},\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 85.96,\n",
    "            \"std\": 4.66,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 72.83,\n",
    "            \"std\": 2.72,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 76.67,\n",
    "            \"std\": 1.62,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 75.76,\n",
    "            \"std\": 1.28,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GIN\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.35,\n",
    "            \"std\": 0.01,\n",
    "        },\n",
    "        # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 87.27, 'std': 1.63},\n",
    "        # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.05, 'std': 1.27},\n",
    "        # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.54, 'std': 0.21},\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 75.74,\n",
    "            \"std\": 2.43,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.70,\n",
    "            \"std\": 3.10,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 76.85,\n",
    "            \"std\": 1.50,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 75.64,\n",
    "            \"std\": 1.94,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with GraphSAGE\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.50,\n",
    "            \"std\": 0.02,\n",
    "        },\n",
    "        # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.57, 'std': 0.59},\n",
    "        # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.92, 'std': 1.85},\n",
    "        # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 89.34, 'std': 0.39},\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 74.04,\n",
    "            \"std\": 4.09,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 70.97,\n",
    "            \"std\": 4.06,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 70.39,\n",
    "            \"std\": 0.96,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 69.99,\n",
    "            \"std\": 1.13,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Transformer\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.64,\n",
    "            \"std\": 0.01,\n",
    "        },\n",
    "        # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 84.40, 'std': 1.16},\n",
    "        # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.60, 'std': 1.88},\n",
    "        # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.55, 'std': 0.39},\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"MUTAG\",\n",
    "            \"mean\": 74.04,\n",
    "            \"std\": 5.51,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"PROTEINS\",\n",
    "            \"mean\": 74.48,\n",
    "            \"std\": 1.89,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI1\",\n",
    "            \"mean\": 75.02,\n",
    "            \"std\": 2.24,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"NCI109\",\n",
    "            \"mean\": 73.91,\n",
    "            \"std\": 3.90,\n",
    "        },\n",
    "        {\n",
    "            \"model\": \"GCCN with Hasse\",\n",
    "            \"domain\": \"simplicial\",\n",
    "            \"dataset\": \"ZINC\",\n",
    "            \"mean\": 0.56,\n",
    "            \"std\": 0.02,\n",
    "        },\n",
    "        # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 87.56, 'std': 0.66},\n",
    "        # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.50, 'std': 1.61},\n",
    "        # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.61, 'std': 0.27},\n",
    "    ]\n",
    ")\n",
    "topotune_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the raw table data\n",
    "raw_table_data = {\n",
    "    # Format: {dataset: [(method, mean, std), ...]}\n",
    "    # 'Cora': [\n",
    "    #     ('CWN', 74.95, 0.98),\n",
    "    #     ('CCCN', 86.32, 1.38),\n",
    "    #     ('SCCNN', 87.44, 1.17),\n",
    "    #     ('SCN', 87.68, 1.17),\n",
    "    #     ('DR_cell', 82.19, 1.07),\n",
    "    #     ('SDP_cell', 80.65, 2.39),\n",
    "    #     ('DR_simplicial', 82.27, 1.34),\n",
    "    #     ('SDP_simplicial', 79.91, 1.18)\n",
    "    # ],\n",
    "    # 'Citeseer': [\n",
    "    #     ('CWN', 70.49, 2.85),\n",
    "    #     ('CCCN', 75.20, 1.82),\n",
    "    #     ('SCCNN', 75.63, 1.58),\n",
    "    #     ('SCN', 74.91, 1.25),\n",
    "    #     ('DR_cell', 70.23, 2.69),\n",
    "    #     ('SDP_cell', 69.03, 2.01),\n",
    "    #     ('DR_simplicial', 71.24, 1.68),\n",
    "    #     ('SDP_simplicial', 70.40, 1.53)\n",
    "    # ],\n",
    "    # 'PubMed': [\n",
    "    #     ('CWN', 86.94, 0.68),\n",
    "    #     ('CCCN', 88.64, 0.36),\n",
    "    #     ('SCCNN', 88.52, 0.44),\n",
    "    #     ('SCN', 88.67, 0.39),\n",
    "    #     ('DR_cell', 88.18, 0.32),\n",
    "    #     ('SDP_cell', 87.78, 0.58),\n",
    "    #     ('DR_simplicial', 88.72, 0.50),\n",
    "    #     ('SDP_simplicial', 88.62, 0.44)\n",
    "    # ],\n",
    "    \"MUTAG\": [\n",
    "        (\"CWN\", 69.68, 8.58),\n",
    "        (\"CCCN\", 80.43, 1.78),\n",
    "        (\"SCCNN\", 80.85, 5.42),\n",
    "        (\"SCN\", 77.02, 9.32),\n",
    "        (\"DR_cell\", 76.17, 6.63),\n",
    "        (\"SDP_cell\", 70.64, 3.16),\n",
    "        (\"DR_simplicial\", 71.49, 2.43),\n",
    "        (\"SDP_simplicial\", 73.62, 6.13),\n",
    "    ],\n",
    "    \"PROTEINS\": [\n",
    "        (\"CWN\", 76.13, 1.80),\n",
    "        (\"CCCN\", 76.13, 2.70),\n",
    "        (\"SCCNN\", 73.55, 3.43),\n",
    "        (\"SCN\", 73.33, 2.30),\n",
    "        (\"DR_cell\", 74.19, 2.86),\n",
    "        (\"SDP_cell\", 74.98, 1.92),\n",
    "        (\"DR_simplicial\", 75.27, 2.14),\n",
    "        (\"SDP_simplicial\", 74.77, 1.69),\n",
    "    ],\n",
    "    \"NCI1\": [\n",
    "        (\"CWN\", 68.52, 0.51),\n",
    "        (\"CCCN\", 73.93, 1.87),\n",
    "        (\"SCCNN\", 76.67, 1.48),\n",
    "        (\"SCN\", 77.65, 1.28),\n",
    "        (\"DR_cell\", 76.60, 1.75),\n",
    "        (\"SDP_cell\", 75.60, 2.45),\n",
    "        (\"DR_simplicial\", 75.27, 1.57),\n",
    "        (\"SDP_simplicial\", 74.49, 1.03),\n",
    "    ],\n",
    "    \"NCI109\": [\n",
    "        (\"CWN\", 68.19, 0.65),\n",
    "        (\"CCCN\", 73.80, 2.06),\n",
    "        (\"SCCNN\", 75.35, 1.50),\n",
    "        (\"SCN\", 74.83, 1.18),\n",
    "        (\"DR_cell\", 77.12, 1.07),\n",
    "        (\"SDP_cell\", 75.43, 1.94),\n",
    "        (\"DR_simplicial\", 74.58, 1.29),\n",
    "        (\"SDP_simplicial\", 75.70, 1.04),\n",
    "    ],\n",
    "    \"ZINC\": [\n",
    "        (\"CWN\", 0.70, 0.00),\n",
    "        (\"CCCN\", 0.34, 0.01),\n",
    "        (\"SCCNN\", 0.35, 0.02),\n",
    "        (\"SCN\", 0.34, 0.02),\n",
    "        (\"DR_cell\", 0.36, 0.01),\n",
    "        (\"SDP_cell\", 0.36, 0.02),\n",
    "        (\"DR_simplicial\", 0.59, 0.01),\n",
    "        (\"SDP_simplicial\", 0.53, 0.04),\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Process the data to select the best of DR and SDP for each method\n",
    "additional_data = []\n",
    "\n",
    "for dataset, entries in raw_table_data.items():\n",
    "    optim_dir = optimization_metrics[dataset][\"direction\"]\n",
    "\n",
    "    # Group data by method prefix (before the underscore)\n",
    "    method_results = {}\n",
    "    standard_methods = []\n",
    "    dr_sdp_methods = {\"cell\": {}, \"simplicial\": {}}\n",
    "\n",
    "    for method, mean, std in entries:\n",
    "        if method in [\"CWN\", \"CCCN\", \"SCCNN\", \"SCN\"]:\n",
    "            # These are the standard methods - just add them directly\n",
    "            standard_methods.append(\n",
    "                {\n",
    "                    \"method\": method,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"mean\": mean,\n",
    "                    \"std\": std,\n",
    "                }\n",
    "            )\n",
    "        elif method.startswith(\"DR_\") or method.startswith(\"SDP_\"):\n",
    "            # These are DR or SDP methods - group by domain\n",
    "            method_type, domain = method.split(\"_\")\n",
    "            dr_sdp_methods[domain][method_type] = {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    # Add all standard methods\n",
    "    additional_data.extend(standard_methods)\n",
    "\n",
    "    # Select the best of DR/SDP for each domain\n",
    "    for domain in [\"cell\", \"simplicial\"]:\n",
    "        if \"DR\" in dr_sdp_methods[domain] and \"SDP\" in dr_sdp_methods[domain]:\n",
    "            dr_result = dr_sdp_methods[domain][\"DR\"]\n",
    "            sdp_result = dr_sdp_methods[domain][\"SDP\"]\n",
    "\n",
    "            # Determine which is better based on optimization direction\n",
    "            if optim_dir == \"max\":\n",
    "                if dr_result[\"mean\"] >= sdp_result[\"mean\"]:\n",
    "                    best_method = \"DR\"\n",
    "                    best_result = dr_result\n",
    "                else:\n",
    "                    best_method = \"SDP\"\n",
    "                    best_result = sdp_result\n",
    "            else:  # min direction\n",
    "                if dr_result[\"mean\"] <= sdp_result[\"mean\"]:\n",
    "                    best_method = \"DR\"\n",
    "                    best_result = dr_result\n",
    "                else:\n",
    "                    best_method = \"SDP\"\n",
    "                    best_result = sdp_result\n",
    "\n",
    "            # Add the best result\n",
    "            method_name = f\"{best_method}_{domain}\"\n",
    "            additional_data.append(\n",
    "                {\n",
    "                    \"method\": method_name,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"mean\": best_result[\"mean\"],\n",
    "                    \"std\": best_result[\"std\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "# Map method names to their proper format in the data\n",
    "method_mappings = {\n",
    "    \"CWN\": \"Cell CWN\",\n",
    "    \"CCCN\": \"CCNN\",  # Cell CCNN\n",
    "    \"SCCNN\": \"Simplicial CCNN\",\n",
    "    \"SCN\": \"Simplicial SCN\",\n",
    "    \"DR_cell\": \"Cell DR\",\n",
    "    \"SDP_cell\": \"Cell SDP\",\n",
    "    \"DR_simplicial\": \"DR\",\n",
    "    \"SDP_simplicial\": \"SDP\",\n",
    "}\n",
    "\n",
    "# Domain mappings\n",
    "domain_mappings = {\n",
    "    \"CWN\": \"cell\",\n",
    "    \"CCCN\": \"cell\",\n",
    "    \"SCCNN\": \"simplicial\",\n",
    "    \"SCN\": \"simplicial\",\n",
    "    \"DR_cell\": \"cell\",\n",
    "    \"SDP_cell\": \"cell\",\n",
    "    \"DR_simplicial\": \"simplicial\",\n",
    "    \"SDP_simplicial\": \"simplicial\",\n",
    "}\n",
    "\n",
    "# For display purposes, we'll use simplified method names\n",
    "display_mappings = {\n",
    "    \"DR_cell\": \"DR\",\n",
    "    \"SDP_cell\": \"SDP\",\n",
    "    \"DR_simplicial\": \"DR\",\n",
    "    \"SDP_simplicial\": \"SDP\",\n",
    "}\n",
    "\n",
    "# Convert the additional data to the proper format for the dataframe\n",
    "formatted_data = []\n",
    "for item in additional_data:\n",
    "    formatted_data.append(\n",
    "        {\n",
    "            \"model\": method_mappings[item[\"method\"]],\n",
    "            \"domain\": domain_mappings[item[\"method\"]],\n",
    "            \"dataset\": item[\"dataset\"],\n",
    "            \"mean\": item[\"mean\"],\n",
    "            \"std\": item[\"std\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# This data can now be added to your existing dataframe or used to create a new one\n",
    "tbx_df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_add_df = pd.concat([df_res, topotune_df, tbx_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, dataset, mean, std, domain]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_add_df[\n",
    "    final_add_df.duplicated(subset=[\"model\", \"dataset\", \"domain\"], keep=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df):\n",
    "    \"\"\"\n",
    "    Generates a LaTeX table with methods as rows and datasets as columns.\n",
    "    For models containing \"with\", splits into first word (model) and last word (variant).\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with columns 'model', 'domain', 'dataset', 'mean', and 'std'\n",
    "\n",
    "    Returns:\n",
    "    tuple: (LaTeX preamble, LaTeX table code)\n",
    "    \"\"\"\n",
    "    # Ensure df has required columns\n",
    "    required_columns = [\"model\", \"domain\", \"dataset\", \"mean\", \"std\"]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(\"DataFrame must contain column: {}\".format(col))\n",
    "\n",
    "    # Remove duplicates and show warning if any are found\n",
    "    duplicates = df.duplicated(\n",
    "        subset=[\"model\", \"domain\", \"dataset\"], keep=False\n",
    "    )\n",
    "    if duplicates.any():\n",
    "        print(\n",
    "            \"Warning: Found {} duplicate entries. Using the first occurrence.\".format(\n",
    "                duplicates.sum()\n",
    "            )\n",
    "        )\n",
    "        df = df.drop_duplicates(\n",
    "            subset=[\"model\", \"domain\", \"dataset\"], keep=\"first\"\n",
    "        )\n",
    "\n",
    "    # Instead of pivot, create a dictionary structure directly\n",
    "    data_dict = {}\n",
    "\n",
    "    # Group by domain, then model, then dataset\n",
    "    for _, row in df.iterrows():\n",
    "        domain = row[\"domain\"]\n",
    "        model = row[\"model\"]\n",
    "        dataset = row[\"dataset\"]\n",
    "        mean = row[\"mean\"]\n",
    "        std = row[\"std\"]\n",
    "\n",
    "        # Initialize nested dictionaries if they don't exist\n",
    "        if domain not in data_dict:\n",
    "            data_dict[domain] = {}\n",
    "        if model not in data_dict[domain]:\n",
    "            data_dict[domain][model] = {}\n",
    "\n",
    "        # Store the mean and std values\n",
    "        data_dict[domain][model][dataset] = {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    # Get sorted lists of unique values\n",
    "    domains = sorted(data_dict.keys())\n",
    "    datasets = sorted(df[\"dataset\"].unique())\n",
    "\n",
    "    # Find best results for each dataset\n",
    "    best_results = {}\n",
    "\n",
    "    for dataset in datasets:\n",
    "        all_means = []\n",
    "        for domain in domains:\n",
    "            for model in data_dict[domain]:\n",
    "                if dataset in data_dict[domain][model]:\n",
    "                    all_means.append(data_dict[domain][model][dataset][\"mean\"])\n",
    "\n",
    "        if all_means:\n",
    "            optim_dir = optimization_metrics.get(\n",
    "                dataset, {\"direction\": \"max\"}\n",
    "            )[\"direction\"]\n",
    "            if optim_dir == \"max\":\n",
    "                best_results[dataset] = max(all_means)\n",
    "            else:\n",
    "                best_results[dataset] = min(all_means)\n",
    "\n",
    "    # Helper function to process model names for display\n",
    "    def process_model_name(model_name, domain):\n",
    "        # Remove domain prefix if present\n",
    "        domain_prefix = domain.capitalize() + \" \"\n",
    "        if model_name.startswith(domain_prefix):\n",
    "            model_name = model_name[len(domain_prefix) :]\n",
    "\n",
    "        # For models with \"with\", split into main model and variant\n",
    "        if \" with \" in model_name:\n",
    "            parts = model_name.split()\n",
    "            main_model = parts[0]  # First word (usually GCCN)\n",
    "            variant = parts[-1]  # Last word after \"with\"\n",
    "            return main_model, variant\n",
    "        elif \"GPSE\" in model_name:\n",
    "            # Special handling for GPSE\n",
    "            return \"GPSE\", model_name.replace(\"GPSE\", \"\").strip()\n",
    "        else:\n",
    "            # No splitting needed\n",
    "            return model_name, \"\"\n",
    "\n",
    "    # Function to generate a LaTeX row for a model\n",
    "    def generate_model_row(\n",
    "        model, domain, is_first_in_group=False, group_name=\"\"\n",
    "    ):\n",
    "        # Process model name\n",
    "        main_model, variant = process_model_name(model, domain)\n",
    "\n",
    "        # Start row\n",
    "        if is_first_in_group:\n",
    "            row = \"\\\\multirow{{1}}{{*}}{{{}}} & \".format(group_name)\n",
    "        else:\n",
    "            row = \" & \"\n",
    "\n",
    "        # Add variant name\n",
    "        row += \"\\\\emph{{{}}}\".format(variant if variant else main_model)\n",
    "\n",
    "        # Add data for each dataset\n",
    "        for dataset in datasets:\n",
    "            if dataset in data_dict[domain][model]:\n",
    "                mean = data_dict[domain][model][dataset][\"mean\"]\n",
    "                std = data_dict[domain][model][dataset][\"std\"]\n",
    "\n",
    "                # Format based on whether it's the best result\n",
    "                if dataset in best_results and np.isclose(\n",
    "                    mean, best_results[dataset]\n",
    "                ):\n",
    "                    row += \" & \\\\cellcolor{{gray!30}}\\\\textbf{{{0:.3f}}} \\\\scriptsize{{±{1:.3f}}}\".format(\n",
    "                        mean, std\n",
    "                    )\n",
    "                else:\n",
    "                    # Check if within one standard deviation of best\n",
    "                    optim_dir = optimization_metrics.get(\n",
    "                        dataset, {\"direction\": \"max\"}\n",
    "                    )[\"direction\"]\n",
    "                    threshold = (\n",
    "                        best_results[dataset] - std\n",
    "                        if dataset in best_results\n",
    "                        else None\n",
    "                    )\n",
    "\n",
    "                    if threshold is not None:\n",
    "                        if (optim_dir == \"max\" and mean >= threshold) or (\n",
    "                            optim_dir == \"min\" and mean <= threshold\n",
    "                        ):\n",
    "                            row += \" & \\\\cellcolor{{blue!20}}{0:.3f} \\\\scriptsize{{±{1:.3f}}}\".format(\n",
    "                                mean, std\n",
    "                            )\n",
    "                        else:\n",
    "                            row += (\n",
    "                                \" & {0:.3f} \\\\scriptsize{{±{1:.3f}}}\".format(\n",
    "                                    mean, std\n",
    "                                )\n",
    "                            )\n",
    "                    else:\n",
    "                        row += \" & {0:.3f} \\\\scriptsize{{±{1:.3f}}}\".format(\n",
    "                            mean, std\n",
    "                        )\n",
    "            else:\n",
    "                row += \" & -\"\n",
    "\n",
    "        return row + \" \\\\\\\\\"\n",
    "\n",
    "    # Generate LaTeX table\n",
    "    latex_table = []\n",
    "\n",
    "    # Process each domain\n",
    "    for domain in domains:\n",
    "        # Organize models by main type\n",
    "        domain_models = {}\n",
    "\n",
    "        # Group models based on their main type (after processing)\n",
    "        for model in data_dict[domain]:\n",
    "            main_type, _ = process_model_name(model, domain)\n",
    "\n",
    "            if main_type not in domain_models:\n",
    "                domain_models[main_type] = []\n",
    "\n",
    "            domain_models[main_type].append(model)\n",
    "\n",
    "        # Sort model groups and models within groups\n",
    "        sorted_types = sorted(domain_models.keys())\n",
    "        for model_type in sorted_types:\n",
    "            domain_models[model_type] = sorted(domain_models[model_type])\n",
    "\n",
    "        # Add domain header\n",
    "        domain_display = domain.capitalize()\n",
    "        latex_table.append(\n",
    "            \"\\\\multicolumn{{{0}}}{{l}}{{\\\\textbf{{{1} Methods}}}} \\\\\\\\\".format(\n",
    "                len(datasets) + 2, domain_display\n",
    "            )\n",
    "        )\n",
    "        latex_table.append(\"\\\\midrule\")\n",
    "\n",
    "        # Process each model type group\n",
    "        for i, model_type in enumerate(sorted_types):\n",
    "            models = domain_models[model_type]\n",
    "\n",
    "            # Add group header with multirow\n",
    "            latex_table.append(\n",
    "                \"\\\\multirow{{{0}}}{{*}}{{{1}}} & \".format(\n",
    "                    len(models), model_type\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Process each model in the group\n",
    "            for j, model in enumerate(models):\n",
    "                if j == 0:\n",
    "                    # First model in group, header already added\n",
    "                    row = generate_model_row(\n",
    "                        model,\n",
    "                        domain,\n",
    "                        is_first_in_group=True,\n",
    "                        group_name=model_type,\n",
    "                    )\n",
    "                else:\n",
    "                    # Subsequent models in group\n",
    "                    row = (\n",
    "                        \" & \"\n",
    "                        + generate_model_row(model, domain).split(\" & \", 1)[1]\n",
    "                    )\n",
    "\n",
    "                latex_table.append(row)\n",
    "\n",
    "                # Add cmidrule between models but not after the last one\n",
    "                if j < len(models) - 1:\n",
    "                    latex_table.append(\n",
    "                        \"\\\\cmidrule{{2-{0}}}\".format(len(datasets) + 2)\n",
    "                    )\n",
    "\n",
    "            # Add midrule between different model types but not after the last one\n",
    "            if i < len(sorted_types) - 1:\n",
    "                latex_table.append(\"\\\\midrule\")\n",
    "\n",
    "        # Add midrule between domains\n",
    "        if domain != domains[-1]:\n",
    "            latex_table.append(\"\\\\midrule\")\n",
    "\n",
    "    # Construct the LaTeX table header\n",
    "    dataset_labels = \" & & \" + \" & \".join(\n",
    "        [\"\\\\emph{{{}}}\".format(dataset) for dataset in datasets]\n",
    "    )\n",
    "\n",
    "    # Additional packages needed\n",
    "    preamble = \"\\\\usepackage{multirow}\\n\\\\usepackage{booktabs}\\n\\\\usepackage{colortbl}\\n\\\\usepackage{array}\"\n",
    "\n",
    "    # Create column specifications\n",
    "    col_spec = (\n",
    "        \">{{\\\\raggedright\\\\arraybackslash}}p{{2.5cm}}>{{\\\\raggedright\\\\arraybackslash}}p{{2.5cm}}\"\n",
    "        + \"c\" * len(datasets)\n",
    "    )\n",
    "\n",
    "    latex_code = (\n",
    "        \"\\\\begin{table}[h]\\n\"\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\scriptsize\\n\"\n",
    "        \"\\\\begin{tabular}{\" + col_spec + \"}\\n\"\n",
    "        \"\\\\toprule\\n\"\n",
    "        \"\\\\textbf{Method} & \\\\textbf{Variant} \"\n",
    "        + dataset_labels\n",
    "        + \" \\\\\\\\\\n\"\n",
    "        + \"\\n\".join(latex_table)\n",
    "        + \"\\n\\\\bottomrule\\n\"\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Cross-domain comparison grouped by domain type (Simplicial/Cellular): results are shown as mean and standard deviation. \"\n",
    "        \"The best result is bold and shaded in grey, while those within one standard deviation are in blue-shaded boxes.}\\n\"\n",
    "        \"\\\\end{table}\"\n",
    "    )\n",
    "\n",
    "    return preamble, latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 20 duplicate entries. Using the first occurrence.\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\scriptsize\n",
      "\\begin{tabular}{>{{\\raggedright\\arraybackslash}}p{{2.5cm}}>{{\\raggedright\\arraybackslash}}p{{2.5cm}}ccccccc}\n",
      "\\toprule\n",
      "\\textbf{Method} & \\textbf{Variant}  & & \\emph{IMDB-BINARY} & \\emph{IMDB-MULTI} & \\emph{MUTAG} & \\emph{NCI1} & \\emph{NCI109} & \\emph{PROTEINS} & \\emph{ZINC} \\\\\n",
      "\\multicolumn{9}{l}{\\textbf{Cell Methods}} \\\\\n",
      "\\midrule\n",
      "\\multirow{4}{*}{GPSE} & \n",
      "\\emph{_GEOM} & \\cellcolor{gray!30}\\textbf{73.200} \\scriptsize{±1.876} & \\cellcolor{blue!20}49.013 \\scriptsize{±3.783} & - & 78.016 \\scriptsize{±1.175} & \\cellcolor{blue!20}77.909 \\scriptsize{±1.246} & \\cellcolor{blue!20}74.767 \\scriptsize{±3.695} & 0.210 \\scriptsize{±0.002} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_MOLPCBA} & \\cellcolor{blue!20}70.960 \\scriptsize{±5.104} & \\cellcolor{gray!30}\\textbf{50.027} \\scriptsize{±3.561} & - & \\cellcolor{blue!20}78.521 \\scriptsize{±0.947} & 77.483 \\scriptsize{±0.641} & \\cellcolor{blue!20}74.839 \\scriptsize{±2.590} & 0.213 \\scriptsize{±0.005} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_PCQM4MV2} & \\cellcolor{blue!20}71.280 \\scriptsize{±4.376} & \\cellcolor{blue!20}48.640 \\scriptsize{±4.244} & - & \\cellcolor{blue!20}78.833 \\scriptsize{±1.321} & \\cellcolor{blue!20}77.812 \\scriptsize{±1.257} & \\cellcolor{gray!30}\\textbf{76.416} \\scriptsize{±3.470} & 0.212 \\scriptsize{±0.009} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_ZINC} & \\cellcolor{blue!20}72.000 \\scriptsize{±3.709} & \\cellcolor{blue!20}48.533 \\scriptsize{±4.569} & - & \\cellcolor{gray!30}\\textbf{79.280} \\scriptsize{±1.120} & \\cellcolor{gray!30}\\textbf{78.296} \\scriptsize{±1.534} & \\cellcolor{blue!20}74.839 \\scriptsize{±3.046} & 0.214 \\scriptsize{±0.002} \\\\\n",
      "\\multirow{10}{*}{Other} & \n",
      "\\emph{CCNN} & - & - & 80.430 \\scriptsize{±1.780} & 76.670 \\scriptsize{±1.480} & 75.350 \\scriptsize{±1.500} & \\cellcolor{blue!20}76.130 \\scriptsize{±2.700} & 0.340 \\scriptsize{±0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{CWN} & - & - & 69.680 \\scriptsize{±8.580} & 68.520 \\scriptsize{±0.510} & 68.190 \\scriptsize{±0.650} & \\cellcolor{blue!20}76.130 \\scriptsize{±1.800} & 0.700 \\scriptsize{±0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{DR} & - & - & 76.170 \\scriptsize{±6.630} & 76.600 \\scriptsize{±1.750} & 77.120 \\scriptsize{±1.070} & - & 0.360 \\scriptsize{±0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SDP} & - & - & - & - & - & \\cellcolor{blue!20}74.980 \\scriptsize{±1.920} & - \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GAT} & - & - & \\cellcolor{blue!20}83.400 \\scriptsize{±4.850} & 76.110 \\scriptsize{±1.690} & 75.620 \\scriptsize{±0.760} & 74.050 \\scriptsize{±2.160} & 0.380 \\scriptsize{±0.030} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GCN} & - & - & \\cellcolor{blue!20}85.110 \\scriptsize{±6.730} & 76.420 \\scriptsize{±1.670} & 75.620 \\scriptsize{±0.940} & 74.410 \\scriptsize{±1.770} & 0.360 \\scriptsize{±0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GIN} & - & - & \\cellcolor{gray!30}\\textbf{86.380} \\scriptsize{±6.490} & 77.650 \\scriptsize{±1.110} & 77.190 \\scriptsize{±0.210} & 72.540 \\scriptsize{±3.070} & \\cellcolor{gray!30}\\textbf{0.190} \\scriptsize{±0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GraphSAGE} & - & - & \\cellcolor{blue!20}85.530 \\scriptsize{±6.800} & \\cellcolor{blue!20}78.230 \\scriptsize{±1.470} & 77.100 \\scriptsize{±0.830} & 73.620 \\scriptsize{±2.720} & 0.240 \\scriptsize{±0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Hasse} & - & - & \\cellcolor{blue!20}85.960 \\scriptsize{±7.150} & 76.750 \\scriptsize{±1.630} & 76.940 \\scriptsize{±0.820} & \\cellcolor{blue!20}73.730 \\scriptsize{±2.950} & 0.310 \\scriptsize{±0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Transformer} & - & - & \\cellcolor{blue!20}83.830 \\scriptsize{±6.490} & 73.000 \\scriptsize{±1.370} & 73.200 \\scriptsize{±1.050} & 70.970 \\scriptsize{±4.060} & 0.450 \\scriptsize{±0.020} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{9}{l}{\\textbf{Simplicial Methods}} \\\\\n",
      "\\midrule\n",
      "\\multirow{10}{*}{Other} & \n",
      "\\emph{DR} & - & - & - & 75.270 \\scriptsize{±1.570} & - & \\cellcolor{blue!20}75.270 \\scriptsize{±2.140} & - \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GCCN with GAT} & - & - & 79.150 \\scriptsize{±4.090} & 74.860 \\scriptsize{±1.420} & 74.810 \\scriptsize{±1.140} & \\cellcolor{blue!20}74.620 \\scriptsize{±1.950} & 0.570 \\scriptsize{±0.030} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GCN} & - & - & 74.040 \\scriptsize{±8.300} & 74.200 \\scriptsize{±2.170} & 74.130 \\scriptsize{±0.530} & \\cellcolor{blue!20}74.910 \\scriptsize{±2.510} & 0.530 \\scriptsize{±0.050} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GIN} & - & - & \\cellcolor{blue!20}85.960 \\scriptsize{±4.660} & 76.670 \\scriptsize{±1.620} & 75.760 \\scriptsize{±1.280} & 72.830 \\scriptsize{±2.720} & 0.350 \\scriptsize{±0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GraphSAGE} & - & - & 75.740 \\scriptsize{±2.430} & 76.850 \\scriptsize{±1.500} & 75.640 \\scriptsize{±1.940} & \\cellcolor{blue!20}74.700 \\scriptsize{±3.100} & 0.500 \\scriptsize{±0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SDP} & - & - & 73.620 \\scriptsize{±6.130} & - & 75.700 \\scriptsize{±1.040} & - & 0.530 \\scriptsize{±0.040} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{CCNN} & - & - & 76.170 \\scriptsize{±6.630} & 76.600 \\scriptsize{±1.750} & 77.120 \\scriptsize{±1.070} & \\cellcolor{blue!20}75.270 \\scriptsize{±2.140} & 0.360 \\scriptsize{±0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SCN} & - & - & 77.020 \\scriptsize{±9.320} & 77.650 \\scriptsize{±1.280} & 74.830 \\scriptsize{±1.180} & 73.330 \\scriptsize{±2.300} & 0.340 \\scriptsize{±0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Hasse} & - & - & 74.040 \\scriptsize{±5.510} & 75.020 \\scriptsize{±2.240} & 73.910 \\scriptsize{±3.900} & 74.480 \\scriptsize{±1.890} & 0.560 \\scriptsize{±0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{Transformer} & - & - & 74.040 \\scriptsize{±4.090} & 70.390 \\scriptsize{±0.960} & 69.990 \\scriptsize{±1.130} & 70.970 \\scriptsize{±4.060} & 0.640 \\scriptsize{±0.010} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Cross-domain comparison grouped by domain type (Simplicial/Cellular): results are shown as mean and standard deviation. The best result is bold and shaded in grey, while those within one standard deviation are in blue-shaded boxes.}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(generate_latex_table(final_add_df)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peekvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
