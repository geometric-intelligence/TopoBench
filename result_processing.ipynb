{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJ_PREFIX = \"main_exp\"\n",
    "PROJ_TYPES = [\"SANN\", \"GPSE\"]\n",
    "PROJ_DS = [\"NCI1\", \"NCI109\", \"MUTAG\", \"PROTEINS\", \"ZINC\", \"IMDB-BINARY\", \"IMDB-MULTI\"]\n",
    "\n",
    "today = date.today()\n",
    "api = wandb.Api(overrides={\"base_url\": \"https://api.wandb.ai\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Find all csv files in the current directory\n",
    "csv_files = glob.glob(\"csv/*.csv\")\n",
    "# # Collect all the names of the csv files without the extension\n",
    "csv_names = [csv_file[:-4] for csv_file in csv_files]\n",
    "user = \"telyatnikov_sap\"\n",
    "\n",
    "for project_dataset in PROJ_DS:\n",
    "    for project_type in PROJ_TYPES:\n",
    "        project_name = f\"{PROJ_PREFIX}_{project_type}_{project_dataset}\"\n",
    "        if project_name not in csv_names:\n",
    "            runs = api.runs(f\"{user}/{project_name}\")\n",
    "            try:\n",
    "                list(runs)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            summary_list, config_list, name_list = [], [], []\n",
    "            for run in runs:\n",
    "                # .summary contains the output keys/values for metrics like accuracy.\n",
    "                #  We call ._json_dict to omit large files\n",
    "                summary_list.append(run.summary._json_dict)\n",
    "\n",
    "                # .config contains the hyperparameters.\n",
    "                #  We remove special values that start with _.\n",
    "                config_list.append(\n",
    "                    {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "                )\n",
    "\n",
    "                # .name is the human-readable name of the run.\n",
    "                name_list.append(run.name)\n",
    "\n",
    "            runs_df = pd.DataFrame(\n",
    "                {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "            )\n",
    "\n",
    "            runs_df.to_csv(f\"csv/{user}_{project_name}.csv\")\n",
    "        else:\n",
    "            runs_df = pd.read_csv(f\"csv/{user}_{project_name}.csv\", index_col=0)\n",
    "\n",
    "            for row in runs_df.iloc:\n",
    "                row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "                row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "    for row in runs_df.iloc:\n",
    "        row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "    lst = [i[\"summary\"] for i in runs_df.iloc]\n",
    "    df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "    df_init = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"csv/*.csv\")\n",
    "df_list = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, index_col=0)\n",
    "    for row in df.iloc:\n",
    "        row[\"summary\"] = ast.literal_eval(row[\"summary\"])\n",
    "        row[\"config\"] = ast.literal_eval(row[\"config\"])\n",
    "        row[\"summary\"].update(row[\"config\"])\n",
    "\n",
    "    lst = [i[\"summary\"] for i in df.iloc]\n",
    "    df = pd.DataFrame.from_dict(lst)\n",
    "\n",
    "    df_init = df.copy()\n",
    "\n",
    "    df_list.append(df_init)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_to_normalize):\n",
    "    # Use json_normalize to flatten the nested dictionaries into separate columns\n",
    "    flattened_df = pd.json_normalize(df[column_to_normalize])\n",
    "    # Rename columns to include 'nested_column' prefix\n",
    "    flattened_df.columns = [\n",
    "        f\"{column_to_normalize}.{col}\" for col in flattened_df.columns\n",
    "    ]\n",
    "    # Concatenate the flattened DataFrame with the original DataFrame\n",
    "    result_df = pd.concat([df, flattened_df], axis=1)\n",
    "    # Get new columns names\n",
    "    new_columns = flattened_df.columns\n",
    "    # Drop the original nested column if needed\n",
    "    result_df.drop(column_to_normalize, axis=1, inplace=True)\n",
    "    return result_df, new_columns\n",
    "\n",
    "\n",
    "# Config columns to normalize\n",
    "columns_to_normalize = [\"model\", \"dataset\", \"callbacks\", \"paths\", \"transforms\", 'optimizer']\n",
    "\n",
    "# Keep track of config columns added\n",
    "config_columns = []\n",
    "for column in columns_to_normalize:\n",
    "    df, columns = normalize_column(df, column)\n",
    "    config_columns.extend(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct model name based on each pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_correct_name(row):\n",
    "    if not isinstance(row, str) and np.isnan(row):\n",
    "        return \"SANN\"\n",
    "    return f\"GPSE_{row}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model.model_name'] = df['transforms.sann_encoding.pretrain_model'].map(map_correct_name)\n",
    "df['transforms.sann_encoding.neighborhoods'] = df['transforms.sann_encoding.neighborhoods'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GPSE_GEOM', 'GPSE_ZINC', 'GPSE_PCQM4MV2', 'GPSE_MOLPCBA', 'SANN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model.model_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " '_wandb',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'loss',\n",
       " 'seed',\n",
       " 'tags',\n",
       " 'test',\n",
       " 'train',\n",
       " 'extras',\n",
       " 'logger',\n",
       " 'trainer',\n",
       " 'ckpt_path',\n",
       " 'evaluator',\n",
       " 'task_name',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'model/params/non_trainable',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.compile',\n",
       " 'model._target_',\n",
       " 'model.model_name',\n",
       " 'model.model_domain',\n",
       " 'model.readout.max_hop',\n",
       " 'model.readout._target_',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.task_level',\n",
       " 'model.readout.complex_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.readout.pooling_type',\n",
       " 'model.readout.readout_name',\n",
       " 'model.readout.num_cell_dimensions',\n",
       " 'model.backbone.max_hop',\n",
       " 'model.backbone._target_',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.update_func',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.max_hop',\n",
       " 'model.feature_encoder._target_',\n",
       " 'model.feature_encoder.all_ones',\n",
       " 'model.feature_encoder.in_channels',\n",
       " 'model.feature_encoder.encoder_name',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.feature_encoder.feature_lifting',\n",
       " 'model.feature_encoder.dataset_in_channels',\n",
       " 'model.feature_encoder.selected_dimensions',\n",
       " 'model.backbone_wrapper.max_hop',\n",
       " 'model.backbone_wrapper._target_',\n",
       " 'model.backbone_wrapper._partial_',\n",
       " 'model.backbone_wrapper.complex_dim',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'model.backbone_wrapper.wrapper_name',\n",
       " 'model.backbone_wrapper.num_cell_dimensions',\n",
       " 'dataset.loader._target_',\n",
       " 'dataset.loader.parameters.data_dir',\n",
       " 'dataset.loader.parameters.data_name',\n",
       " 'dataset.loader.parameters.data_type',\n",
       " 'dataset.loader.parameters.data_domain',\n",
       " 'dataset.parameters.task',\n",
       " 'dataset.parameters.loss_type',\n",
       " 'dataset.parameters.task_level',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.parameters.num_features',\n",
       " 'dataset.parameters.monitor_metric',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.split_type',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.split_params.data_split_dir',\n",
       " 'dataset.split_params.learning_setting',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.dataloader_params.pin_memory',\n",
       " 'dataset.dataloader_params.num_workers',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'dataset.parameters.degrees_fields',\n",
       " 'dataset.dataloader_params.persistent_workers',\n",
       " 'callbacks.model_timer._target_',\n",
       " 'callbacks.model_summary._target_',\n",
       " 'callbacks.model_summary.max_depth',\n",
       " 'callbacks.early_stopping.mode',\n",
       " 'callbacks.early_stopping.strict',\n",
       " 'callbacks.early_stopping.monitor',\n",
       " 'callbacks.early_stopping.verbose',\n",
       " 'callbacks.early_stopping._target_',\n",
       " 'callbacks.early_stopping.patience',\n",
       " 'callbacks.early_stopping.min_delta',\n",
       " 'callbacks.early_stopping.check_finite',\n",
       " 'callbacks.early_stopping.stopping_threshold',\n",
       " 'callbacks.early_stopping.divergence_threshold',\n",
       " 'callbacks.early_stopping.check_on_train_epoch_end',\n",
       " 'callbacks.model_checkpoint.mode',\n",
       " 'callbacks.model_checkpoint.dirpath',\n",
       " 'callbacks.model_checkpoint.monitor',\n",
       " 'callbacks.model_checkpoint.verbose',\n",
       " 'callbacks.model_checkpoint._target_',\n",
       " 'callbacks.model_checkpoint.filename',\n",
       " 'callbacks.model_checkpoint.save_last',\n",
       " 'callbacks.model_checkpoint.save_top_k',\n",
       " 'callbacks.model_checkpoint.every_n_epochs',\n",
       " 'callbacks.model_checkpoint.save_weights_only',\n",
       " 'callbacks.model_checkpoint.every_n_train_steps',\n",
       " 'callbacks.model_checkpoint.train_time_interval',\n",
       " 'callbacks.model_checkpoint.auto_insert_metric_name',\n",
       " 'callbacks.model_checkpoint.save_on_train_epoch_end',\n",
       " 'callbacks.learning_rate_monitor._target_',\n",
       " 'callbacks.learning_rate_monitor.logging_interval',\n",
       " 'paths.log_dir',\n",
       " 'paths.data_dir',\n",
       " 'paths.root_dir',\n",
       " 'paths.work_dir',\n",
       " 'paths.output_dir',\n",
       " 'transforms.sann_encoding.cuda',\n",
       " 'transforms.sann_encoding.device',\n",
       " 'transforms.sann_encoding.dim_out',\n",
       " 'transforms.sann_encoding.max_hop',\n",
       " 'transforms.sann_encoding._target_',\n",
       " 'transforms.sann_encoding.max_rank',\n",
       " 'transforms.sann_encoding.in_channels',\n",
       " 'transforms.sann_encoding.copy_initial',\n",
       " 'transforms.sann_encoding.neighborhoods',\n",
       " 'transforms.sann_encoding.pretrain_model',\n",
       " 'transforms.sann_encoding.transform_name',\n",
       " 'transforms.sann_encoding.transform_type',\n",
       " 'transforms.sann_encoding.dim_target_node',\n",
       " 'transforms.sann_encoding.dim_target_graph',\n",
       " 'transforms.graph2cell_lifting._target_',\n",
       " 'transforms.graph2cell_lifting.complex_dim',\n",
       " 'transforms.graph2cell_lifting.neighborhoods',\n",
       " 'transforms.graph2cell_lifting.transform_name',\n",
       " 'transforms.graph2cell_lifting.transform_type',\n",
       " 'transforms.graph2cell_lifting.feature_lifting',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.graph2cell_lifting.preserve_edge_attr',\n",
       " 'transforms.data_manipulations._target_',\n",
       " 'transforms.data_manipulations.transform_name',\n",
       " 'transforms.data_manipulations.transform_type',\n",
       " 'transforms.data_manipulations.selected_fields',\n",
       " 'transforms.one_hot_node_degree_features._target_',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'transforms.one_hot_node_degree_features.degrees_fields',\n",
       " 'transforms.one_hot_node_degree_features.transform_name',\n",
       " 'transforms.one_hot_node_degree_features.transform_type',\n",
       " 'transforms.one_hot_node_degree_features.features_fields',\n",
       " 'optimizer._target_',\n",
       " 'optimizer.optimizer_id',\n",
       " 'optimizer.scheduler.scheduler_id',\n",
       " 'optimizer.scheduler.scheduler_params.gamma',\n",
       " 'optimizer.scheduler.scheduler_params.step_size',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get grouped df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['dataset.split_params.data_seed'].isna())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cell'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model.model_domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " '_wandb',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'loss',\n",
       " 'seed',\n",
       " 'tags',\n",
       " 'test',\n",
       " 'train',\n",
       " 'extras',\n",
       " 'logger',\n",
       " 'trainer',\n",
       " 'ckpt_path',\n",
       " 'evaluator',\n",
       " 'task_name',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'model/params/non_trainable',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.compile',\n",
       " 'model._target_',\n",
       " 'model.model_name',\n",
       " 'model.model_domain',\n",
       " 'model.readout.max_hop',\n",
       " 'model.readout._target_',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.task_level',\n",
       " 'model.readout.complex_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.readout.pooling_type',\n",
       " 'model.readout.readout_name',\n",
       " 'model.readout.num_cell_dimensions',\n",
       " 'model.backbone.max_hop',\n",
       " 'model.backbone._target_',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.update_func',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.max_hop',\n",
       " 'model.feature_encoder._target_',\n",
       " 'model.feature_encoder.all_ones',\n",
       " 'model.feature_encoder.in_channels',\n",
       " 'model.feature_encoder.encoder_name',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.feature_encoder.feature_lifting',\n",
       " 'model.feature_encoder.dataset_in_channels',\n",
       " 'model.feature_encoder.selected_dimensions',\n",
       " 'model.backbone_wrapper.max_hop',\n",
       " 'model.backbone_wrapper._target_',\n",
       " 'model.backbone_wrapper._partial_',\n",
       " 'model.backbone_wrapper.complex_dim',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'model.backbone_wrapper.wrapper_name',\n",
       " 'model.backbone_wrapper.num_cell_dimensions',\n",
       " 'dataset.loader._target_',\n",
       " 'dataset.loader.parameters.data_dir',\n",
       " 'dataset.loader.parameters.data_name',\n",
       " 'dataset.loader.parameters.data_type',\n",
       " 'dataset.loader.parameters.data_domain',\n",
       " 'dataset.parameters.task',\n",
       " 'dataset.parameters.loss_type',\n",
       " 'dataset.parameters.task_level',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.parameters.num_features',\n",
       " 'dataset.parameters.monitor_metric',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.split_type',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.split_params.data_split_dir',\n",
       " 'dataset.split_params.learning_setting',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.dataloader_params.pin_memory',\n",
       " 'dataset.dataloader_params.num_workers',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'dataset.parameters.degrees_fields',\n",
       " 'dataset.dataloader_params.persistent_workers',\n",
       " 'callbacks.model_timer._target_',\n",
       " 'callbacks.model_summary._target_',\n",
       " 'callbacks.model_summary.max_depth',\n",
       " 'callbacks.early_stopping.mode',\n",
       " 'callbacks.early_stopping.strict',\n",
       " 'callbacks.early_stopping.monitor',\n",
       " 'callbacks.early_stopping.verbose',\n",
       " 'callbacks.early_stopping._target_',\n",
       " 'callbacks.early_stopping.patience',\n",
       " 'callbacks.early_stopping.min_delta',\n",
       " 'callbacks.early_stopping.check_finite',\n",
       " 'callbacks.early_stopping.stopping_threshold',\n",
       " 'callbacks.early_stopping.divergence_threshold',\n",
       " 'callbacks.early_stopping.check_on_train_epoch_end',\n",
       " 'callbacks.model_checkpoint.mode',\n",
       " 'callbacks.model_checkpoint.dirpath',\n",
       " 'callbacks.model_checkpoint.monitor',\n",
       " 'callbacks.model_checkpoint.verbose',\n",
       " 'callbacks.model_checkpoint._target_',\n",
       " 'callbacks.model_checkpoint.filename',\n",
       " 'callbacks.model_checkpoint.save_last',\n",
       " 'callbacks.model_checkpoint.save_top_k',\n",
       " 'callbacks.model_checkpoint.every_n_epochs',\n",
       " 'callbacks.model_checkpoint.save_weights_only',\n",
       " 'callbacks.model_checkpoint.every_n_train_steps',\n",
       " 'callbacks.model_checkpoint.train_time_interval',\n",
       " 'callbacks.model_checkpoint.auto_insert_metric_name',\n",
       " 'callbacks.model_checkpoint.save_on_train_epoch_end',\n",
       " 'callbacks.learning_rate_monitor._target_',\n",
       " 'callbacks.learning_rate_monitor.logging_interval',\n",
       " 'paths.log_dir',\n",
       " 'paths.data_dir',\n",
       " 'paths.root_dir',\n",
       " 'paths.work_dir',\n",
       " 'paths.output_dir',\n",
       " 'transforms.sann_encoding.cuda',\n",
       " 'transforms.sann_encoding.device',\n",
       " 'transforms.sann_encoding.dim_out',\n",
       " 'transforms.sann_encoding.max_hop',\n",
       " 'transforms.sann_encoding._target_',\n",
       " 'transforms.sann_encoding.max_rank',\n",
       " 'transforms.sann_encoding.in_channels',\n",
       " 'transforms.sann_encoding.copy_initial',\n",
       " 'transforms.sann_encoding.neighborhoods',\n",
       " 'transforms.sann_encoding.pretrain_model',\n",
       " 'transforms.sann_encoding.transform_name',\n",
       " 'transforms.sann_encoding.transform_type',\n",
       " 'transforms.sann_encoding.dim_target_node',\n",
       " 'transforms.sann_encoding.dim_target_graph',\n",
       " 'transforms.graph2cell_lifting._target_',\n",
       " 'transforms.graph2cell_lifting.complex_dim',\n",
       " 'transforms.graph2cell_lifting.neighborhoods',\n",
       " 'transforms.graph2cell_lifting.transform_name',\n",
       " 'transforms.graph2cell_lifting.transform_type',\n",
       " 'transforms.graph2cell_lifting.feature_lifting',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.graph2cell_lifting.preserve_edge_attr',\n",
       " 'transforms.data_manipulations._target_',\n",
       " 'transforms.data_manipulations.transform_name',\n",
       " 'transforms.data_manipulations.transform_type',\n",
       " 'transforms.data_manipulations.selected_fields',\n",
       " 'transforms.one_hot_node_degree_features._target_',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'transforms.one_hot_node_degree_features.degrees_fields',\n",
       " 'transforms.one_hot_node_degree_features.transform_name',\n",
       " 'transforms.one_hot_node_degree_features.transform_type',\n",
       " 'transforms.one_hot_node_degree_features.features_fields',\n",
       " 'optimizer._target_',\n",
       " 'optimizer.optimizer_id',\n",
       " 'optimizer.scheduler.scheduler_id',\n",
       " 'optimizer.scheduler.scheduler_params.gamma',\n",
       " 'optimizer.scheduler.scheduler_params.step_size',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_params = []\n",
    "for param in list(df.columns):\n",
    "    if df[param].dtype == pd.CategoricalDtype:\n",
    "        continue\n",
    "    if  len(df[param].unique()) > 1:\n",
    "        changed_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AvgTime/train_batch_mean',\n",
       " 'AvgTime/train_batch_std',\n",
       " 'AvgTime/train_epoch_mean',\n",
       " 'AvgTime/train_epoch_std',\n",
       " 'AvgTime/val_batch_mean',\n",
       " 'AvgTime/val_batch_std',\n",
       " 'AvgTime/val_epoch_mean',\n",
       " 'AvgTime/val_epoch_std',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " 'epoch',\n",
       " 'lr-Adam',\n",
       " 'test/accuracy',\n",
       " 'test/auroc',\n",
       " 'test/loss',\n",
       " 'test/precision',\n",
       " 'test/recall',\n",
       " 'train/accuracy',\n",
       " 'train/auroc',\n",
       " 'train/loss',\n",
       " 'train/precision',\n",
       " 'train/recall',\n",
       " 'trainer/global_step',\n",
       " 'val/accuracy',\n",
       " 'val/auroc',\n",
       " 'val/loss',\n",
       " 'val/precision',\n",
       " 'val/recall',\n",
       " 'model/params/total',\n",
       " 'model/params/trainable',\n",
       " 'test/mae',\n",
       " 'test/mse',\n",
       " 'train/mae',\n",
       " 'train/mse',\n",
       " 'val/mae',\n",
       " 'val/mse',\n",
       " 'model.readout.hidden_dim',\n",
       " 'model.readout.out_channels',\n",
       " 'model.backbone.n_layers',\n",
       " 'model.backbone.in_channels',\n",
       " 'model.backbone.hidden_channels',\n",
       " 'model.feature_encoder.out_channels',\n",
       " 'model.feature_encoder.proj_dropout',\n",
       " 'model.backbone_wrapper.out_channels',\n",
       " 'dataset.parameters.num_classes',\n",
       " 'dataset.parameters.num_features',\n",
       " 'dataset.split_params.k',\n",
       " 'dataset.split_params.data_seed',\n",
       " 'dataset.split_params.train_prop',\n",
       " 'dataset.dataloader_params.batch_size',\n",
       " 'dataset.parameters.max_x_1_degree',\n",
       " 'dataset.parameters.max_node_degree',\n",
       " 'transforms.graph2cell_lifting.max_cell_length',\n",
       " 'transforms.one_hot_node_degree_features.max_degree',\n",
       " 'optimizer.parameters.lr',\n",
       " 'optimizer.parameters.weight_decay']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GPSE_GEOM', 'GPSE_ZINC', 'GPSE_PCQM4MV2', 'GPSE_MOLPCBA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model.model_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best results for each model and dataset\n",
    "# 1. Keep the columns that are necessary for the comparison\n",
    "sweeped_columns = [\n",
    "    #'transforms.sann_encoding.max_hop',\n",
    "    'transforms.sann_encoding.neighborhoods',\n",
    "    #'transforms.sann_encoding.max_rank',\n",
    "    'model.feature_encoder.proj_dropout',\n",
    "    'transforms.sann_encoding.pretrain_model',\n",
    "    'model.backbone.n_layers',\n",
    "    'model.feature_encoder.out_channels',\n",
    "    'optimizer.parameters.weight_decay',\n",
    "    'optimizer.parameters.lr',\n",
    "    'dataset.dataloader_params.batch_size',\n",
    "]\n",
    "run_columns = ['dataset.split_params.data_seed','seed',]\n",
    "\n",
    "# Dataset and model columns\n",
    "dataset_model_columns = ['model.model_name', 'model.model_domain', 'dataset.loader.parameters.data_name']\n",
    "\n",
    "# Performance columns\n",
    "performance_columns = [\n",
    "    'val/loss', 'test/loss',\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "keep_columns = dataset_model_columns + sweeped_columns + performance_columns + run_columns\n",
    "df_keep = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_classification = [\n",
    "    'val/accuracy', 'test/accuracy',\n",
    "    'val/auroc','test/auroc',\n",
    "    'val/recall', 'test/recall',\n",
    "    'val/precision', 'test/precision',\n",
    "    ]\n",
    "performance_regression = [\n",
    "    'val/mae', 'test/mae',\n",
    "    'val/mse', 'test/mse',\n",
    "    ]\n",
    "# Define a dict of dicts for each dataset the corresponding optimization metrics\n",
    "optimization_metrics = {\n",
    "    'NCI109': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'NCI1': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PROTEINS': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'MUTAG': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'ZINC': {'optim_metric': 'val/mae', 'eval_metric': 'test/mae', 'direction': 'min', 'performance_columns': performance_regression},\n",
    "    'IMDB-BINARY': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'IMDB-MULTI': {'optim_metric': 'val/accuracy', 'eval_metric': 'test/accuracy', 'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Cora': {'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'Citeseer': {'direction': 'max', 'performance_columns': performance_classification},\n",
    "    'PubMed': {'direction': 'max', 'performance_columns': performance_classification},\n",
    "\n",
    "} \n",
    "\n",
    "len(optimization_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_subsets=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PROTEINS, Model: GPSE_GEOM\n",
      "[3 4 5 0 1 2]\n",
      "61.2885462555066\n",
      "Dataset: PROTEINS, Model: GPSE_ZINC\n",
      "[3 4 5 0 1 2]\n",
      "61.2885462555066\n",
      "Dataset: PROTEINS, Model: GPSE_PCQM4MV2\n",
      "[3 4 5 0 1 2]\n",
      "61.2885462555066\n",
      "Dataset: PROTEINS, Model: GPSE_MOLPCBA\n",
      "[3 4 5 0 1 2]\n",
      "61.2885462555066\n",
      "Dataset: NCI109, Model: GPSE_GEOM\n",
      "[5 4 3]\n",
      "99.67447916666666\n",
      "Dataset: NCI109, Model: GPSE_ZINC\n",
      "[5 4 3]\n",
      "99.67447916666666\n",
      "Dataset: NCI109, Model: GPSE_PCQM4MV2\n",
      "[5 4 3]\n",
      "99.67447916666666\n",
      "Dataset: NCI109, Model: GPSE_MOLPCBA\n",
      "[5 4 3]\n",
      "99.67447916666666\n",
      "Dataset: NCI1, Model: GPSE_GEOM\n",
      "[5 4 2 3 1 0]\n",
      "82.31731933790876\n",
      "Dataset: NCI1, Model: GPSE_ZINC\n",
      "[5 4 2 3 1 0]\n",
      "82.31731933790876\n",
      "Dataset: NCI1, Model: GPSE_PCQM4MV2\n",
      "[5 4 2 3 1 0]\n",
      "82.31731933790876\n",
      "Dataset: NCI1, Model: GPSE_MOLPCBA\n",
      "[5 4 2 3 1 0]\n",
      "82.31731933790876\n",
      "Dataset: IMDB-BINARY, Model: GPSE_GEOM\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: GPSE_ZINC\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: GPSE_PCQM4MV2\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: IMDB-BINARY, Model: GPSE_MOLPCBA\n",
      "[5 4]\n",
      "99.93489583333334\n",
      "Dataset: ZINC, Model: GPSE_GEOM\n",
      "[3 4 5 1 2 0]\n",
      "70.24070021881839\n",
      "Dataset: ZINC, Model: GPSE_ZINC\n",
      "[3 4 5 1 2 0]\n",
      "70.24070021881839\n",
      "Dataset: ZINC, Model: GPSE_PCQM4MV2\n",
      "[3 4 5 1 2 0]\n",
      "70.24070021881839\n",
      "Dataset: ZINC, Model: GPSE_MOLPCBA\n",
      "[3 4 5 1 2 0]\n",
      "70.24070021881839\n",
      "Dataset: IMDB-MULTI, Model: GPSE_GEOM\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: GPSE_ZINC\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: GPSE_PCQM4MV2\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n",
      "Dataset: IMDB-MULTI, Model: GPSE_MOLPCBA\n",
      "[2 1 5 4 3 0]\n",
      "95.326278659612\n"
     ]
    }
   ],
   "source": [
    "search_metric_types = ['accuracy',] #'auroc', 'recall', 'precision']\n",
    "\n",
    "\n",
    "# Get unique datasets\n",
    "datasets = list(df['dataset.loader.parameters.data_name'].unique())\n",
    "# Get unique models\n",
    "models = list(df['model.model_name'].unique())\n",
    "\n",
    "best_results = defaultdict(dict)\n",
    "best_results_all_metrics = defaultdict(dict)\n",
    "best_runs = defaultdict(dict)\n",
    "collect_subsets = defaultdict(dict)\n",
    "collect_bast_parameters = defaultdict(dict)\n",
    "# Got over each dataset and model and find the best result\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        # Get the subset of the DataFrame for the current dataset and model\n",
    "        subset = df_keep[\n",
    "            (df_keep['dataset.loader.parameters.data_name'] == dataset)\n",
    "        ]\n",
    "\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        direction = optimization_metrics[dataset]['direction']\n",
    "        \n",
    "        # Keep metrics that matters for dataset\n",
    "        performance_columns = optimization_metrics[dataset]['performance_columns']\n",
    "        subset = subset[dataset_model_columns + sweeped_columns + performance_columns + run_columns]\n",
    "\n",
    "        aggregated = subset.groupby(sweeped_columns +  ['model.model_name', 'model.model_domain'], dropna=False).agg(\n",
    "            {col: [\"mean\", \"std\", \"count\"] for col in performance_columns},\n",
    "        )\n",
    "\n",
    "        # aggregated = subset.groupby(sweeped_columns, dropna=False).count()\n",
    "\n",
    "        # Go from MultiIndex to Index\n",
    "        aggregated = aggregated.reset_index()\n",
    "        print(f\"Dataset: {dataset}, Model: {model}\")\n",
    "        print(aggregated[(eval_metric, 'count')].unique())\n",
    "        #print(aggregated['dataset.split_params.data_seed'].unique())\n",
    "        print((aggregated[(eval_metric, 'count')] >= 5).sum() / len(aggregated) * 100)\n",
    "        aggregated = aggregated[aggregated[(eval_metric, 'count')] >= 5]\n",
    "        #print(len(aggregated[aggregated['seed'] > 4]))\n",
    "        aggregated = aggregated.sort_values(\n",
    "                by=(eval_metric, \"mean\"), ascending=(direction == 'min')\n",
    "            )\n",
    "\n",
    "        \n",
    "        # Git percent in case of classification\n",
    "        if 'test/accuracy' in performance_columns:\n",
    "            # Go over all the performance columns and multiply by 100\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] *= 100\n",
    "                aggregated[(col, \"std\")] *= 100\n",
    "            \n",
    "            # Round performance columns values up to 2 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # Round all values up to 4 decimal points\n",
    "            # Round performance columns values up to 4 decimal points\n",
    "            for col in performance_columns:\n",
    "                aggregated[(col, \"mean\")] = aggregated[(col, \"mean\")].round(4)\n",
    "                aggregated[(col, \"std\")] = aggregated[(col, \"std\")].round(4)\n",
    "        \n",
    "        \n",
    "        collect_subsets[dataset] = aggregated\n",
    "\n",
    "# Delete 'US-county-demos-Election' from datasets\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     aggregated = collect_subsets[dataset]\n",
    "#     # For every model.backbone.num_layers get make a bar plot for each sweeped column\n",
    "#     for num_layers in aggregated['model.backbone.num_layers'].unique():\n",
    "#         agg_subset = aggregated[aggregated['model.backbone.num_layers']==num_layers]\n",
    "\n",
    "#         cols = ['transforms.R.loops', 'transforms.R.lower_bound_eq', 'model.backbone.num_layers', 'transforms.R.compute_every_it']\n",
    "\n",
    "#         # iterate over rows\n",
    "#         model_names = []\n",
    "#         for index, row in agg_subset.iterrows():\n",
    "#             # Get values of the row\n",
    "#             values = [row[col].item() for col in cols]\n",
    "#             # Count \"No Rewiring\" values\n",
    "#             no_rewiring = values.count(\"No Rewiring\")\n",
    "        \n",
    "#             if no_rewiring == 3:\n",
    "#                 model_name = f\"base_model|Layers={row['model.backbone.num_layers'].item()}\"\n",
    "#             else:\n",
    "#                 model_name = ''\n",
    "#                 for col, value in zip(cols, values):\n",
    "#                     if col == 'transforms.R.loops':\n",
    "#                         model_name += f\"RLo={value}|\"\n",
    "#                     elif col == 'transforms.R.lower_bound_eq':\n",
    "#                         model_name += f\"LBa={value}|\"\n",
    "#                     elif col == 'model.backbone.num_layers':\n",
    "#                         pass\n",
    "#                         #model_name += f\"NLa={value}|\"\n",
    "#                     elif col == 'transforms.R.compute_every_it':\n",
    "#                         model_name += f\"RIt={value}|\"\n",
    "#                     else:\n",
    "#                         raise ValueError(\"Unknown column\")\n",
    "#             model_names.append(model_name)\n",
    "#         agg_subset['Model_name'] = model_names\n",
    "    \n",
    "#         # Plotting\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         agg_subset.sort_values(by=('test/accuracy','mean'), ascending=False, inplace=True)\n",
    "#         model_names = agg_subset['Model_name']\n",
    "    \n",
    "#         accuracy_means = np.array(agg_subset[('test/accuracy','mean')])\n",
    "#         accuracy_stds = np.array(agg_subset[('test/accuracy','std')])\n",
    "#         bars = plt.bar(model_names, accuracy_means, yerr=accuracy_stds, capsize=5, color='skyblue')\n",
    "\n",
    "#         accuracy_means = np.array(agg_subset[('test/accuracy','mean')])\n",
    "#         # Adding data labels on top of bars\n",
    "#         for bar, mean in zip(bars, accuracy_means):\n",
    "#             plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2, f'{mean:.1f}', ha='center', va='bottom')\n",
    "#         #plt.xticks(rotation=45)\n",
    "#         plt.title(f\"Model performance for {dataset} dataset\")\n",
    "#         plt.ylabel(\"Test accuracy\")\n",
    "#         plt.tight_layout()\n",
    "#         delta = np.array(agg_subset[('test/accuracy','std')]).max() + 1\n",
    "#         plt.ylim((agg_subset[('test/accuracy','mean')].min()-delta).round(), (agg_subset[('test/accuracy','mean')].max()+delta).round())\n",
    "#         plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "#         # Rotate x-axis labels\n",
    "#         plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "\n",
    "#         num_layers = agg_subset[agg_subset['Model_name'].apply(lambda x:  True if 'base_model' in x  else False)]['Model_name'].item().split('|')[1]\n",
    "#         plt.savefig(f\"figures/model_performance_{dataset}_num_layers={num_layers}.png\",dpi=300, bbox_inches = \"tight\")\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/0rz4lf5s51bfpr4hwz5hx0kh0000gn/T/ipykernel_2287/1903166908.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protein_subset.loc[:, 'overfit'] = protein_subset[('val/accuracy', 'mean')] - protein_subset[('test/accuracy', 'mean')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test/accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val/accuracy</th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>model.model_domain</th>\n",
       "      <th>transforms.sann_encoding.neighborhoods</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>68.9606</td>\n",
       "      <td>12.7973</td>\n",
       "      <td>5</td>\n",
       "      <td>74.6043</td>\n",
       "      <td>3.5116</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>72.9749</td>\n",
       "      <td>1.7114</td>\n",
       "      <td>5</td>\n",
       "      <td>76.1870</td>\n",
       "      <td>4.1437</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>71.9713</td>\n",
       "      <td>2.9052</td>\n",
       "      <td>5</td>\n",
       "      <td>75.1799</td>\n",
       "      <td>3.6329</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_incidence-0', 'up_incid...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>72.7599</td>\n",
       "      <td>4.1722</td>\n",
       "      <td>5</td>\n",
       "      <td>75.6835</td>\n",
       "      <td>3.7607</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>72.9032</td>\n",
       "      <td>2.3990</td>\n",
       "      <td>5</td>\n",
       "      <td>75.1799</td>\n",
       "      <td>3.2073</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>72.7599</td>\n",
       "      <td>2.8222</td>\n",
       "      <td>5</td>\n",
       "      <td>75.0360</td>\n",
       "      <td>3.6736</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'down_incidence-1', 'down_i...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>73.4767</td>\n",
       "      <td>2.9228</td>\n",
       "      <td>5</td>\n",
       "      <td>75.6835</td>\n",
       "      <td>3.4931</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>73.3333</td>\n",
       "      <td>3.3489</td>\n",
       "      <td>5</td>\n",
       "      <td>75.4676</td>\n",
       "      <td>3.7157</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>73.8351</td>\n",
       "      <td>1.3411</td>\n",
       "      <td>5</td>\n",
       "      <td>75.8993</td>\n",
       "      <td>3.6595</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>73.1183</td>\n",
       "      <td>4.3383</td>\n",
       "      <td>5</td>\n",
       "      <td>75.1799</td>\n",
       "      <td>3.4875</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>cell</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/accuracy                val/accuracy               model.model_name  \\\n",
       "              mean      std count         mean     std count                    \n",
       "825        68.9606  12.7973     5      74.6043  3.5116     5     GPSE_MOLPCBA   \n",
       "248        72.9749   1.7114     5      76.1870  4.1437     5     GPSE_MOLPCBA   \n",
       "1322       71.9713   2.9052     5      75.1799  3.6329     5        GPSE_ZINC   \n",
       "1799       72.7599   4.1722     5      75.6835  3.7607     5        GPSE_ZINC   \n",
       "1628       72.9032   2.3990     5      75.1799  3.2073     5        GPSE_ZINC   \n",
       "107        72.7599   2.8222     5      75.0360  3.6736     5        GPSE_ZINC   \n",
       "744        73.4767   2.9228     5      75.6835  3.4931     5    GPSE_PCQM4MV2   \n",
       "805        73.3333   3.3489     5      75.4676  3.7157     5        GPSE_ZINC   \n",
       "769        73.8351   1.3411     5      75.8993  3.6595     5        GPSE_ZINC   \n",
       "577        73.1183   4.3383     5      75.1799  3.4875     5        GPSE_ZINC   \n",
       "\n",
       "     model.model_domain             transforms.sann_encoding.neighborhoods  \\\n",
       "                                                                             \n",
       "825                cell  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "248                cell  ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "1322               cell  ['up_adjacency-0', 'up_incidence-0', 'up_incid...   \n",
       "1799               cell                                 ['up_adjacency-0']   \n",
       "1628               cell                                 ['up_adjacency-0']   \n",
       "107                cell  ['up_adjacency-0', 'down_incidence-1', 'down_i...   \n",
       "744                cell  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "805                cell  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "769                cell  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "577                cell  ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "\n",
       "     model.backbone.n_layers overfit  \n",
       "                                      \n",
       "825                      1.0  5.6437  \n",
       "248                      1.0  3.2121  \n",
       "1322                     2.0  3.2086  \n",
       "1799                     2.0  2.9236  \n",
       "1628                     2.0  2.2767  \n",
       "107                      2.0  2.2761  \n",
       "744                      4.0  2.2068  \n",
       "805                      4.0  2.1343  \n",
       "769                      1.0  2.0642  \n",
       "577                      1.0  2.0616  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_subset = collect_subsets['PROTEINS'][['test/accuracy', 'val/accuracy', 'model.model_name', 'model.model_domain', 'transforms.sann_encoding.neighborhoods', 'model.backbone.n_layers']]\n",
    "protein_subset.loc[:, 'overfit'] = protein_subset[('val/accuracy', 'mean')] - protein_subset[('test/accuracy', 'mean')]\n",
    "protein_subset.sort_values(by='overfit', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test/accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val/accuracy</th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>transforms.sann_encoding.neighborhoods</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>77.4910</td>\n",
       "      <td>2.4624</td>\n",
       "      <td>5</td>\n",
       "      <td>75.1799</td>\n",
       "      <td>3.3648</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>77.0609</td>\n",
       "      <td>1.6228</td>\n",
       "      <td>5</td>\n",
       "      <td>74.6763</td>\n",
       "      <td>2.8163</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>76.9892</td>\n",
       "      <td>3.0455</td>\n",
       "      <td>5</td>\n",
       "      <td>75.9712</td>\n",
       "      <td>3.3973</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>76.9892</td>\n",
       "      <td>2.8154</td>\n",
       "      <td>5</td>\n",
       "      <td>74.0288</td>\n",
       "      <td>2.8597</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_GEOM</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>76.8459</td>\n",
       "      <td>1.3789</td>\n",
       "      <td>5</td>\n",
       "      <td>75.0360</td>\n",
       "      <td>3.9042</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>72.0430</td>\n",
       "      <td>2.0275</td>\n",
       "      <td>5</td>\n",
       "      <td>73.8129</td>\n",
       "      <td>2.8255</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0', 'up_incidence-0', 'up_incid...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>71.9713</td>\n",
       "      <td>2.8154</td>\n",
       "      <td>5</td>\n",
       "      <td>72.8777</td>\n",
       "      <td>3.5573</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_GEOM</td>\n",
       "      <td>['up_adjacency-0', 'up_incidence-0', 'up_incid...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>71.9713</td>\n",
       "      <td>2.9052</td>\n",
       "      <td>5</td>\n",
       "      <td>75.1799</td>\n",
       "      <td>3.6329</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>['up_adjacency-0', 'up_incidence-0', 'up_incid...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>71.6846</td>\n",
       "      <td>3.4658</td>\n",
       "      <td>5</td>\n",
       "      <td>72.5180</td>\n",
       "      <td>4.6666</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>68.9606</td>\n",
       "      <td>12.7973</td>\n",
       "      <td>5</td>\n",
       "      <td>74.6043</td>\n",
       "      <td>3.5116</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', 'down_adj...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1113 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/accuracy                val/accuracy               model.model_name  \\\n",
       "              mean      std count         mean     std count                    \n",
       "1750       77.4910   2.4624     5      75.1799  3.3648     5    GPSE_PCQM4MV2   \n",
       "1564       77.0609   1.6228     5      74.6763  2.8163     5    GPSE_PCQM4MV2   \n",
       "583        76.9892   3.0455     5      75.9712  3.3973     5        GPSE_ZINC   \n",
       "455        76.9892   2.8154     5      74.0288  2.8597     5        GPSE_GEOM   \n",
       "611        76.8459   1.3789     5      75.0360  3.9042     5        GPSE_ZINC   \n",
       "...            ...      ...   ...          ...     ...   ...              ...   \n",
       "1289       72.0430   2.0275     5      73.8129  2.8255     5    GPSE_PCQM4MV2   \n",
       "1092       71.9713   2.8154     5      72.8777  3.5573     5        GPSE_GEOM   \n",
       "1322       71.9713   2.9052     5      75.1799  3.6329     5        GPSE_ZINC   \n",
       "593        71.6846   3.4658     5      72.5180  4.6666     5        GPSE_ZINC   \n",
       "825        68.9606  12.7973     5      74.6043  3.5116     5     GPSE_MOLPCBA   \n",
       "\n",
       "                 transforms.sann_encoding.neighborhoods  \\\n",
       "                                                          \n",
       "1750                                 ['up_adjacency-0']   \n",
       "1564                                 ['up_adjacency-0']   \n",
       "583   ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "455   ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "611   ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "...                                                 ...   \n",
       "1289  ['up_adjacency-0', 'up_incidence-0', 'up_incid...   \n",
       "1092  ['up_adjacency-0', 'up_incidence-0', 'up_incid...   \n",
       "1322  ['up_adjacency-0', 'up_incidence-0', 'up_incid...   \n",
       "593   ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "825   ['up_adjacency-0', 'up_adjacency-1', 'down_adj...   \n",
       "\n",
       "     model.backbone.n_layers  \n",
       "                              \n",
       "1750                     2.0  \n",
       "1564                     1.0  \n",
       "583                      2.0  \n",
       "455                      4.0  \n",
       "611                      4.0  \n",
       "...                      ...  \n",
       "1289                     2.0  \n",
       "1092                     2.0  \n",
       "1322                     2.0  \n",
       "593                      2.0  \n",
       "825                      1.0  \n",
       "\n",
       "[1113 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_subsets['PROTEINS'][['test/accuracy', 'val/accuracy', 'model.model_name', 'transforms.sann_encoding.neighborhoods', 'model.backbone.n_layers']].sort_values(by=('test/accuracy', 'mean'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">test/mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">val/mae</th>\n",
       "      <th>model.model_name</th>\n",
       "      <th>transforms.sann_encoding.neighborhoods</th>\n",
       "      <th>model.backbone.n_layers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_GEOM</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.2084</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_ZINC</td>\n",
       "      <td>['up_adjacency-0', 'up_adjacency-1', '2-up_adj...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0', 'down_incidence-1', 'down_i...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>0.4418</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_GEOM</td>\n",
       "      <td>['up_adjacency-0']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4876</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_PCQM4MV2</td>\n",
       "      <td>['up_adjacency-0', 'down_incidence-1', 'down_i...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>5</td>\n",
       "      <td>GPSE_MOLPCBA</td>\n",
       "      <td>['up_adjacency-0', 'down_incidence-1', 'down_i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>963 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test/mae               val/mae               model.model_name  \\\n",
       "         mean     std count    mean     std count                    \n",
       "249    0.2116  0.0085     5  0.2454  0.0064     5    GPSE_PCQM4MV2   \n",
       "203    0.2104  0.0016     5  0.2470  0.0047     5        GPSE_GEOM   \n",
       "227    0.2129  0.0052     5  0.2505  0.0042     5     GPSE_MOLPCBA   \n",
       "251    0.2084  0.0069     5  0.2520  0.0043     5    GPSE_PCQM4MV2   \n",
       "271    0.2139  0.0022     5  0.2547  0.0054     5        GPSE_ZINC   \n",
       "...       ...     ...   ...     ...     ...   ...              ...   \n",
       "1312   0.4458  0.0219     5  0.4757  0.0141     5     GPSE_MOLPCBA   \n",
       "161    0.4265  0.0347     5  0.4812  0.0539     5    GPSE_PCQM4MV2   \n",
       "1292   0.4418  0.0298     5  0.4872  0.0247     5        GPSE_GEOM   \n",
       "160    0.4353  0.0225     5  0.4876  0.0370     5    GPSE_PCQM4MV2   \n",
       "125    0.5006  0.0847     5  0.5500  0.1251     5     GPSE_MOLPCBA   \n",
       "\n",
       "                 transforms.sann_encoding.neighborhoods  \\\n",
       "                                                          \n",
       "249   ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "203   ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "227   ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "251   ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "271   ['up_adjacency-0', 'up_adjacency-1', '2-up_adj...   \n",
       "...                                                 ...   \n",
       "1312                                 ['up_adjacency-0']   \n",
       "161   ['up_adjacency-0', 'down_incidence-1', 'down_i...   \n",
       "1292                                 ['up_adjacency-0']   \n",
       "160   ['up_adjacency-0', 'down_incidence-1', 'down_i...   \n",
       "125   ['up_adjacency-0', 'down_incidence-1', 'down_i...   \n",
       "\n",
       "     model.backbone.n_layers  \n",
       "                              \n",
       "249                      4.0  \n",
       "203                      4.0  \n",
       "227                      4.0  \n",
       "251                      4.0  \n",
       "271                      2.0  \n",
       "...                      ...  \n",
       "1312                     1.0  \n",
       "161                      4.0  \n",
       "1292                     1.0  \n",
       "160                      4.0  \n",
       "125                      1.0  \n",
       "\n",
       "[963 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_subsets['ZINC'][['test/mae', 'val/mae', 'model.model_name', 'transforms.sann_encoding.neighborhoods', 'model.backbone.n_layers']].sort_values(by=('val/mae', 'mean'), ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_list_to_name(inc_list):\n",
    "    inc_list = eval(inc_list)\n",
    "    inc_name = \"\"\n",
    "    for inc in inc_list:\n",
    "        inc_num = inc.split('-')\n",
    "        inc_val = int(inc_num[0]) if len(inc_num) == 3 else 1\n",
    "        dim = int(inc_num[-1])\n",
    "\n",
    "        key = ''\n",
    "        if 'incidence' in inc:\n",
    "            if 'up' in inc:\n",
    "                key = f'U_{dim}_{dim+inc_val}'\n",
    "            elif 'down' in inc:\n",
    "                key = f'L_{dim-inc_val}_{dim}'\n",
    "            else:\n",
    "                raise Exception('Unknown NHBD')\n",
    "        elif 'adjacency' in inc:\n",
    "            key = 'A_'\n",
    "            if 'up' in inc:\n",
    "                key = f'A_{dim}'\n",
    "            elif 'down' in inc:\n",
    "                key  = f'A_{dim}'\n",
    "            else:\n",
    "                raise Exception('Unknown NHBD')\n",
    "        inc_name += key + ','\n",
    "    return inc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROTEINS max\n",
      "NCI109 max\n",
      "NCI1 max\n",
      "IMDB-BINARY max\n",
      "ZINC min\n",
      "IMDB-MULTI max\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    agg_sub = collect_subsets[dataset].copy()\n",
    "    eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "    optim_dir = optimization_metrics[dataset]['direction']\n",
    "    print(dataset, optim_dir)\n",
    "    agg_sub.sort_values(by=(eval_metric,'mean'), ascending=(optim_dir == 'min'), inplace=True)\n",
    "    agg_subset = agg_sub[:10].copy()\n",
    "\n",
    "    cols = [\n",
    "        'transforms.sann_encoding.neighborhoods',\n",
    "        'transforms.sann_encoding.pretrain_model',\n",
    "        'model.backbone.n_layers',\n",
    "        'model.model_domain',\n",
    "        'model.feature_encoder.proj_dropout',\n",
    "        'model.feature_encoder.out_channels',\n",
    "        'optimizer.parameters.weight_decay',\n",
    "        'optimizer.parameters.lr',\n",
    "        'dataset.dataloader_params.batch_size']\n",
    "\n",
    "    # iterate over rows\n",
    "    model_names = []\n",
    "    for index, row in agg_subset.iterrows():\n",
    "        m_name = row['model.model_name'].item()\n",
    "        # Get values of the row\n",
    "        values = [row[col].item() for col in cols]\n",
    "        is_sann = 'SANN' in m_name\n",
    "\n",
    "        model_name=f'{m_name}|'\n",
    "        for col, value in zip(cols, values):\n",
    "            if col == 'transforms.sann_encoding.max_hop' and is_sann:\n",
    "                model_name += f\"Hop={value}|\"\n",
    "            elif col == 'model.backbone.n_layers':\n",
    "                model_name += f\"L={value}|\"\n",
    "            elif col == 'transforms.sann_encoding.neighborhoods' and not is_sann:\n",
    "                model_name += f\"NH={inc_list_to_name(value)}|\"\n",
    "            elif col == 'model.feature_encoder.out_channels':\n",
    "                model_name += f\"OCs={value}|\"\n",
    "            elif col == 'optimizer.parameters.lr':\n",
    "                model_name += f\"LR={value}|\"\n",
    "            elif col == 'optimizer.parameters.weight_decay':\n",
    "                model_name += f\"WD={value}|\"\n",
    "            elif col == 'dataset.dataloader_params.batch_size':\n",
    "                model_name += f\"BS={value}|\"\n",
    "        model_names.append(model_name)\n",
    "    agg_subset['Model_name'] = model_names\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    model_names = agg_subset['Model_name']\n",
    "    \n",
    "    accuracy_means = np.array(agg_subset[(eval_metric,'mean')])\n",
    "    accuracy_stds = np.array(agg_subset[(eval_metric,'std')])\n",
    "    bars = plt.bar(model_names, accuracy_means, yerr=accuracy_stds, capsize=5, color='skyblue')\n",
    "\n",
    "    accuracy_means = np.array(agg_subset[(eval_metric,'mean')])\n",
    "    # Adding data labels on top of bars\n",
    "    for bar, mean in zip(bars, accuracy_means):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2, f'{mean:.1f}', ha='center', va='bottom')\n",
    "    #plt.xticks(rotation=45)\n",
    "    plt.title(f\"Model performance for {dataset} dataset\")\n",
    "    plt.ylabel(f\"Test {eval_metric}\")\n",
    "    plt.tight_layout()\n",
    "    delta = agg_subset[(eval_metric,'std')].max() + 1\n",
    "    plt.ylim((agg_subset[(eval_metric,'mean')].min()-delta).round(), (agg_subset[(eval_metric,'mean')].max()+delta).round())\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "\n",
    "    plt.savefig(f\"figures/{dataset}_performance.png\",dpi=300, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    aggregated = collect_subsets[dataset]\n",
    "    for m_name in aggregated['model.model_name'].unique():\n",
    "        agg_sub = aggregated[aggregated['model.model_name']==m_name].copy()\n",
    "        optim_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        optim_dir = optimization_metrics[dataset]['direction']\n",
    "        agg_sub.sort_values(by=(optim_metric,'mean'), ascending=(optim_dir == 'min'), inplace=True)\n",
    "        agg_subset = agg_sub[:10].copy()\n",
    "\n",
    "        cols = [\n",
    "            'transforms.sann_encoding.neighborhoods',\n",
    "            'transforms.sann_encoding.pretrain_model',\n",
    "            'model.backbone.n_layers',\n",
    "            'model.model_domain',\n",
    "            'model.feature_encoder.out_channels',\n",
    "            'optimizer.parameters.weight_decay',\n",
    "            'optimizer.parameters.lr',\n",
    "            'model.feature_encoder.proj_dropout',\n",
    "            'dataset.dataloader_params.batch_size']\n",
    "\n",
    "        # iterate over rows\n",
    "        model_names = []\n",
    "        for index, row in agg_subset.iterrows():\n",
    "            # Get values of the row\n",
    "            values = [row[col].item() for col in cols]\n",
    "            is_sann = 'SANN' in m_name\n",
    "\n",
    "            model_name=f'{m_name}|'\n",
    "            for col, value in zip(cols, values):\n",
    "                if col == 'transforms.sann_encoding.max_hop' and is_sann:\n",
    "                    model_name += f\"Hop={value}|\"\n",
    "                elif col == 'model.backbone.n_layers':\n",
    "                    model_name += f\"L={value}|\"\n",
    "                elif col == 'transforms.sann_encoding.neighborhoods' and not is_sann:\n",
    "                    model_name += f\"NH={inc_list_to_name(value)}|\"\n",
    "                elif col == 'model.feature_encoder.out_channels':\n",
    "                    model_name += f\"OCs={value}|\"\n",
    "                elif col == 'optimizer.parameters.lr':\n",
    "                    model_name += f\"LR={value}|\"\n",
    "                elif col == 'optimizer.parameters.weight_decay':\n",
    "                    model_name += f\"WD={value}|\"\n",
    "                elif col == 'dataset.dataloader_params.batch_size':\n",
    "                    model_name += f\"BS={value}|\"\n",
    "            model_names.append(model_name)\n",
    "        agg_subset['Model_name'] = model_names\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        model_names = agg_subset['Model_name']\n",
    "        \n",
    "        accuracy_means = np.array(agg_subset[(optim_metric,'mean')])\n",
    "        accuracy_stds = np.array(agg_subset[(optim_metric,'std')])\n",
    "        bars = plt.bar(model_names, accuracy_means, yerr=accuracy_stds, capsize=5, color='skyblue')\n",
    "\n",
    "        accuracy_means = np.array(agg_subset[(optim_metric,'mean')])\n",
    "        # Adding data labels on top of bars\n",
    "        for bar, mean in zip(bars, accuracy_means):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2, f'{mean:.1f}', ha='center', va='bottom')\n",
    "        #plt.xticks(rotation=45)\n",
    "        plt.title(f\"Model performance for {dataset} dataset\")\n",
    "        plt.ylabel(\"Test accuracy\")\n",
    "        plt.tight_layout()\n",
    "        delta = agg_subset[(optim_metric,'std')].max() + 1\n",
    "        plt.ylim((agg_subset[(optim_metric,'mean')].min()-delta).round(), (agg_subset[(optim_metric,'mean')].max()+delta).round())\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        # Rotate x-axis labels\n",
    "        plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "\n",
    "        plt.savefig(f\"figures/{m_name}_performance_{dataset}.png\",dpi=300, bbox_inches = \"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'model': [],\n",
    "    'dataset': [],\n",
    "    'mean': [],\n",
    "    'std': [],\n",
    "    'domain': []\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "    aggregated = collect_subsets[dataset]\n",
    "    for m_name in aggregated['model.model_name'].unique():\n",
    "        agg_sub = aggregated[aggregated['model.model_name']==m_name].copy()\n",
    "        optim_metric = optimization_metrics[dataset]['optim_metric']\n",
    "        eval_metric = optimization_metrics[dataset]['eval_metric']\n",
    "        optim_dir = optimization_metrics[dataset]['direction']\n",
    "        agg_sub.sort_values(by=(optim_metric,'mean'), ascending=(optim_dir == 'min'), inplace=True)\n",
    "\n",
    "        df_dict['domain'].append(agg_sub.iloc[0]['model.model_domain'].item())\n",
    "        df_dict['model'].append(m_name)\n",
    "        df_dict['dataset'].append(dataset)\n",
    "        df_dict['mean'].append(agg_sub.iloc[0][(eval_metric, 'mean')])\n",
    "        df_dict['std'].append(agg_sub.iloc[0][(eval_metric, 'std')])\n",
    "df_res = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.extend([\n",
    "    {'model': 'GCCN with GAT', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 83.40, 'std': 4.85},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 74.05, 'std': 2.16},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 76.11, 'std': 1.69},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 75.62, 'std': 0.76},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.38, 'std': 0.03},\n",
    "    # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.39, 'std': 0.65},\n",
    "    # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 74.62, 'std': 1.95},\n",
    "    # {'model': 'Cell with GAT', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 87.68, 'std': 0.33},\n",
    "    \n",
    "    {'model': 'GCCN with GCN', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 85.11, 'std': 6.73},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 74.41, 'std': 1.77},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 76.42, 'std': 1.67},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 75.62, 'std': 0.94},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.36, 'std': 0.01},\n",
    "    # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.51, 'std': 0.70},\n",
    "    # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.41, 'std': 2.00},\n",
    "    # {'model': 'Cell with GCN', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.18, 'std': 0.26},\n",
    "    \n",
    "    {'model': 'GCCN with GIN', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 86.38, 'std': 6.49},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 72.54, 'std': 3.07},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 77.65, 'std': 1.11},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 77.19, 'std': 0.21},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.19, 'std': 0.00},\n",
    "    # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'Cora', 'mean': 87.42, 'std': 1.85},\n",
    "    # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.13, 'std': 1.17},\n",
    "    # {'model': 'Cell with GIN', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.47, 'std': 0.27},\n",
    "    \n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 85.53, 'std': 6.80},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 73.62, 'std': 2.72},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 78.23, 'std': 1.47},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 77.10, 'std': 0.83},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.24, 'std': 0.00},\n",
    "    # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'Cora', 'mean': 88.57, 'std': 0.58},\n",
    "    # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.89, 'std': 1.84},\n",
    "    # {'model': 'Cell with GraphSAGE', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 89.40, 'std': 0.57},\n",
    "    \n",
    "    {'model': 'GCCN with Transformer', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 83.83, 'std': 6.49},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 70.97, 'std': 4.06},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 73.00, 'std': 1.37},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 73.20, 'std': 1.05},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.45, 'std': 0.02},\n",
    "    # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'Cora', 'mean': 84.61, 'std': 1.32},\n",
    "    # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 75.05, 'std': 1.67},\n",
    "    # {'model': 'Cell with Transformer', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.37, 'std': 0.22},\n",
    "    \n",
    "    {'model': 'GCCN with Hasse', 'domain': 'cell', 'dataset': 'MUTAG', 'mean': 85.96, 'std': 7.15},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'cell', 'dataset': 'PROTEINS', 'mean': 73.73, 'std': 2.95},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'cell', 'dataset': 'NCI1', 'mean': 76.75, 'std': 1.63},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'cell', 'dataset': 'NCI109', 'mean': 76.94, 'std': 0.82},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'cell', 'dataset': 'ZINC', 'mean': 0.31, 'std': 0.01},\n",
    "    # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'Cora', 'mean': 87.24, 'std': 0.58},\n",
    "    # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'Citeseer', 'mean': 74.26, 'std': 1.47},\n",
    "    # {'model': 'Cell with Hasse', 'domain': 'cell', 'dataset': 'PubMed', 'mean': 88.65, 'std': 0.55},\n",
    "])\n",
    "\n",
    "# Simplicial models\n",
    "data.extend([\n",
    "    {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 79.15, 'std': 4.09},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 74.62, 'std': 1.95},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 74.86, 'std': 1.42},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 74.81, 'std': 1.14},\n",
    "    {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.57, 'std': 0.03},\n",
    "    # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.33, 'std': 0.67},\n",
    "    # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.65, 'std': 1.93},\n",
    "    # {'model': 'GCCN with GAT', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 87.72, 'std': 0.36},\n",
    "    \n",
    "    {'model': 'GCCN with GCN', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 74.04, 'std': 8.30},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 74.91, 'std': 2.51},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 74.20, 'std': 2.17},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 74.13, 'std': 0.53},\n",
    "    {'model': 'GCCN with GCN', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.53, 'std': 0.05},\n",
    "    # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.51, 'std': 0.70},\n",
    "    # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.41, 'std': 2.00},\n",
    "    # {'model': 'GCN', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.19, 'std': 0.24},\n",
    "    \n",
    "    {'model': 'GCCN with GIN', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 85.96, 'std': 4.66},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 72.83, 'std': 2.72},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 76.67, 'std': 1.62},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 75.76, 'std': 1.28},\n",
    "    {'model': 'GCCN with GIN', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.35, 'std': 0.01},\n",
    "    # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 87.27, 'std': 1.63},\n",
    "    # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.05, 'std': 1.27},\n",
    "    # {'model': 'GIN', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.54, 'std': 0.21},\n",
    "    \n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 75.74, 'std': 2.43},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 74.70, 'std': 3.10},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 76.85, 'std': 1.50},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 75.64, 'std': 1.94},\n",
    "    {'model': 'GCCN with GraphSAGE', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.50, 'std': 0.02},\n",
    "    # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 88.57, 'std': 0.59},\n",
    "    # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 75.92, 'std': 1.85},\n",
    "    # {'model': 'GraphSAGE', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 89.34, 'std': 0.39},\n",
    "    \n",
    "    {'model': 'GCCN with Transformer', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 74.04, 'std': 4.09},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 70.97, 'std': 4.06},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 70.39, 'std': 0.96},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 69.99, 'std': 1.13},\n",
    "    {'model': 'GCCN with Transformer', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.64, 'std': 0.01},\n",
    "    # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 84.40, 'std': 1.16},\n",
    "    # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.60, 'std': 1.88},\n",
    "    # {'model': 'Transformer', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.55, 'std': 0.39},\n",
    "    \n",
    "    {'model': 'GCCN with Hasse', 'domain': 'simplicial', 'dataset': 'MUTAG', 'mean': 74.04, 'std': 5.51},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'simplicial', 'dataset': 'PROTEINS', 'mean': 74.48, 'std': 1.89},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'simplicial', 'dataset': 'NCI1', 'mean': 75.02, 'std': 2.24},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'simplicial', 'dataset': 'NCI109', 'mean': 73.91, 'std': 3.90},\n",
    "    {'model': 'GCCN with Hasse', 'domain': 'simplicial', 'dataset': 'ZINC', 'mean': 0.56, 'std': 0.02},\n",
    "    # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'Cora', 'mean': 87.56, 'std': 0.66},\n",
    "    # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'Citeseer', 'mean': 74.50, 'std': 1.61},\n",
    "    # {'model': 'Simplicial with Hasse', 'domain': 'simplicial', 'dataset': 'PubMed', 'mean': 88.61, 'std': 0.27},\n",
    "])\n",
    "topotune_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the raw table data\n",
    "raw_table_data = {\n",
    "    # Format: {dataset: [(method, mean, std), ...]}\n",
    "    # 'Cora': [\n",
    "    #     ('CWN', 74.95, 0.98),\n",
    "    #     ('CCCN', 86.32, 1.38), \n",
    "    #     ('SCCNN', 87.44, 1.17),\n",
    "    #     ('SCN', 87.68, 1.17),\n",
    "    #     ('DR_cell', 82.19, 1.07),\n",
    "    #     ('SDP_cell', 80.65, 2.39),\n",
    "    #     ('DR_simplicial', 82.27, 1.34),\n",
    "    #     ('SDP_simplicial', 79.91, 1.18)\n",
    "    # ],\n",
    "    # 'Citeseer': [\n",
    "    #     ('CWN', 70.49, 2.85),\n",
    "    #     ('CCCN', 75.20, 1.82),\n",
    "    #     ('SCCNN', 75.63, 1.58),\n",
    "    #     ('SCN', 74.91, 1.25),\n",
    "    #     ('DR_cell', 70.23, 2.69),\n",
    "    #     ('SDP_cell', 69.03, 2.01),\n",
    "    #     ('DR_simplicial', 71.24, 1.68),\n",
    "    #     ('SDP_simplicial', 70.40, 1.53)\n",
    "    # ],\n",
    "    # 'PubMed': [\n",
    "    #     ('CWN', 86.94, 0.68),\n",
    "    #     ('CCCN', 88.64, 0.36),\n",
    "    #     ('SCCNN', 88.52, 0.44),\n",
    "    #     ('SCN', 88.67, 0.39),\n",
    "    #     ('DR_cell', 88.18, 0.32),\n",
    "    #     ('SDP_cell', 87.78, 0.58),\n",
    "    #     ('DR_simplicial', 88.72, 0.50),\n",
    "    #     ('SDP_simplicial', 88.62, 0.44)\n",
    "    # ],\n",
    "    'MUTAG': [\n",
    "        ('CWN', 69.68, 8.58),\n",
    "        ('CCCN', 80.43, 1.78),\n",
    "        ('SCCNN', 80.85, 5.42),\n",
    "        ('SCN', 77.02, 9.32),\n",
    "        ('DR_cell', 76.17, 6.63),\n",
    "        ('SDP_cell', 70.64, 3.16),\n",
    "        ('DR_simplicial', 71.49, 2.43),\n",
    "        ('SDP_simplicial', 73.62, 6.13)\n",
    "    ],\n",
    "    'PROTEINS': [\n",
    "        ('CWN', 76.13, 1.80),\n",
    "        ('CCCN', 76.13, 2.70),\n",
    "        ('SCCNN', 73.55, 3.43),\n",
    "        ('SCN', 73.33, 2.30),\n",
    "        ('DR_cell', 74.19, 2.86),\n",
    "        ('SDP_cell', 74.98, 1.92),\n",
    "        ('DR_simplicial', 75.27, 2.14),\n",
    "        ('SDP_simplicial', 74.77, 1.69)\n",
    "    ],\n",
    "    'NCI1': [\n",
    "        ('CWN', 68.52, 0.51),\n",
    "        ('CCCN', 73.93, 1.87),\n",
    "        ('SCCNN', 76.67, 1.48),\n",
    "        ('SCN', 77.65, 1.28),\n",
    "        ('DR_cell', 76.60, 1.75),\n",
    "        ('SDP_cell', 75.60, 2.45),\n",
    "        ('DR_simplicial', 75.27, 1.57),\n",
    "        ('SDP_simplicial', 74.49, 1.03)\n",
    "    ],\n",
    "    'NCI109': [\n",
    "        ('CWN', 68.19, 0.65),\n",
    "        ('CCCN', 73.80, 2.06),\n",
    "        ('SCCNN', 75.35, 1.50),\n",
    "        ('SCN', 74.83, 1.18),\n",
    "        ('DR_cell', 77.12, 1.07),\n",
    "        ('SDP_cell', 75.43, 1.94),\n",
    "        ('DR_simplicial', 74.58, 1.29),\n",
    "        ('SDP_simplicial', 75.70, 1.04)\n",
    "    ],\n",
    "    'ZINC': [\n",
    "        ('CWN', 0.70, 0.00),\n",
    "        ('CCCN', 0.34, 0.01),\n",
    "        ('SCCNN', 0.35, 0.02),\n",
    "        ('SCN', 0.34, 0.02),\n",
    "        ('DR_cell', 0.36, 0.01),\n",
    "        ('SDP_cell', 0.36, 0.02),\n",
    "        ('DR_simplicial', 0.59, 0.01),\n",
    "        ('SDP_simplicial', 0.53, 0.04)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Process the data to select the best of DR and SDP for each method\n",
    "additional_data = []\n",
    "\n",
    "for dataset, entries in raw_table_data.items():\n",
    "    optim_dir = optimization_metrics[dataset]['direction']\n",
    "    \n",
    "    # Group data by method prefix (before the underscore)\n",
    "    method_results = {}\n",
    "    standard_methods = []\n",
    "    dr_sdp_methods = {'cell': {}, 'simplicial': {}}\n",
    "    \n",
    "    for method, mean, std in entries:\n",
    "        if method in ['CWN', 'CCCN', 'SCCNN', 'SCN']:\n",
    "            # These are the standard methods - just add them directly\n",
    "            standard_methods.append({'method': method, 'dataset': dataset, 'mean': mean, 'std': std})\n",
    "        elif method.startswith('DR_') or method.startswith('SDP_'):\n",
    "            # These are DR or SDP methods - group by domain\n",
    "            method_type, domain = method.split('_')\n",
    "            dr_sdp_methods[domain][method_type] = {'mean': mean, 'std': std}\n",
    "    \n",
    "    # Add all standard methods\n",
    "    additional_data.extend(standard_methods)\n",
    "    \n",
    "    # Select the best of DR/SDP for each domain\n",
    "    for domain in ['cell', 'simplicial']:\n",
    "        if 'DR' in dr_sdp_methods[domain] and 'SDP' in dr_sdp_methods[domain]:\n",
    "            dr_result = dr_sdp_methods[domain]['DR']\n",
    "            sdp_result = dr_sdp_methods[domain]['SDP']\n",
    "            \n",
    "            # Determine which is better based on optimization direction\n",
    "            if optim_dir == 'max':\n",
    "                if dr_result['mean'] >= sdp_result['mean']:\n",
    "                    best_method = 'DR'\n",
    "                    best_result = dr_result\n",
    "                else:\n",
    "                    best_method = 'SDP'\n",
    "                    best_result = sdp_result\n",
    "            else:  # min direction\n",
    "                if dr_result['mean'] <= sdp_result['mean']:\n",
    "                    best_method = 'DR'\n",
    "                    best_result = dr_result\n",
    "                else:\n",
    "                    best_method = 'SDP'\n",
    "                    best_result = sdp_result\n",
    "            \n",
    "            # Add the best result\n",
    "            method_name = f\"{best_method}_{domain}\"\n",
    "            additional_data.append({\n",
    "                'method': method_name,\n",
    "                'dataset': dataset,\n",
    "                'mean': best_result['mean'],\n",
    "                'std': best_result['std']\n",
    "            })\n",
    "\n",
    "\n",
    "# Map method names to their proper format in the data\n",
    "method_mappings = {\n",
    "    'CWN': 'Cell CWN',\n",
    "    'CCCN': 'CCNN',  # Cell CCNN\n",
    "    'SCCNN': 'Simplicial CCNN',\n",
    "    'SCN': 'Simplicial SCN',\n",
    "    'DR_cell': 'Cell DR',\n",
    "    'SDP_cell': 'Cell SDP',\n",
    "    'DR_simplicial': 'DR',\n",
    "    'SDP_simplicial': 'SDP'\n",
    "}\n",
    "\n",
    "# Domain mappings\n",
    "domain_mappings = {\n",
    "    'CWN': 'cell',\n",
    "    'CCCN': 'cell',\n",
    "    'SCCNN': 'simplicial',\n",
    "    'SCN': 'simplicial',\n",
    "    'DR_cell': 'cell',\n",
    "    'SDP_cell': 'cell',\n",
    "    'DR_simplicial': 'simplicial',\n",
    "    'SDP_simplicial': 'simplicial'\n",
    "}\n",
    "\n",
    "# For display purposes, we'll use simplified method names\n",
    "display_mappings = {\n",
    "    'DR_cell': 'DR',\n",
    "    'SDP_cell': 'SDP',\n",
    "    'DR_simplicial': 'DR',\n",
    "    'SDP_simplicial': 'SDP'\n",
    "}\n",
    "\n",
    "# Convert the additional data to the proper format for the dataframe\n",
    "formatted_data = []\n",
    "for item in additional_data:\n",
    "    formatted_data.append({\n",
    "        'model': method_mappings[item['method']],\n",
    "        'domain': domain_mappings[item['method']],\n",
    "        'dataset': item['dataset'],\n",
    "        'mean': item['mean'],\n",
    "        'std': item['std']\n",
    "    })\n",
    "\n",
    "# This data can now be added to your existing dataframe or used to create a new one\n",
    "tbx_df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_add_df = pd.concat([df_res, topotune_df, tbx_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, dataset, mean, std, domain]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_add_df[final_add_df.duplicated(subset=['model', 'dataset', 'domain'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df):\n",
    "    \"\"\"\n",
    "    Generates a LaTeX table with methods as rows and datasets as columns.\n",
    "    For models containing \"with\", splits into first word (model) and last word (variant).\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with columns 'model', 'domain', 'dataset', 'mean', and 'std'\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (LaTeX preamble, LaTeX table code)\n",
    "    \"\"\"\n",
    "    # Ensure df has required columns\n",
    "    required_columns = ['model', 'domain', 'dataset', 'mean', 'std']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(\"DataFrame must contain column: {}\".format(col))\n",
    "    \n",
    "    # Remove duplicates and show warning if any are found\n",
    "    duplicates = df.duplicated(subset=['model', 'domain', 'dataset'], keep=False)\n",
    "    if duplicates.any():\n",
    "        print(\"Warning: Found {} duplicate entries. Using the first occurrence.\".format(duplicates.sum()))\n",
    "        df = df.drop_duplicates(subset=['model', 'domain', 'dataset'], keep='first')\n",
    "    \n",
    "    \n",
    "    # Instead of pivot, create a dictionary structure directly\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Group by domain, then model, then dataset\n",
    "    for _, row in df.iterrows():\n",
    "        domain = row['domain']\n",
    "        model = row['model']\n",
    "        dataset = row['dataset']\n",
    "        mean = row['mean']\n",
    "        std = row['std']\n",
    "        \n",
    "        # Initialize nested dictionaries if they don't exist\n",
    "        if domain not in data_dict:\n",
    "            data_dict[domain] = {}\n",
    "        if model not in data_dict[domain]:\n",
    "            data_dict[domain][model] = {}\n",
    "        \n",
    "        # Store the mean and std values\n",
    "        data_dict[domain][model][dataset] = {'mean': mean, 'std': std}\n",
    "    \n",
    "    # Get sorted lists of unique values\n",
    "    domains = sorted(data_dict.keys())\n",
    "    datasets = sorted(df['dataset'].unique())\n",
    "    \n",
    "    # Find best results for each dataset\n",
    "    best_results = {}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        all_means = []\n",
    "        for domain in domains:\n",
    "            for model in data_dict[domain]:\n",
    "                if dataset in data_dict[domain][model]:\n",
    "                    all_means.append(data_dict[domain][model][dataset]['mean'])\n",
    "        \n",
    "        if all_means:\n",
    "            optim_dir = optimization_metrics.get(dataset, {'direction': 'max'})['direction']\n",
    "            if optim_dir == 'max':\n",
    "                best_results[dataset] = max(all_means)\n",
    "            else:\n",
    "                best_results[dataset] = min(all_means)\n",
    "    \n",
    "    # Helper function to process model names for display\n",
    "    def process_model_name(model_name, domain):\n",
    "        # Remove domain prefix if present\n",
    "        domain_prefix = domain.capitalize() + \" \"\n",
    "        if model_name.startswith(domain_prefix):\n",
    "            model_name = model_name[len(domain_prefix):]\n",
    "        \n",
    "        # For models with \"with\", split into main model and variant\n",
    "        if \" with \" in model_name:\n",
    "            parts = model_name.split()\n",
    "            main_model = parts[0]  # First word (usually GCCN)\n",
    "            variant = parts[-1]    # Last word after \"with\"\n",
    "            return main_model, variant\n",
    "        elif \"GPSE\" in model_name:\n",
    "            # Special handling for GPSE\n",
    "            return \"GPSE\", model_name.replace(\"GPSE\", \"\").strip()\n",
    "        else:\n",
    "            # No splitting needed\n",
    "            return model_name, \"\"\n",
    "    \n",
    "    # Function to generate a LaTeX row for a model\n",
    "    def generate_model_row(model, domain, is_first_in_group=False, group_name=\"\"):\n",
    "        # Process model name\n",
    "        main_model, variant = process_model_name(model, domain)\n",
    "        \n",
    "        # Start row\n",
    "        if is_first_in_group:\n",
    "            row = \"\\\\multirow{{1}}{{*}}{{{}}} & \".format(group_name)\n",
    "        else:\n",
    "            row = \" & \"\n",
    "        \n",
    "        # Add variant name\n",
    "        row += \"\\\\emph{{{}}}\".format(variant if variant else main_model)\n",
    "        \n",
    "        # Add data for each dataset\n",
    "        for dataset in datasets:\n",
    "            if dataset in data_dict[domain][model]:\n",
    "                mean = data_dict[domain][model][dataset]['mean']\n",
    "                std = data_dict[domain][model][dataset]['std']\n",
    "                \n",
    "                # Format based on whether it's the best result\n",
    "                if dataset in best_results and np.isclose(mean, best_results[dataset]):\n",
    "                    row += \" & \\\\cellcolor{{gray!30}}\\\\textbf{{{0:.3f}}} \\\\scriptsize{{{1:.3f}}}\".format(mean, std)\n",
    "                else:\n",
    "                    # Check if within one standard deviation of best\n",
    "                    optim_dir = optimization_metrics.get(dataset, {'direction': 'max'})['direction']\n",
    "                    threshold = best_results[dataset] - std if dataset in best_results else None\n",
    "                    \n",
    "                    if threshold is not None:\n",
    "                        if (optim_dir == 'max' and mean >= threshold) or (optim_dir == 'min' and mean <= threshold):\n",
    "                            row += \" & \\\\cellcolor{{blue!20}}{0:.3f} \\\\scriptsize{{{1:.3f}}}\".format(mean, std)\n",
    "                        else:\n",
    "                            row += \" & {0:.3f} \\\\scriptsize{{{1:.3f}}}\".format(mean, std)\n",
    "                    else:\n",
    "                        row += \" & {0:.3f} \\\\scriptsize{{{1:.3f}}}\".format(mean, std)\n",
    "            else:\n",
    "                row += \" & -\"\n",
    "        \n",
    "        return row + \" \\\\\\\\\"\n",
    "    \n",
    "    # Generate LaTeX table\n",
    "    latex_table = []\n",
    "    \n",
    "    # Process each domain\n",
    "    for domain in domains:\n",
    "        # Organize models by main type\n",
    "        domain_models = {}\n",
    "        \n",
    "        # Group models based on their main type (after processing)\n",
    "        for model in data_dict[domain]:\n",
    "            main_type, _ = process_model_name(model, domain)\n",
    "            \n",
    "            if main_type not in domain_models:\n",
    "                domain_models[main_type] = []\n",
    "            \n",
    "            domain_models[main_type].append(model)\n",
    "        \n",
    "        # Sort model groups and models within groups\n",
    "        sorted_types = sorted(domain_models.keys())\n",
    "        for model_type in sorted_types:\n",
    "            domain_models[model_type] = sorted(domain_models[model_type])\n",
    "        \n",
    "        # Add domain header\n",
    "        domain_display = domain.capitalize()\n",
    "        latex_table.append(\"\\\\multicolumn{{{0}}}{{l}}{{\\\\textbf{{{1} Methods}}}} \\\\\\\\\".format(len(datasets) + 2, domain_display))\n",
    "        latex_table.append(\"\\\\midrule\")\n",
    "        \n",
    "        # Process each model type group\n",
    "        for i, model_type in enumerate(sorted_types):\n",
    "            models = domain_models[model_type]\n",
    "            \n",
    "            # Add group header with multirow\n",
    "            latex_table.append(\"\\\\multirow{{{0}}}{{*}}{{{1}}} & \".format(len(models), model_type))\n",
    "            \n",
    "            # Process each model in the group\n",
    "            for j, model in enumerate(models):\n",
    "                if j == 0:\n",
    "                    # First model in group, header already added\n",
    "                    row = generate_model_row(model, domain, is_first_in_group=True, group_name=model_type)\n",
    "                else:\n",
    "                    # Subsequent models in group\n",
    "                    row = \" & \" + generate_model_row(model, domain).split(\" & \", 1)[1]\n",
    "                \n",
    "                latex_table.append(row)\n",
    "                \n",
    "                # Add cmidrule between models but not after the last one\n",
    "                if j < len(models) - 1:\n",
    "                    latex_table.append(\"\\\\cmidrule{{2-{0}}}\".format(len(datasets) + 2))\n",
    "            \n",
    "            # Add midrule between different model types but not after the last one\n",
    "            if i < len(sorted_types) - 1:\n",
    "                latex_table.append(\"\\\\midrule\")\n",
    "        \n",
    "        # Add midrule between domains\n",
    "        if domain != domains[-1]:\n",
    "            latex_table.append(\"\\\\midrule\")\n",
    "    \n",
    "    # Construct the LaTeX table header\n",
    "    dataset_labels = \" & & \" + \" & \".join([\"\\\\emph{{{}}}\".format(dataset) for dataset in datasets])\n",
    "    \n",
    "    # Additional packages needed\n",
    "    preamble = \"\\\\usepackage{multirow}\\n\\\\usepackage{booktabs}\\n\\\\usepackage{colortbl}\\n\\\\usepackage{array}\"\n",
    "    \n",
    "    # Create column specifications\n",
    "    col_spec = \">{{\\\\raggedright\\\\arraybackslash}}p{{2.5cm}}>{{\\\\raggedright\\\\arraybackslash}}p{{2.5cm}}\" + \"c\" * len(datasets)\n",
    "    \n",
    "    latex_code = (\n",
    "        \"\\\\begin{table}[h]\\n\"\n",
    "        \"\\\\centering\\n\"\n",
    "        \"\\\\scriptsize\\n\"\n",
    "        \"\\\\begin{tabular}{\" + col_spec + \"}\\n\"\n",
    "        \"\\\\toprule\\n\"\n",
    "        \"\\\\textbf{Method} & \\\\textbf{Variant} \" + dataset_labels + \" \\\\\\\\\\n\"\n",
    "        + \"\\n\".join(latex_table)\n",
    "        + \"\\n\\\\bottomrule\\n\"\n",
    "        \"\\\\end{tabular}\\n\"\n",
    "        \"\\\\caption{Cross-domain comparison grouped by domain type (Simplicial/Cellular): results are shown as mean and standard deviation. \"\n",
    "        \"The best result is bold and shaded in grey, while those within one standard deviation are in blue-shaded boxes.}\\n\"\n",
    "        \"\\\\end{table}\"\n",
    "    )\n",
    "\n",
    "    return preamble, latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 20 duplicate entries. Using the first occurrence.\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\scriptsize\n",
      "\\begin{tabular}{>{{\\raggedright\\arraybackslash}}p{{2.5cm}}>{{\\raggedright\\arraybackslash}}p{{2.5cm}}ccccccc}\n",
      "\\toprule\n",
      "\\textbf{Method} & \\textbf{Variant}  & & \\emph{IMDB-BINARY} & \\emph{IMDB-MULTI} & \\emph{MUTAG} & \\emph{NCI1} & \\emph{NCI109} & \\emph{PROTEINS} & \\emph{ZINC} \\\\\n",
      "\\multicolumn{9}{l}{\\textbf{Cell Methods}} \\\\\n",
      "\\midrule\n",
      "\\multirow{4}{*}{GPSE} & \n",
      "\\emph{_GEOM} & \\cellcolor{gray!30}\\textbf{73.200} \\scriptsize{1.876} & \\cellcolor{blue!20}49.013 \\scriptsize{3.783} & - & 78.016 \\scriptsize{1.175} & \\cellcolor{blue!20}77.909 \\scriptsize{1.246} & \\cellcolor{blue!20}74.767 \\scriptsize{3.695} & 0.210 \\scriptsize{0.002} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_MOLPCBA} & \\cellcolor{blue!20}70.960 \\scriptsize{5.104} & \\cellcolor{gray!30}\\textbf{50.027} \\scriptsize{3.561} & - & \\cellcolor{blue!20}78.521 \\scriptsize{0.947} & 77.483 \\scriptsize{0.641} & \\cellcolor{blue!20}74.839 \\scriptsize{2.590} & 0.213 \\scriptsize{0.005} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_PCQM4MV2} & \\cellcolor{blue!20}71.280 \\scriptsize{4.376} & \\cellcolor{blue!20}48.640 \\scriptsize{4.244} & - & \\cellcolor{blue!20}78.833 \\scriptsize{1.321} & \\cellcolor{blue!20}77.812 \\scriptsize{1.257} & \\cellcolor{gray!30}\\textbf{76.416} \\scriptsize{3.470} & 0.212 \\scriptsize{0.009} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{_ZINC} & \\cellcolor{blue!20}72.000 \\scriptsize{3.709} & \\cellcolor{blue!20}48.533 \\scriptsize{4.569} & - & \\cellcolor{gray!30}\\textbf{79.280} \\scriptsize{1.120} & \\cellcolor{gray!30}\\textbf{78.296} \\scriptsize{1.534} & \\cellcolor{blue!20}74.839 \\scriptsize{3.046} & 0.214 \\scriptsize{0.002} \\\\\n",
      "\\multirow{10}{*}{Other} & \n",
      "\\emph{CCNN} & - & - & 80.430 \\scriptsize{1.780} & 76.670 \\scriptsize{1.480} & 75.350 \\scriptsize{1.500} & \\cellcolor{blue!20}76.130 \\scriptsize{2.700} & 0.340 \\scriptsize{0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{CWN} & - & - & 69.680 \\scriptsize{8.580} & 68.520 \\scriptsize{0.510} & 68.190 \\scriptsize{0.650} & \\cellcolor{blue!20}76.130 \\scriptsize{1.800} & 0.700 \\scriptsize{0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{DR} & - & - & 76.170 \\scriptsize{6.630} & 76.600 \\scriptsize{1.750} & 77.120 \\scriptsize{1.070} & - & 0.360 \\scriptsize{0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SDP} & - & - & - & - & - & \\cellcolor{blue!20}74.980 \\scriptsize{1.920} & - \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GAT} & - & - & \\cellcolor{blue!20}83.400 \\scriptsize{4.850} & 76.110 \\scriptsize{1.690} & 75.620 \\scriptsize{0.760} & 74.050 \\scriptsize{2.160} & 0.380 \\scriptsize{0.030} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GCN} & - & - & \\cellcolor{blue!20}85.110 \\scriptsize{6.730} & 76.420 \\scriptsize{1.670} & 75.620 \\scriptsize{0.940} & 74.410 \\scriptsize{1.770} & 0.360 \\scriptsize{0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GIN} & - & - & \\cellcolor{gray!30}\\textbf{86.380} \\scriptsize{6.490} & 77.650 \\scriptsize{1.110} & 77.190 \\scriptsize{0.210} & 72.540 \\scriptsize{3.070} & \\cellcolor{gray!30}\\textbf{0.190} \\scriptsize{0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with GraphSAGE} & - & - & \\cellcolor{blue!20}85.530 \\scriptsize{6.800} & \\cellcolor{blue!20}78.230 \\scriptsize{1.470} & 77.100 \\scriptsize{0.830} & 73.620 \\scriptsize{2.720} & 0.240 \\scriptsize{0.000} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Hasse} & - & - & \\cellcolor{blue!20}85.960 \\scriptsize{7.150} & 76.750 \\scriptsize{1.630} & 76.940 \\scriptsize{0.820} & \\cellcolor{blue!20}73.730 \\scriptsize{2.950} & 0.310 \\scriptsize{0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Transformer} & - & - & \\cellcolor{blue!20}83.830 \\scriptsize{6.490} & 73.000 \\scriptsize{1.370} & 73.200 \\scriptsize{1.050} & 70.970 \\scriptsize{4.060} & 0.450 \\scriptsize{0.020} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{9}{l}{\\textbf{Simplicial Methods}} \\\\\n",
      "\\midrule\n",
      "\\multirow{10}{*}{Other} & \n",
      "\\emph{DR} & - & - & - & 75.270 \\scriptsize{1.570} & - & \\cellcolor{blue!20}75.270 \\scriptsize{2.140} & - \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GCCN with GAT} & - & - & 79.150 \\scriptsize{4.090} & 74.860 \\scriptsize{1.420} & 74.810 \\scriptsize{1.140} & \\cellcolor{blue!20}74.620 \\scriptsize{1.950} & 0.570 \\scriptsize{0.030} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GCN} & - & - & 74.040 \\scriptsize{8.300} & 74.200 \\scriptsize{2.170} & 74.130 \\scriptsize{0.530} & \\cellcolor{blue!20}74.910 \\scriptsize{2.510} & 0.530 \\scriptsize{0.050} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GIN} & - & - & \\cellcolor{blue!20}85.960 \\scriptsize{4.660} & 76.670 \\scriptsize{1.620} & 75.760 \\scriptsize{1.280} & 72.830 \\scriptsize{2.720} & 0.350 \\scriptsize{0.010} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{GraphSAGE} & - & - & 75.740 \\scriptsize{2.430} & 76.850 \\scriptsize{1.500} & 75.640 \\scriptsize{1.940} & \\cellcolor{blue!20}74.700 \\scriptsize{3.100} & 0.500 \\scriptsize{0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SDP} & - & - & 73.620 \\scriptsize{6.130} & - & 75.700 \\scriptsize{1.040} & - & 0.530 \\scriptsize{0.040} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{CCNN} & - & - & 76.170 \\scriptsize{6.630} & 76.600 \\scriptsize{1.750} & 77.120 \\scriptsize{1.070} & \\cellcolor{blue!20}75.270 \\scriptsize{2.140} & 0.360 \\scriptsize{0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{SCN} & - & - & 77.020 \\scriptsize{9.320} & 77.650 \\scriptsize{1.280} & 74.830 \\scriptsize{1.180} & 73.330 \\scriptsize{2.300} & 0.340 \\scriptsize{0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{with Hasse} & - & - & 74.040 \\scriptsize{5.510} & 75.020 \\scriptsize{2.240} & 73.910 \\scriptsize{3.900} & 74.480 \\scriptsize{1.890} & 0.560 \\scriptsize{0.020} \\\\\n",
      "\\cmidrule{2-9}\n",
      " & \\emph{Transformer} & - & - & 74.040 \\scriptsize{4.090} & 70.390 \\scriptsize{0.960} & 69.990 \\scriptsize{1.130} & 70.970 \\scriptsize{4.060} & 0.640 \\scriptsize{0.010} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Cross-domain comparison grouped by domain type (Simplicial/Cellular): results are shown as mean and standard deviation. The best result is bold and shaded in grey, while those within one standard deviation are in blue-shaded boxes.}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(generate_latex_table(final_add_df)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peekvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
