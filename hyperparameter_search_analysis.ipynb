{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from topobench.nn.backbones.graph.gat_v4 import GATv4\n",
    "from topobench.nn.readouts.ftd_readout import FTDReadOut\n",
    "from topobench.nn.encoders.all_cell_encoder import AllCellFeatureEncoder\n",
    "from torch_geometric.nn import GAT, GCN, global_mean_pool\n",
    "import yaml\n",
    "from hydra import compose, initialize\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Number of runs per experiment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_runs_in_block(lines):\n",
    "    params = {}\n",
    "    for line in lines:\n",
    "        if \"=\" not in line or line.strip().startswith(\"python\") or \"--multirun\" in line or line.strip().endswith(\"&\"):\n",
    "            continue\n",
    "        key, val = line.split(\"=\", 1)\n",
    "        key = key.strip()\n",
    "        val = val.strip().strip(\"\\\\\")\n",
    "        \n",
    "        # Special case: multiple escaped bracketed items (e.g. \\[...\\],\\[...\\],...)\n",
    "        if \"\\\\[\" in val and \"\\\\]\" in val:\n",
    "            # Find all escaped bracketed expressions\n",
    "            matches = re.findall(r'(\\[.*?\\\\\\])', val)\n",
    "            cleaned = [m.replace(\"\\\\\", \"\") for m in matches]\n",
    "            params[key] = cleaned\n",
    "        elif \",\" in val:\n",
    "            params[key] = val.split(\",\")\n",
    "        else:\n",
    "            params[key] = [val]\n",
    "    # Cartesian product of all parameter options\n",
    "    total = 1\n",
    "    for v in params.values():\n",
    "        total *= len(v)\n",
    "    return total\n",
    "\n",
    "\n",
    "def parse_hydra_sh(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    blocks = []\n",
    "    current = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"python -m\"):\n",
    "            if current:\n",
    "                blocks.append(current)\n",
    "                current = []\n",
    "        current.append(line)\n",
    "    if current:\n",
    "        blocks.append(current)\n",
    "\n",
    "    results = []\n",
    "    for i, block in enumerate(blocks):\n",
    "        run_count = count_runs_in_block(block)\n",
    "        results.append((i + 1, run_count))\n",
    "    \n",
    "    for block_num, count in results:\n",
    "        print(f\"Block {block_num}: {count} runs\")\n",
    "    print(f\"Total: {sum(count for _, count in results)} runs\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1: 11520 runs\n",
      "Block 2: 11520 runs\n",
      "Block 3: 11520 runs\n",
      "Block 4: 11520 runs\n",
      "Block 5: 11520 runs\n",
      "Block 6: 11520 runs\n",
      "Block 7: 720 runs\n",
      "Block 8: 720 runs\n",
      "Total: 70560 runs\n"
     ]
    }
   ],
   "source": [
    "results = parse_hydra_sh(\"/home/lcornelis/code/TopoProteo/topoproteo_experiments.sh\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Number of Parameters Per Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_v4_hidden_channels= [[8, 16], [64, 128]]\n",
    "gat_v4_heads= [[2, 2], [4, 4]]\n",
    "fc_out_channels_gatv4 = [1,8]\n",
    "\n",
    "gat_num_layers= [2, 4]  # only for GAT and GCN\n",
    "gat_hidden_channels= [8, 16]\n",
    "gat_heads= [2, 4]\n",
    "fc_out_channels_gat = [8,16]\n",
    "\n",
    "gcn_num_layers= [2, 4] \n",
    "gcn_hidden_channels= [8, 16]\n",
    "fc_out_channels_gcn = [8,16]\n",
    "\n",
    "readout_graph_encoder_dims = [256,128]\n",
    "readout_fc_dims= [128,64,32], [256,128,64]\n",
    "readout_fc_acts = ['relu', 'tanh']\n",
    "\n",
    "# Dataset Parameters \n",
    "FTD_config = \"/home/lcornelis/code/TopoProteo/configs/dataset/graph/FTD.yaml\"\n",
    "gatv4config = \"/home/lcornelis/code/TopoProteo/configs/model/graph/gatv4.yaml\"\n",
    "gatconfig = \"/home/lcornelis/code/TopoProteo/configs/model/graph/gat.yaml\"\n",
    "gcnconfig = \"/home/lcornelis/code/TopoProteo/configs/model/graph/gcn.yaml\"\n",
    "mlpconfig = \"/home/lcornelis/code/TopoProteo/configs/model/graph/mlp.yaml\" #fix this \n",
    "\n",
    "with open(FTD_config, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# Navigate to the nested value\n",
    "num_nodes = config[\"loader\"][\"parameters\"][\"num_nodes\"]\n",
    "task_level = config[\"parameters\"][\"task_level\"]\n",
    "out_channels = config[\"parameters\"][\"num_classes\"]\n",
    "\n",
    "#shared readout parameters\n",
    "\n",
    "with open(gatv4config, \"r\") as f:\n",
    "    config_gatv4 = yaml.safe_load(f)\n",
    "\n",
    "readout = config_gatv4[\"readout\"]\n",
    "readout_which_layer = readout[\"which_layer\"]\n",
    "fc_dropout = readout[\"fc_dropout\"]\n",
    "feature_encoder_dim = readout[\"feature_encoder_dim\"]\n",
    "hidden_dim = readout[\"hidden_dim\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config_and_model(model_name, dataset_name, adj_thresh):\n",
    "    cfg = compose(\n",
    "        config_name=\"run.yaml\",\n",
    "        overrides=[\n",
    "            f\"model={model_name}\",\n",
    "            f\"dataset={dataset_name}\",\n",
    "            f\"dataset.loader.parameters.adj_thresh={adj_thresh}\",\n",
    "        ], \n",
    "        return_hydra_config=True\n",
    "    )\n",
    "    model = hydra.utils.instantiate(\n",
    "                cfg.model,\n",
    "                evaluator=cfg.evaluator,\n",
    "                optimizer=cfg.optimizer,\n",
    "                loss=cfg.loss,\n",
    "            )\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT-v4 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params_list_combined = []\n",
    "\n",
    "for feature_encoder_out_channels in fc_out_channels_gatv4:\n",
    "    for hidden_channels in gat_v4_hidden_channels:\n",
    "        for heads in gat_v4_heads:\n",
    "            for in_channels in fc_out_channels_gatv4:\n",
    "                for fc_dim in readout_fc_dims:\n",
    "                    for graph_encoder_dim in readout_graph_encoder_dims:\n",
    "                        for fc_act in readout_fc_acts:\n",
    "                            cfg = compose(\n",
    "                                config_name=\"run.yaml\",\n",
    "                                overrides=[\n",
    "                                    \"model=graph/gatv4\",\n",
    "                                    \"dataset=graph/FTD\",\n",
    "                                    \"dataset.loader.parameters.adj_thresh=0.5\",\n",
    "                                ], \n",
    "                                return_hydra_config=True\n",
    "                            )\n",
    "                            model = hydra.utils.instantiate(\n",
    "                                    cfg.model,\n",
    "                                    evaluator=cfg.evaluator,\n",
    "                                    optimizer=cfg.optimizer,\n",
    "                                    loss=cfg.loss,\n",
    "                                )\n",
    "                            total_params_combined = (\n",
    "                                sum(p.numel() for p in feature_encoder_model.parameters()) +\n",
    "                                sum(p.numel() for p in gat_v4_model.parameters()) +\n",
    "                                sum(p.numel() for p in readout_model.parameters())\n",
    "                            )\n",
    "                            total_params_list_combined.append(total_params_combined)\n",
    "\n",
    "print(\"Max number of parameters: \", max(total_params_list_combined))\n",
    "print(\"Min number of parameters: \", min(total_params_list_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got str\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m graph_encoder_dim \u001b[38;5;129;01min\u001b[39;00m readout_graph_encoder_dims:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fc_act \u001b[38;5;129;01min\u001b[39;00m readout_fc_acts:\n\u001b[0;32m---> 39\u001b[0m         readout_model \u001b[38;5;241m=\u001b[39m \u001b[43mFTDReadOut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#SOSOSOSSSS\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwhich_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreadout_which_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfc_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfc_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfc_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfc_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfc_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfc_act\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_feature_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_encoder_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_encoder_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgraph_encoder_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_encoder_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtask_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m         total_params_combined \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m feature_encoder_model\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m gat_v4_model\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m readout_model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m         total_params_list_combined\u001b[38;5;241m.\u001b[39mappend(total_params_combined)\n",
      "File \u001b[0;32m~/code/TopoProteo/topobench/nn/readouts/ftd_readout.py:31\u001b[0m, in \u001b[0;36mFTDReadOut.__init__\u001b[0;34m(self, num_nodes, hidden_dim, which_layer, fc_dim, fc_dropout, fc_act, out_channels, use_feature_encoder, feature_encoder_dim, graph_encoder_dim, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m     num_nodes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     30\u001b[0m ):\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim \u001b[38;5;241m=\u001b[39m hidden_dim\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_dim \u001b[38;5;241m=\u001b[39m feature_encoder_dim\n",
      "File \u001b[0;32m~/code/TopoProteo/topobench/nn/readouts/base.py:37\u001b[0m, in \u001b[0;36mAbstractZeroCellReadOut.__init__\u001b[0;34m(self, hidden_dim, out_channels, task_level, pooling_type, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     hidden_dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     34\u001b[0m ):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m task_level \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid task_level\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_level \u001b[38;5;241m=\u001b[39m task_level\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/torch/nn/modules/linear.py:98\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got str\""
     ]
    }
   ],
   "source": [
    "# Get values from config\n",
    "backbone = config_gatv4[\"backbone\"]\n",
    "# Extract values backbone\n",
    "which_layer = backbone[\"which_layer\"]\n",
    "dropout = backbone[\"dropout\"]\n",
    "act = backbone[\"act\"]\n",
    "use_layer_norm = backbone[\"use_layer_norm\"]\n",
    "weight_initializer = backbone[\"weight_initializer\"]\n",
    "\n",
    "# Compute fc_input_dim\n",
    "fc_input_dim = num_nodes * len(which_layer)\n",
    "\n",
    "total_params_list_combined = []\n",
    "\n",
    "for feature_encoder_out_channels in fc_out_channels_gatv4:\n",
    "    feature_encoder_model = AllCellFeatureEncoder(\n",
    "        in_channels=[1],  # SOS\n",
    "        out_channels=feature_encoder_out_channels,\n",
    "    )\n",
    "    for hidden_channels in gat_v4_hidden_channels:\n",
    "        for heads in gat_v4_heads:\n",
    "            for in_channels in fc_out_channels_gatv4:\n",
    "                gat_v4_model = GATv4(\n",
    "                    in_channels= in_channels, \n",
    "                    hidden_channels=hidden_channels,\n",
    "                    out_channels=1,\n",
    "                    heads=heads,\n",
    "                    dropout=dropout,\n",
    "                    act=act,\n",
    "                    which_layer=which_layer,\n",
    "                    use_layer_norm=use_layer_norm,\n",
    "                    num_nodes=num_nodes,\n",
    "                    weight_initializer=weight_initializer,\n",
    "                )\n",
    "                \n",
    "                for fc_dim in readout_fc_dims:\n",
    "                    for graph_encoder_dim in readout_graph_encoder_dims:\n",
    "                        for fc_act in readout_fc_acts:\n",
    "                            readout_model = FTDReadOut(\n",
    "                                num_nodes=num_nodes,\n",
    "                                hidden_dim=hidden_dim, #SOSOSOSSSS\n",
    "                                which_layer=readout_which_layer,  \n",
    "                                fc_dim=fc_dim,\n",
    "                                fc_dropout=fc_dropout,\n",
    "                                fc_act=fc_act,\n",
    "                                out_channels=out_channels,\n",
    "                                use_feature_encoder=True,\n",
    "                                feature_encoder_dim=feature_encoder_dim,\n",
    "                                graph_encoder_dim=graph_encoder_dim,\n",
    "                                task_level=task_level,\n",
    "                            )\n",
    "                            total_params_combined = (\n",
    "                                sum(p.numel() for p in feature_encoder_model.parameters()) +\n",
    "                                sum(p.numel() for p in gat_v4_model.parameters()) +\n",
    "                                sum(p.numel() for p in readout_model.parameters())\n",
    "                            )\n",
    "                            total_params_list_combined.append(total_params_combined)\n",
    "\n",
    "print(\"Max number of parameters: \", max(total_params_list_combined))\n",
    "print(\"Min number of parameters: \", min(total_params_list_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gatconfig, \"r\") as f:\n",
    "    config_gat = yaml.safe_load(f)\n",
    "backbone = config[\"backbone\"]\n",
    "dropout = backbone[\"dropout\"]\n",
    "act = backbone[\"act\"]\n",
    "num_layers = backbone[\"num_layers\"]\n",
    "hidden_channels = backbone[\"hidden_channels\"]\n",
    "heads = backbone[\"heads\"]\n",
    "\n",
    "total_params_list_combined = []\n",
    "\n",
    "for feature_encoder_out_channels in fc_out_channels_gat:\n",
    "    feature_encoder_model = AllCellFeatureEncoder(\n",
    "        in_channels=[1],  # Adjust if needed\n",
    "        out_channels=feature_encoder_out_channels,\n",
    "    )\n",
    "    for num_layers in gat_num_layers:\n",
    "        for hidden_channels in gat_hidden_channels:\n",
    "            for heads in gat_heads:\n",
    "                gat_model = GAT(\n",
    "                    in_channels=1,  # Based on encoded output\n",
    "                    num_layers=num_layers,\n",
    "                    hidden_channels=hidden_channels,\n",
    "                    out_channels=1,\n",
    "                    heads=heads,\n",
    "                    dropout=dropout,\n",
    "                    act=act,\n",
    "                )\n",
    "\n",
    "                for fc_dim in readout_fc_dims:\n",
    "                    for graph_encoder_dim in readout_graph_encoder_dims:\n",
    "                        for fc_act in readout_fc_acts:\n",
    "                            readout_model = FTDReadOut(\n",
    "                                num_nodes=num_nodes,\n",
    "                                hidden_dim=10,  # SOS\n",
    "                                which_layer=readout_which_layer,\n",
    "                                fc_dim=fc_dim,\n",
    "                                fc_dropout=fc_dropout,\n",
    "                                fc_act=fc_act,\n",
    "                                out_channels=1,\n",
    "                                use_feature_encoder=True,\n",
    "                                feature_encoder_dim=feature_encoder_out_channels,\n",
    "                                graph_encoder_dim=graph_encoder_dim,\n",
    "                                task_level=task_level,\n",
    "                            )\n",
    "\n",
    "                            total_params_combined = (\n",
    "                                sum(p.numel() for p in feature_encoder_model.parameters()) +\n",
    "                                sum(p.numel() for p in gat_model.parameters()) +\n",
    "                                sum(p.numel() for p in readout_model.parameters())\n",
    "                            )\n",
    "                            total_params_list_combined.append(total_params_combined)\n",
    "\n",
    "print(\"Max number of parameters: \", max(total_params_list_combined))\n",
    "print(\"Min number of parameters: \", min(total_params_list_combined))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gcnconfig, \"r\") as f:\n",
    "    config_gcn = yaml.safe_load(f)\n",
    "backbone = config[\"backbone\"]\n",
    "dropout = backbone[\"dropout\"]\n",
    "act = backbone[\"act\"]\n",
    "num_layers = backbone[\"num_layers\"]\n",
    "hidden_channels = backbone[\"hidden_channels\"]\n",
    "\n",
    "fc_input_dim = (num_nodes * 2) - 1\n",
    "total_params_list_combined = []\n",
    "for num_layers in gcn_num_layers:\n",
    "    for hidden_channels in gcn_hidden_channels:\n",
    "        gcn_model = GCN(\n",
    "            in_channels=1,\n",
    "            num_layers=num_layers,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=1,\n",
    "            dropout=dropout,\n",
    "            act=act,\n",
    "        )\n",
    "        for fc_dim in fc_dim_choices:\n",
    "            for fc_dropout in fc_dropout_choices:\n",
    "                for fc_act in fc_act_choices:\n",
    "                    readout_model = FTDReadOut(\n",
    "                        num_nodes=num_nodes,\n",
    "                        which_layer=readout_which_layer,\n",
    "                        fc_dim=fc_dim,\n",
    "                        fc_dropout=fc_dropout,\n",
    "                        fc_act=fc_act,\n",
    "                        out_channels=1,\n",
    "                        fc_input_dim=fc_input_dim,\n",
    "                        use_feature_encoder=True,\n",
    "                        feature_encoder_dim=feature_encoder_dim,\n",
    "                        graph_encoder_dim=graph_encoder_dim,\n",
    "                        hidden_dim=10, #SOS\n",
    "                        task_level=task_level, #SOS\n",
    "                    )\n",
    "                    total_params_combined = sum(p.numel() for p in gcn_model.parameters()) + sum(p.numel() for p in readout_model.parameters())\n",
    "                    total_params_list_combined.append(total_params_combined)\n",
    "\n",
    "print(\"Max number of parameters: \", max(total_params_list_combined))\n",
    "print(\"Min number of parameters: \", min(total_params_list_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = config.dropout\n",
    "fc_input_dim = (num_nodes * 2) -1\n",
    "total_params_list_combined = []\n",
    "for fc_dim in mlp_channel_lists:\n",
    "    for fc_dropout in dropout_choices:\n",
    "        for fc_act in fc_act_choices:\n",
    "            readout_model = FTDReadOut(\n",
    "                        num_nodes=num_nodes,\n",
    "                        which_layer=readout_which_layer,\n",
    "                        fc_dim=fc_dim,\n",
    "                        fc_dropout=fc_dropout,\n",
    "                        fc_act=fc_act,\n",
    "                        out_channels=1,\n",
    "                        fc_input_dim=fc_input_dim,\n",
    "                        use_feature_encoder=True,\n",
    "                        feature_encoder_dim=feature_encoder_dim,\n",
    "                        graph_encoder_dim=graph_encoder_dim,\n",
    "                        hidden_dim=10, #SOS\n",
    "                        task_level=task_level, #SOS\n",
    "                    )\n",
    "            total_params_combined = sum(p.numel() for p in readout_model.parameters())\n",
    "            total_params_list_combined.append(total_params_combined)\n",
    "    \n",
    "\n",
    "print(\"Max number of parameters: \", max(total_params_list_combined))\n",
    "print(\"Min number of parameters: \", min(total_params_list_combined))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
